"""
ä¼˜åŒ–çš„æ—¶é—´åºåˆ—å¤„ç†å™¨ - æä¾›é«˜æ€§èƒ½çš„æ•°æ®å¤„ç†æ–¹æ³•
"""
import pandas as pd
import numpy as np
from typing import Union, Optional, Tuple
import logging

logger = logging.getLogger(__name__)


class OptimizedTimeSeriesProcessor:
    """ä¼˜åŒ–çš„æ—¶é—´åºåˆ—å¤„ç†å™¨ï¼Œä¸“æ³¨æ€§èƒ½å’Œå†…å­˜æ•ˆç‡"""
    
    @staticmethod
    def _get_effective_trading_date(release_date: pd.Timestamp, 
                                   trading_dates: pd.DatetimeIndex) -> pd.Timestamp:
        """
        è·å–è´¢æŠ¥å‘å¸ƒæ—¥æœŸå¯¹åº”çš„ç”Ÿæ•ˆäº¤æ˜“æ—¥
        
        Parameters:
        -----------
        release_date : è´¢æŠ¥å‘å¸ƒæ—¥æœŸ
        trading_dates : äº¤æ˜“æ—¥åºåˆ—
        
        Returns:
        --------
        ç”Ÿæ•ˆçš„äº¤æ˜“æ—¥æœŸï¼š
        - å¦‚æœå‘å¸ƒæ—¥æœŸæ˜¯äº¤æ˜“æ—¥ï¼Œè¿”å›å‘å¸ƒæ—¥æœŸ
        - å¦‚æœå‘å¸ƒæ—¥æœŸæ˜¯éäº¤æ˜“æ—¥ï¼Œè¿”å›ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥
        - å¦‚æœæ²¡æœ‰åç»­äº¤æ˜“æ—¥ï¼Œè¿”å›None
        """
        # å¦‚æœå‘å¸ƒæ—¥æœŸæ˜¯äº¤æ˜“æ—¥ï¼Œç›´æ¥ä½¿ç”¨
        if release_date in trading_dates:
            return release_date
        
        # å¦‚æœæ˜¯éäº¤æ˜“æ—¥ï¼Œæ‰¾åˆ°ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥
        future_dates = trading_dates[trading_dates > release_date]
        if len(future_dates) > 0:
            return future_dates[0]
        
        # å¦‚æœæ²¡æœ‰åç»­äº¤æ˜“æ—¥ï¼Œè¿”å›None
        return None
    
    @staticmethod
    def expand_to_daily_vectorized(factor_data: pd.DataFrame,
                                  release_dates: pd.DataFrame,
                                  trading_dates: pd.DatetimeIndex) -> pd.DataFrame:
        """
        å‘é‡åŒ–çš„æ—¥é¢‘æ‰©å±•æ–¹æ³•ï¼Œå¤§å¹…æå‡æ€§èƒ½
        
        Parameters:
        -----------
        factor_data : è´¢æŠ¥å› å­æ•°æ®ï¼Œç´¢å¼•ä¸º(ReportDates, StockCodes)
        release_dates : è´¢æŠ¥å‘å¸ƒæ—¥æœŸï¼ŒåŒ…å«'ReleasedDates'åˆ—
        trading_dates : äº¤æ˜“æ—¥åºåˆ—
        
        Returns:
        --------
        æ—¥é¢‘å› å­æ•°æ®ï¼Œç´¢å¼•ä¸º(TradingDates, StockCodes)
        """
        logger.debug(f"å¼€å§‹å‘é‡åŒ–æ—¥é¢‘æ‰©å±•ï¼Œæ•°æ®å½¢çŠ¶: {factor_data.shape}")
        
        # åˆå¹¶è´¢æŠ¥æ•°æ®å’Œå‘å¸ƒæ—¥æœŸ
        factor_with_release = factor_data.join(release_dates[['ReleasedDates']], how='inner')
        
        if factor_with_release.empty:
            logger.warning("åˆå¹¶åæ•°æ®ä¸ºç©ºï¼Œè¯·æ£€æŸ¥ç´¢å¼•å¯¹é½")
            return pd.DataFrame()
        
        # é‡ç½®ç´¢å¼•ï¼Œä¾¿äºå¤„ç†
        factor_reset = factor_with_release.reset_index()
        
        # æŒ‰å‘å¸ƒæ—¥æœŸæ’åºï¼Œç¡®ä¿æ•°æ®çš„æ—¶é—´é¡ºåº
        factor_sorted = factor_reset.sort_values(['StockCodes', 'ReleasedDates', 'ReportDates'])
        
        # è·å–æ‰€æœ‰å”¯ä¸€çš„è‚¡ç¥¨ä»£ç 
        stock_codes = factor_sorted['StockCodes'].unique()
        
        # åˆ›å»ºç»“æœå®¹å™¨
        results = []
        
        # é¢„è®¡ç®—äº¤æ˜“æ—¥æœŸçš„ç´¢å¼•æ˜ å°„ï¼Œæé«˜æŸ¥æ‰¾æ•ˆç‡
        trading_dates_index = pd.Series(
            range(len(trading_dates)), 
            index=trading_dates
        )
        
        # æ‰¹é‡å¤„ç†è‚¡ç¥¨
        for stock_code in stock_codes:
            stock_data = factor_sorted[factor_sorted['StockCodes'] == stock_code].copy()
            
            if stock_data.empty:
                continue
                
            # ä¸ºè¯¥è‚¡ç¥¨åˆ›å»ºæ—¥é¢‘æ•°æ®æ¡†æ¶
            daily_result = pd.DataFrame(
                index=trading_dates,
                columns=factor_data.columns,
                dtype=float
            )
            
            # ä½¿ç”¨å‘é‡åŒ–æ–¹æ³•å¡«å……æ•°æ®
            daily_result = OptimizedTimeSeriesProcessor._fill_daily_data_vectorized(
                daily_result, stock_data, trading_dates_index
            )
            
            # æ·»åŠ è‚¡ç¥¨ä»£ç 
            daily_result['StockCodes'] = stock_code
            results.append(daily_result)
        
        if not results:
            logger.warning("æ²¡æœ‰ç”Ÿæˆä»»ä½•ç»“æœæ•°æ®")
            return pd.DataFrame()
        
        # åˆå¹¶æ‰€æœ‰è‚¡ç¥¨çš„æ•°æ®
        expanded = pd.concat(results, ignore_index=False)
        
        # è®¾ç½®MultiIndex
        expanded = expanded.reset_index()
        expanded = expanded.rename(columns={'index': 'TradingDates'})
        expanded = expanded.set_index(['TradingDates', 'StockCodes'])
        
        # å¦‚æœåªæœ‰ä¸€åˆ—ï¼Œè¿”å›Series
        if len(expanded.columns) == 1:
            result = expanded.iloc[:, 0]
        else:
            result = expanded
            
        logger.debug(f"å®Œæˆå‘é‡åŒ–æ—¥é¢‘æ‰©å±•ï¼Œç»“æœå½¢çŠ¶: {result.shape}")
        return result
    
    @staticmethod
    def _fill_daily_data_vectorized(daily_result: pd.DataFrame, 
                                   stock_data: pd.DataFrame,
                                   trading_dates_index: pd.Series) -> pd.DataFrame:
        """
        ä½¿ç”¨å‘é‡åŒ–æ–¹æ³•å¡«å……å•ä¸ªè‚¡ç¥¨çš„æ—¥é¢‘æ•°æ®
        
        Parameters:
        -----------
        daily_result : å¾…å¡«å……çš„æ—¥é¢‘DataFrame
        stock_data : å•ä¸ªè‚¡ç¥¨çš„è´¢æŠ¥æ•°æ®
        trading_dates_index : äº¤æ˜“æ—¥æœŸç´¢å¼•æ˜ å°„
        
        Returns:
        --------
        å¡«å……åçš„æ—¥é¢‘æ•°æ®
        """
        # ğŸ”¥ ä¿®å¤ï¼šæ­£ç¡®å¤„ç†éäº¤æ˜“æ—¥å‘å¸ƒçš„è´¢æŠ¥
        # ä¸å†è¿‡æ»¤å‘å¸ƒæ—¥æœŸï¼Œè€Œæ˜¯ä½¿ç”¨è¾…åŠ©å‡½æ•°æ‰¾åˆ°ç”Ÿæ•ˆäº¤æ˜“æ—¥
        
        # ä¸ºæ¯ä¸ªå‘å¸ƒæ—¥æœŸåˆ›å»ºæ©ç 
        for _, row in stock_data.iterrows():
            release_date = row['ReleasedDates']
            
            # è·å–ç”Ÿæ•ˆäº¤æ˜“æ—¥ï¼šå‘å¸ƒæ—¥æœ¬èº«æˆ–ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥
            effective_date = OptimizedTimeSeriesProcessor._get_effective_trading_date(
                release_date, trading_dates_index.index
            )
            
            if effective_date is None:
                continue  # æ²¡æœ‰åç»­äº¤æ˜“æ—¥ï¼Œè·³è¿‡
                
            # æ‰¾åˆ°ç”Ÿæ•ˆæ—¥æœŸä¹‹åçš„æ‰€æœ‰äº¤æ˜“æ—¥ç´¢å¼•
            effective_idx = trading_dates_index.get(effective_date)
            if effective_idx is None:
                continue
                
            # ä½¿ç”¨å¸ƒå°”ç´¢å¼•æ‰¹é‡æ›´æ–°
            mask = trading_dates_index >= effective_idx
            valid_dates = trading_dates_index.index[mask]
            
            # æ‰¹é‡å¡«å……æ‰€æœ‰å› å­åˆ—
            for col in daily_result.columns:
                if col in row and pd.notna(row[col]):
                    daily_result.loc[valid_dates, col] = row[col]
        
        return daily_result
    
    @staticmethod
    def expand_to_daily_memory_efficient(factor_data: pd.DataFrame,
                                       release_dates: pd.DataFrame,
                                       trading_dates: pd.DatetimeIndex,
                                       chunk_size: int = 100) -> pd.DataFrame:
        """
        å†…å­˜é«˜æ•ˆçš„æ—¥é¢‘æ‰©å±•æ–¹æ³•ï¼Œé€‚ç”¨äºå¤§æ•°æ®é›†
        
        Parameters:
        -----------
        factor_data : è´¢æŠ¥å› å­æ•°æ®
        release_dates : è´¢æŠ¥å‘å¸ƒæ—¥æœŸ
        trading_dates : äº¤æ˜“æ—¥åºåˆ—
        chunk_size : æ‰¹å¤„ç†å¤§å°
        
        Returns:
        --------
        æ—¥é¢‘å› å­æ•°æ®
        """
        logger.debug(f"å¼€å§‹å†…å­˜é«˜æ•ˆæ—¥é¢‘æ‰©å±•ï¼Œå—å¤§å°: {chunk_size}")
        
        # åˆå¹¶æ•°æ®
        factor_with_release = factor_data.join(release_dates[['ReleasedDates']], how='inner')
        factor_reset = factor_with_release.reset_index()
        factor_sorted = factor_reset.sort_values(['StockCodes', 'ReleasedDates', 'ReportDates'])
        
        # è·å–è‚¡ç¥¨ä»£ç å¹¶åˆ†å—å¤„ç†
        stock_codes = factor_sorted['StockCodes'].unique()
        
        results = []
        
        # åˆ†å—å¤„ç†è‚¡ç¥¨
        for i in range(0, len(stock_codes), chunk_size):
            chunk_stocks = stock_codes[i:i + chunk_size]
            logger.debug(f"å¤„ç†è‚¡ç¥¨å— {i//chunk_size + 1}/{(len(stock_codes)-1)//chunk_size + 1}")
            
            chunk_data = factor_sorted[factor_sorted['StockCodes'].isin(chunk_stocks)]
            
            # å¯¹è¯¥å—ä½¿ç”¨å‘é‡åŒ–æ–¹æ³•
            chunk_result = OptimizedTimeSeriesProcessor._process_stock_chunk(
                chunk_data, trading_dates, factor_data.columns
            )
            
            if not chunk_result.empty:
                results.append(chunk_result)
            
            # å¼ºåˆ¶åƒåœ¾å›æ”¶ä»¥é‡Šæ”¾å†…å­˜
            del chunk_data
            
        if not results:
            return pd.DataFrame()
        
        # åˆå¹¶ç»“æœ
        final_result = pd.concat(results, ignore_index=False)
        
        # è®¾ç½®ç´¢å¼•
        if 'TradingDates' not in final_result.index.names:
            final_result = final_result.reset_index()
            final_result = final_result.rename(columns={'index': 'TradingDates'})
            final_result = final_result.set_index(['TradingDates', 'StockCodes'])
        
        logger.debug(f"å®Œæˆå†…å­˜é«˜æ•ˆæ—¥é¢‘æ‰©å±•ï¼Œç»“æœå½¢çŠ¶: {final_result.shape}")
        return final_result
    
    @staticmethod
    def _process_stock_chunk(chunk_data: pd.DataFrame,
                           trading_dates: pd.DatetimeIndex,
                           factor_columns: pd.Index) -> pd.DataFrame:
        """
        å¤„ç†å•ä¸ªè‚¡ç¥¨å—
        
        Parameters:
        -----------
        chunk_data : è‚¡ç¥¨å—æ•°æ®
        trading_dates : äº¤æ˜“æ—¥åºåˆ—
        factor_columns : å› å­åˆ—å
        
        Returns:
        --------
        å¤„ç†åçš„æ—¥é¢‘æ•°æ®
        """
        chunk_results = []
        
        for stock_code, stock_data in chunk_data.groupby('StockCodes'):
            # åˆ›å»ºè¯¥è‚¡ç¥¨çš„æ—¥é¢‘æ¡†æ¶
            daily_data = pd.DataFrame(
                index=trading_dates,
                columns=factor_columns,
                dtype=float
            )
            
            # ğŸ¯ ä¼˜åŒ–çš„å¡«å……é€»è¾‘ - é¿å…é‡å¤è¦†ç›–
            # æŒ‰å‘å¸ƒæ—¥æœŸæ’åºï¼Œç¡®ä¿æŒ‰æ—¶é—´é¡ºåºå¤„ç†
            stock_data_sorted = stock_data.sort_values('ReleasedDates')
            
            for i, (_, row) in enumerate(stock_data_sorted.iterrows()):
                release_date = row['ReleasedDates']
                
                # ğŸ”¥ ä¿®å¤ï¼šæ­£ç¡®å¤„ç†éäº¤æ˜“æ—¥å‘å¸ƒçš„è´¢æŠ¥
                effective_date = OptimizedTimeSeriesProcessor._get_effective_trading_date(
                    release_date, trading_dates
                )
                
                if effective_date is not None:
                    # ğŸ”¥ å…³é”®æ”¹è¿›ï¼šä½¿ç”¨åŒºé—´èµ‹å€¼ï¼Œé¿å…é‡å¤è¦†ç›–
                    if i < len(stock_data_sorted) - 1:
                        next_release_date = stock_data_sorted.iloc[i + 1]['ReleasedDates']
                        next_effective_date = OptimizedTimeSeriesProcessor._get_effective_trading_date(
                            next_release_date, trading_dates
                        )
                        if next_effective_date is not None:
                            mask = (trading_dates >= effective_date) & (trading_dates < next_effective_date)
                        else:
                            mask = trading_dates >= effective_date
                    else:
                        mask = trading_dates >= effective_date
                    
                    for col in factor_columns:
                        if col in row and pd.notna(row[col]):
                            daily_data.loc[mask, col] = row[col]
            
            daily_data['StockCodes'] = stock_code
            chunk_results.append(daily_data)
        
        if chunk_results:
            return pd.concat(chunk_results, ignore_index=False)
        else:
            return pd.DataFrame()
    
    @staticmethod
    def benchmark_expand_methods(factor_data: pd.DataFrame,
                               release_dates: pd.DataFrame,
                               trading_dates: pd.DatetimeIndex) -> dict:
        """
        å¯¹ä¸åŒæ‰©å±•æ–¹æ³•è¿›è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•
        
        Returns:
        --------
        åŸºå‡†æµ‹è¯•ç»“æœå­—å…¸
        """
        import time
        from ..base.time_series_processor import TimeSeriesProcessor
        
        results = {}
        
        # æµ‹è¯•åŸå§‹æ–¹æ³•
        try:
            start_time = time.time()
            original_result = TimeSeriesProcessor.expand_to_daily(
                factor_data, release_dates, trading_dates
            )
            original_time = time.time() - start_time
            results['original'] = {
                'time': original_time,
                'shape': original_result.shape if hasattr(original_result, 'shape') else None,
                'success': True
            }
        except Exception as e:
            results['original'] = {
                'time': None,
                'shape': None,
                'success': False,
                'error': str(e)
            }
        
        # æµ‹è¯•å‘é‡åŒ–æ–¹æ³•
        try:
            start_time = time.time()
            vectorized_result = OptimizedTimeSeriesProcessor.expand_to_daily_vectorized(
                factor_data, release_dates, trading_dates
            )
            vectorized_time = time.time() - start_time
            results['vectorized'] = {
                'time': vectorized_time,
                'shape': vectorized_result.shape if hasattr(vectorized_result, 'shape') else None,
                'success': True
            }
        except Exception as e:
            results['vectorized'] = {
                'time': None,
                'shape': None,
                'success': False,
                'error': str(e)
            }
        
        # æµ‹è¯•å†…å­˜é«˜æ•ˆæ–¹æ³•
        try:
            start_time = time.time()
            memory_result = OptimizedTimeSeriesProcessor.expand_to_daily_memory_efficient(
                factor_data, release_dates, trading_dates
            )
            memory_time = time.time() - start_time
            results['memory_efficient'] = {
                'time': memory_time,
                'shape': memory_result.shape if hasattr(memory_result, 'shape') else None,
                'success': True
            }
        except Exception as e:
            results['memory_efficient'] = {
                'time': None,
                'shape': None,
                'success': False,
                'error': str(e)
            }
        
        return results