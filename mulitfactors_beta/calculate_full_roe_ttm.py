#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å…¨é‡ROE_ttmå› å­è®¡ç®—è„šæœ¬
å¿«é€Ÿè®¡ç®—æ‰€æœ‰è‚¡ç¥¨çš„ROE_ttmå› å­å¹¶ç»Ÿè®¡è€—æ—¶
"""
import pandas as pd
import numpy as np
from pathlib import Path
import sys
import logging
import time
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from factors.financial.fundamental_factors import ROEFactor

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def load_data():
    """åŠ è½½æ‰€éœ€æ•°æ®"""
    print("=" * 60)
    print("å…¨é‡ROE_ttmå› å­è®¡ç®—")
    print(f"å¼€å§‹æ—¶é—´: {datetime.now()}")
    print("=" * 60)
    
    data_load_start = time.time()
    
    # æ•°æ®è·¯å¾„
    data_path = Path(r"E:\Documents\PythonProject\StockProject\StockData")
    auxiliary_path = project_root / "data" / "auxiliary"
    
    print(f"\nğŸ“‚ æ•°æ®åŠ è½½é˜¶æ®µ:")
    
    data = {}
    
    try:
        # åŠ è½½è´¢åŠ¡æ•°æ®
        print(f"   æ­£åœ¨åŠ è½½è´¢åŠ¡æ•°æ®...")
        start = time.time()
        financial_path = auxiliary_path / "FinancialData_unified.pkl"
        if financial_path.exists():
            data['financial_data'] = pd.read_pickle(financial_path)
            elapsed = time.time() - start
            print(f"   âœ… è´¢åŠ¡æ•°æ®: {data['financial_data'].shape} (è€—æ—¶: {elapsed:.2f}ç§’)")
        else:
            print(f"   âŒ è´¢åŠ¡æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {financial_path}")
            return None
        
        # åŠ è½½å‘å¸ƒæ—¥æœŸ
        print(f"   æ­£åœ¨åŠ è½½å‘å¸ƒæ—¥æœŸ...")
        start = time.time()
        release_path = auxiliary_path / "ReleaseDates.pkl"
        if release_path.exists():
            data['release_dates'] = pd.read_pickle(release_path)
            elapsed = time.time() - start
            print(f"   âœ… å‘å¸ƒæ—¥æœŸ: {data['release_dates'].shape} (è€—æ—¶: {elapsed:.2f}ç§’)")
        else:
            print(f"   âŒ å‘å¸ƒæ—¥æœŸæ–‡ä»¶ä¸å­˜åœ¨: {release_path}")
            return None
        
        # åŠ è½½äº¤æ˜“æ—¥
        print(f"   æ­£åœ¨åŠ è½½äº¤æ˜“æ—¥...")
        start = time.time()
        trading_path = auxiliary_path / "TradingDates.pkl"
        if trading_path.exists():
            data['trading_dates'] = pd.read_pickle(trading_path)
            elapsed = time.time() - start
            print(f"   âœ… äº¤æ˜“æ—¥: {len(data['trading_dates'])} ä¸ª (è€—æ—¶: {elapsed:.2f}ç§’)")
        else:
            print(f"   âŒ äº¤æ˜“æ—¥æ–‡ä»¶ä¸å­˜åœ¨: {trading_path}")
            return None
        
        data_load_elapsed = time.time() - data_load_start
        print(f"\nğŸ“Š æ•°æ®åŠ è½½æ€»è€—æ—¶: {data_load_elapsed:.2f}ç§’")
        
        return data
        
    except Exception as e:
        print(f"   âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return None


def analyze_data_scale(data):
    """åˆ†ææ•°æ®è§„æ¨¡"""
    print(f"\nğŸ“Š æ•°æ®è§„æ¨¡åˆ†æ:")
    
    # åˆ†æè´¢åŠ¡æ•°æ®
    financial_data = data['financial_data']
    stocks = financial_data.index.get_level_values('StockCodes').unique()
    report_dates = financial_data.index.get_level_values('ReportDates').unique()
    
    print(f"   è‚¡ç¥¨æ•°é‡: {len(stocks):,}")
    print(f"   æŠ¥å‘ŠæœŸæ•°é‡: {len(report_dates):,}")
    print(f"   è´¢åŠ¡æ•°æ®è®°å½•: {len(financial_data):,}")
    
    # åˆ†ææ—¶é—´èŒƒå›´
    trading_dates = data['trading_dates']
    print(f"   äº¤æ˜“æ—¥èŒƒå›´: {trading_dates.min()} è‡³ {trading_dates.max()}")
    print(f"   äº¤æ˜“æ—¥æ•°é‡: {len(trading_dates):,}")
    
    # ä¼°ç®—è®¡ç®—é‡
    estimated_factor_points = len(stocks) * len(trading_dates)
    print(f"   é¢„ä¼°å› å­æ•°æ®ç‚¹: {estimated_factor_points:,}")
    
    return len(stocks), len(trading_dates), estimated_factor_points


def calculate_full_roe_ttm(data, save_results=True):
    """è®¡ç®—å…¨é‡ROE_ttmå› å­"""
    print(f"\nğŸ”§ å› å­è®¡ç®—é˜¶æ®µ:")
    
    calc_start = time.time()
    
    try:
        # åˆ›å»ºROEå› å­å®ä¾‹
        print(f"   åˆ›å»ºROE_ttmå› å­å®ä¾‹...")
        factor_start = time.time()
        roe_factor = ROEFactor(earnings_method='ttm')
        factor_elapsed = time.time() - factor_start
        print(f"   âœ… ROEå› å­åˆ›å»ºæˆåŠŸ (è€—æ—¶: {factor_elapsed:.3f}ç§’)")
        
        # æ‰§è¡Œè®¡ç®—
        print(f"   å¼€å§‹å…¨é‡è®¡ç®—ROE_ttm...")
        print(f"   â±ï¸  è®¡ç®—å¼€å§‹æ—¶é—´: {datetime.now().strftime('%H:%M:%S')}")
        
        calculate_start = time.time()
        
        roe_values = roe_factor.calculate(
            financial_data=data['financial_data'],
            release_dates=data['release_dates'],
            trading_dates=data['trading_dates']
        )
        
        calculate_elapsed = time.time() - calculate_start
        print(f"   âœ… ROE_ttmè®¡ç®—å®Œæˆ!")
        print(f"   â±ï¸  è®¡ç®—ç»“æŸæ—¶é—´: {datetime.now().strftime('%H:%M:%S')}")
        print(f"   â±ï¸  çº¯è®¡ç®—è€—æ—¶: {calculate_elapsed:.2f}ç§’")
        
        # åˆ†æç»“æœ
        print(f"\nğŸ“ˆ è®¡ç®—ç»“æœåˆ†æ:")
        print(f"   ç»“æœæ•°æ®ç‚¹: {len(roe_values):,}")
        print(f"   æœ‰æ•ˆå€¼æ•°é‡: {roe_values.count():,}")
        print(f"   æœ‰æ•ˆç‡: {roe_values.count() / len(roe_values) * 100:.2f}%")
        print(f"   å‡å€¼: {roe_values.mean():.6f}")
        print(f"   æ ‡å‡†å·®: {roe_values.std():.6f}")
        print(f"   ä¸­ä½æ•°: {roe_values.median():.6f}")
        print(f"   èŒƒå›´: [{roe_values.min():.6f}, {roe_values.max():.6f}]")
        
        # åˆ†ä½æ•°åˆ†æ
        quantiles = roe_values.quantile([0.01, 0.05, 0.25, 0.75, 0.95, 0.99])
        print(f"\n   åˆ†ä½æ•°åˆ†å¸ƒ:")
        for q, val in quantiles.items():
            print(f"      {q*100:4.0f}%: {val:.6f}")
        
        # ä¿å­˜ç»“æœ
        if save_results:
            print(f"\nğŸ’¾ ä¿å­˜ç»“æœ:")
            save_start = time.time()
            
            output_path = project_root / "factor_output"
            output_path.mkdir(exist_ok=True)
            
            # ä¿å­˜ä¸ºpickleæ ¼å¼ï¼ˆæ¨èï¼Œé€Ÿåº¦å¿«ï¼‰
            pkl_file = output_path / f"ROE_ttm_full_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl"
            roe_values.to_pickle(pkl_file)
            
            # ä¿å­˜ä¸ºCSVæ ¼å¼ï¼ˆå¯è¯»æ€§å¥½ï¼‰
            csv_file = output_path / f"ROE_ttm_full_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
            roe_values.to_csv(csv_file)
            
            save_elapsed = time.time() - save_start
            file_size_pkl = pkl_file.stat().st_size / 1024 / 1024  # MB
            file_size_csv = csv_file.stat().st_size / 1024 / 1024  # MB
            
            print(f"   âœ… PKLæ–‡ä»¶: {pkl_file}")
            print(f"      æ–‡ä»¶å¤§å°: {file_size_pkl:.1f} MB")
            print(f"   âœ… CSVæ–‡ä»¶: {csv_file}")
            print(f"      æ–‡ä»¶å¤§å°: {file_size_csv:.1f} MB")
            print(f"   ğŸ’¾ ä¿å­˜è€—æ—¶: {save_elapsed:.2f}ç§’")
        
        calc_elapsed = time.time() - calc_start
        return roe_values, calculate_elapsed, calc_elapsed
        
    except Exception as e:
        print(f"   âŒ ROE_ttmè®¡ç®—å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None, 0, 0


def performance_summary(data_load_time, pure_calc_time, total_calc_time, factor_points):
    """æ€§èƒ½æ€»ç»“"""
    print(f"\n" + "=" * 60)
    print("æ€§èƒ½ç»Ÿè®¡æ€»ç»“")
    print("=" * 60)
    
    total_time = data_load_time + total_calc_time
    
    print(f"â±ï¸  æ—¶é—´ç»Ÿè®¡:")
    print(f"   æ•°æ®åŠ è½½æ—¶é—´: {data_load_time:.2f}ç§’")
    print(f"   çº¯å› å­è®¡ç®—æ—¶é—´: {pure_calc_time:.2f}ç§’")
    print(f"   æ€»è®¡ç®—æ—¶é—´(å«ä¿å­˜): {total_calc_time:.2f}ç§’")
    print(f"   ç¨‹åºæ€»è€—æ—¶: {total_time:.2f}ç§’ ({total_time/60:.1f}åˆ†é’Ÿ)")
    
    print(f"\nğŸš€ æ€§èƒ½æŒ‡æ ‡:")
    if factor_points > 0 and pure_calc_time > 0:
        calc_rate = factor_points / pure_calc_time
        print(f"   å› å­è®¡ç®—é€Ÿåº¦: {calc_rate:,.0f} ç‚¹/ç§’")
        print(f"   å› å­è®¡ç®—é€Ÿåº¦: {calc_rate * 60:,.0f} ç‚¹/åˆ†é’Ÿ")
        
        if calc_rate > 100000:
            performance_level = "ğŸ”¥ æå¿«"
        elif calc_rate > 50000:
            performance_level = "âš¡ å¾ˆå¿«"
        elif calc_rate > 10000:
            performance_level = "âœ… è‰¯å¥½"
        else:
            performance_level = "ğŸŒ è¾ƒæ…¢"
            
        print(f"   æ€§èƒ½è¯„çº§: {performance_level}")
    
    print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
    if pure_calc_time > 60:
        print(f"   - è€ƒè™‘ä½¿ç”¨å¹¶è¡Œè®¡ç®—åŠ é€Ÿ")
        print(f"   - å¯ä»¥åˆ†æ‰¹è®¡ç®—å¤§å‹æ•°æ®é›†")
    if data_load_time > pure_calc_time:
        print(f"   - æ•°æ®åŠ è½½å ç”¨è¾ƒå¤šæ—¶é—´ï¼Œè€ƒè™‘ä¼˜åŒ–æ•°æ®æ ¼å¼")
    
    return total_time


def main():
    """ä¸»å‡½æ•°"""
    program_start = time.time()
    
    # 1. åŠ è½½æ•°æ®
    data = load_data()
    if data is None:
        print("âŒ æ•°æ®åŠ è½½å¤±è´¥ï¼Œç¨‹åºé€€å‡º")
        return
    
    data_load_time = time.time() - program_start
    
    # 2. åˆ†ææ•°æ®è§„æ¨¡
    stock_count, trading_days, estimated_points = analyze_data_scale(data)
    
    # 3. è¯¢é—®ç”¨æˆ·ç¡®è®¤
    print(f"\nâ“ ç¡®è®¤ä¿¡æ¯:")
    print(f"   é¢„ä¼°è®¡ç®— {estimated_points:,} ä¸ªå› å­æ•°æ®ç‚¹")
    estimated_time = estimated_points / 50000  # å‡è®¾æ¯ç§’5ä¸‡ç‚¹
    print(f"   é¢„ä¼°è€—æ—¶: {estimated_time:.1f}ç§’ ({estimated_time/60:.1f}åˆ†é’Ÿ)")
    
    print(f"\nè‡ªåŠ¨å¼€å§‹å…¨é‡è®¡ç®—ROE_ttm...")
    # confirm = input(f"\næ˜¯å¦ç»§ç»­å…¨é‡è®¡ç®—ROE_ttm? (Y/n): ").strip().lower()
    # if confirm == 'n':
    #     print("ç”¨æˆ·å–æ¶ˆï¼Œç¨‹åºé€€å‡º")
    #     return
    
    # 4. æ‰§è¡Œè®¡ç®—
    roe_values, pure_calc_time, total_calc_time = calculate_full_roe_ttm(data, save_results=True)
    
    if roe_values is not None:
        # 5. æ€§èƒ½æ€»ç»“
        actual_points = len(roe_values)
        performance_summary(data_load_time, pure_calc_time, total_calc_time, actual_points)
        
        print(f"\nğŸ‰ å…¨é‡ROE_ttmå› å­è®¡ç®—å®Œæˆ!")
        print(f"ğŸ“Š å®é™…è®¡ç®—äº† {actual_points:,} ä¸ªæ•°æ®ç‚¹")
        print(f"â±ï¸  æ€»è€—æ—¶: {(time.time() - program_start):.2f}ç§’")
    else:
        print(f"\nâŒ è®¡ç®—å¤±è´¥")


if __name__ == "__main__":
    main()