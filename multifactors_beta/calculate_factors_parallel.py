#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¹¶è¡Œå› å­è®¡ç®—è„šæœ¬
æ”¯æŒå¤šç§å› å­çš„å¿«é€Ÿå¹¶è¡Œè®¡ç®—
"""
import pandas as pd
import numpy as np
from pathlib import Path
import sys
import logging
import time
from datetime import datetime
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed
import multiprocessing as mp

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from factors.financial.fundamental_factors import ROEFactor, BPFactor, EPFactor
from factors.calculator.factor_calculator import FactorCalculator

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def load_all_data():
    """åŠ è½½å…¨éƒ¨æ•°æ®"""
    print("=" * 60)
    print("å¹¶è¡Œå› å­è®¡ç®—")
    print(f"å¼€å§‹æ—¶é—´: {datetime.now()}")
    print("=" * 60)
    
    data_load_start = time.time()
    
    data_path = Path(r"E:\Documents\PythonProject\StockProject\StockData")
    auxiliary_path = project_root / "data" / "auxiliary"
    
    print(f"\nğŸ“‚ æ•°æ®åŠ è½½:")
    
    data = {}
    file_info = {
        'financial_data': auxiliary_path / "FinancialData_unified.pkl",
        'release_dates': auxiliary_path / "ReleaseDates.pkl", 
        'trading_dates': auxiliary_path / "TradingDates.pkl",
        'market_cap': data_path / "MarketCap.pkl"
    }
    
    for name, filepath in file_info.items():
        if filepath.exists():
            start = time.time()
            data[name] = pd.read_pickle(filepath)
            elapsed = time.time() - start
            
            if hasattr(data[name], 'shape'):
                size_info = f"{data[name].shape}"
            else:
                size_info = f"é•¿åº¦: {len(data[name])}"
            
            print(f"   âœ… {name}: {size_info} ({elapsed:.2f}ç§’)")
        else:
            print(f"   âŒ {name}: æ–‡ä»¶ä¸å­˜åœ¨")
            return None
    
    # å¤„ç†å¸‚å€¼æ•°æ®æ ¼å¼
    if 'market_cap' in data and isinstance(data['market_cap'], pd.DataFrame):
        data['market_cap'] = data['market_cap'].iloc[:, 0]
    
    data_load_elapsed = time.time() - data_load_start
    print(f"\nğŸ“Š æ•°æ®åŠ è½½æ€»è€—æ—¶: {data_load_elapsed:.2f}ç§’")
    
    return data, data_load_elapsed


def analyze_computation_scale(data):
    """åˆ†æè®¡ç®—è§„æ¨¡"""
    print(f"\nğŸ“Š è®¡ç®—è§„æ¨¡åˆ†æ:")
    
    financial_data = data['financial_data']
    stocks = financial_data.index.get_level_values('StockCodes').unique()
    trading_dates = data['trading_dates']
    
    print(f"   è‚¡ç¥¨æ•°é‡: {len(stocks):,}")
    print(f"   äº¤æ˜“æ—¥æ•°é‡: {len(trading_dates):,}")
    print(f"   é¢„ä¼°å› å­ç‚¹æ•°: {len(stocks) * len(trading_dates):,}")
    
    return len(stocks), len(trading_dates)


def calculate_single_factor(factor_config):
    """è®¡ç®—å•ä¸ªå› å­çš„å‡½æ•°ï¼ˆç”¨äºå¹¶è¡Œï¼‰"""
    factor_name, factor_class, params, data = factor_config
    
    try:
        print(f"   ğŸ”§ å¼€å§‹è®¡ç®— {factor_name}...")
        start_time = time.time()
        
        # åˆ›å»ºå› å­å®ä¾‹
        if params:
            factor = factor_class(**params)
        else:
            factor = factor_class()
        
        # æ ¹æ®å› å­ç±»å‹å‡†å¤‡å‚æ•°
        calc_params = {}
        
        # åŸºæœ¬é¢å› å­é€šå¸¸éœ€è¦è¿™äº›æ•°æ®
        if hasattr(factor, 'category') and factor.category == 'fundamental':
            calc_params['financial_data'] = data['financial_data']
            calc_params['release_dates'] = data['release_dates']
            calc_params['trading_dates'] = data['trading_dates']
            
            # EPå’ŒBPå› å­è¿˜éœ€è¦å¸‚å€¼æ•°æ®
            if factor_name.startswith('EP') or factor_name.startswith('BP'):
                calc_params['market_cap'] = data['market_cap']
        
        # è®¡ç®—å› å­
        result = factor.calculate(**calc_params)
        
        elapsed = time.time() - start_time
        print(f"   âœ… {factor_name} å®Œæˆ: {len(result):,}ç‚¹, {result.count():,}æœ‰æ•ˆ ({elapsed:.2f}ç§’)")
        
        return factor_name, result, elapsed, None
        
    except Exception as e:
        elapsed = time.time() - start_time if 'start_time' in locals() else 0
        print(f"   âŒ {factor_name} å¤±è´¥: {e} ({elapsed:.2f}ç§’)")
        return factor_name, None, elapsed, str(e)


def calculate_factors_parallel(data, factor_configs, max_workers=None):
    """å¹¶è¡Œè®¡ç®—å¤šä¸ªå› å­"""
    print(f"\nğŸš€ å¹¶è¡Œå› å­è®¡ç®—:")
    
    if max_workers is None:
        max_workers = max(1, mp.cpu_count() - 1)
    
    print(f"   å¹¶è¡Œå·¥ä½œè¿›ç¨‹: {max_workers}")
    print(f"   è®¡ç®—å› å­æ•°é‡: {len(factor_configs)}")
    
    calc_start = time.time()
    results = {}
    timing_info = {}
    errors = {}
    
    # å‡†å¤‡è®¡ç®—é…ç½®ï¼ˆæ·»åŠ æ•°æ®ï¼‰
    calc_configs = []
    for name, factor_class, params in factor_configs:
        calc_configs.append((name, factor_class, params, data))
    
    # ä½¿ç”¨çº¿ç¨‹æ± ï¼ˆå› ä¸ºä¸»è¦æ˜¯è®¡ç®—å¯†é›†å‹ï¼Œä½†é¿å…è¿›ç¨‹é—´æ•°æ®ä¼ è¾“å¼€é”€ï¼‰
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_factor = {
            executor.submit(calculate_single_factor, config): config[0] 
            for config in calc_configs
        }
        
        # æ”¶é›†ç»“æœ
        for future in as_completed(future_to_factor):
            factor_name = future_to_factor[future]
            try:
                name, result, elapsed, error = future.result()
                
                timing_info[name] = elapsed
                
                if result is not None:
                    results[name] = result
                else:
                    errors[name] = error
                    
            except Exception as e:
                errors[factor_name] = str(e)
                print(f"   âŒ {factor_name} æ‰§è¡Œå¼‚å¸¸: {e}")
    
    calc_elapsed = time.time() - calc_start
    
    # ç»Ÿè®¡ç»“æœ
    print(f"\nğŸ“ˆ å¹¶è¡Œè®¡ç®—ç»“æœ:")
    print(f"   æ€»è€—æ—¶: {calc_elapsed:.2f}ç§’")
    print(f"   æˆåŠŸå› å­: {len(results)}")
    print(f"   å¤±è´¥å› å­: {len(errors)}")
    
    if results:
        avg_time = sum(timing_info[name] for name in results.keys()) / len(results)
        print(f"   å¹³å‡å•å› å­è€—æ—¶: {avg_time:.2f}ç§’")
        
        total_points = sum(len(result) for result in results.values())
        print(f"   æ€»å› å­æ•°æ®ç‚¹: {total_points:,}")
        
        if calc_elapsed > 0:
            calc_rate = total_points / calc_elapsed
            print(f"   æ•´ä½“è®¡ç®—é€Ÿåº¦: {calc_rate:,.0f} ç‚¹/ç§’")
    
    if errors:
        print(f"\nâŒ è®¡ç®—å¤±è´¥çš„å› å­:")
        for name, error in errors.items():
            print(f"   - {name}: {error}")
    
    return results, timing_info, errors, calc_elapsed


def save_results(results, timing_info):
    """ä¿å­˜è®¡ç®—ç»“æœ"""
    print(f"\nğŸ’¾ ä¿å­˜ç»“æœ:")
    
    save_start = time.time()
    output_path = project_root / "factor_output"
    output_path.mkdir(exist_ok=True)
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    saved_files = []
    
    for factor_name, factor_data in results.items():
        # ä¿å­˜å•ä¸ªå› å­
        pkl_file = output_path / f"{factor_name}_{timestamp}.pkl"
        factor_data.to_pickle(pkl_file)
        
        file_size = pkl_file.stat().st_size / 1024 / 1024
        saved_files.append((factor_name, pkl_file, file_size))
        
        print(f"   âœ… {factor_name}: {pkl_file.name} ({file_size:.1f}MB)")
    
    # ä¿å­˜åˆå¹¶çš„å› å­æ•°æ®
    if len(results) > 1:
        combined_df = pd.DataFrame(results)
        combined_file = output_path / f"factors_combined_{timestamp}.pkl"
        combined_df.to_pickle(combined_file)
        
        combined_size = combined_file.stat().st_size / 1024 / 1024
        print(f"   âœ… åˆå¹¶æ–‡ä»¶: {combined_file.name} ({combined_size:.1f}MB)")
        
        # ä¿å­˜ç›¸å…³æ€§çŸ©é˜µ
        corr_matrix = combined_df.corr()
        corr_file = output_path / f"factor_correlation_{timestamp}.csv"
        corr_matrix.to_csv(corr_file)
        print(f"   âœ… ç›¸å…³æ€§çŸ©é˜µ: {corr_file.name}")
    
    # ä¿å­˜æ€§èƒ½ç»Ÿè®¡
    perf_file = output_path / f"performance_log_{timestamp}.csv"
    perf_df = pd.DataFrame([
        {'factor': name, 'elapsed_time': timing, 'data_points': len(results[name])}
        for name, timing in timing_info.items() if name in results
    ])
    perf_df.to_csv(perf_file, index=False)
    print(f"   âœ… æ€§èƒ½æ—¥å¿—: {perf_file.name}")
    
    save_elapsed = time.time() - save_start
    print(f"   ğŸ’¾ ä¿å­˜è€—æ—¶: {save_elapsed:.2f}ç§’")
    
    return save_elapsed


def main():
    """ä¸»å‡½æ•°"""
    program_start = time.time()
    
    # 1. åŠ è½½æ•°æ®
    data_result = load_all_data()
    if data_result is None:
        print("âŒ æ•°æ®åŠ è½½å¤±è´¥")
        return
    
    data, data_load_time = data_result
    
    # 2. åˆ†æè®¡ç®—è§„æ¨¡
    stock_count, trading_days = analyze_computation_scale(data)
    
    # 3. å®šä¹‰è¦è®¡ç®—çš„å› å­
    factor_configs = [
        ('ROE_ttm', ROEFactor, {'earnings_method': 'ttm'}),
        ('BP', BPFactor, None),
        ('EP_ttm', EPFactor, {'method': 'ttm'}),
    ]
    
    print(f"\nğŸ¯ è®¡ç®—é…ç½®:")
    for name, _, params in factor_configs:
        print(f"   - {name}: {params if params else 'é»˜è®¤å‚æ•°'}")
    
    estimated_points = stock_count * trading_days * len(factor_configs)
    estimated_time = estimated_points / 100000  # å‡è®¾æ¯ç§’10ä¸‡ç‚¹
    
    print(f"\nâ“ ç¡®è®¤ä¿¡æ¯:")
    print(f"   è®¡ç®—å› å­æ•°: {len(factor_configs)}")
    print(f"   é¢„ä¼°æ€»æ•°æ®ç‚¹: {estimated_points:,}")
    print(f"   é¢„ä¼°è€—æ—¶: {estimated_time:.1f}ç§’ ({estimated_time/60:.1f}åˆ†é’Ÿ)")
    
    confirm = input(f"\næ˜¯å¦å¼€å§‹å¹¶è¡Œè®¡ç®—? (Y/n): ").strip().lower()
    if confirm == 'n':
        print("ç”¨æˆ·å–æ¶ˆ")
        return
    
    # 4. å¹¶è¡Œè®¡ç®—å› å­
    results, timing_info, errors, calc_time = calculate_factors_parallel(
        data, factor_configs, max_workers=3
    )
    
    if not results:
        print("âŒ æ²¡æœ‰æˆåŠŸè®¡ç®—çš„å› å­")
        return
    
    # 5. ä¿å­˜ç»“æœ
    save_time = save_results(results, timing_info)
    
    # 6. æœ€ç»ˆæ€»ç»“
    total_time = time.time() - program_start
    
    print(f"\n" + "=" * 60)
    print("æœ€ç»ˆç»Ÿè®¡")
    print("=" * 60)
    print(f"â±ï¸  æ•°æ®åŠ è½½: {data_load_time:.2f}ç§’")
    print(f"â±ï¸  å› å­è®¡ç®—: {calc_time:.2f}ç§’")
    print(f"â±ï¸  ç»“æœä¿å­˜: {save_time:.2f}ç§’")
    print(f"â±ï¸  ç¨‹åºæ€»è€—æ—¶: {total_time:.2f}ç§’ ({total_time/60:.1f}åˆ†é’Ÿ)")
    
    if results:
        total_points = sum(len(result) for result in results.values())
        print(f"ğŸ“Š æˆåŠŸè®¡ç®— {len(results)} ä¸ªå› å­")
        print(f"ğŸ“Š æ€»æ•°æ®ç‚¹: {total_points:,}")
        
        if calc_time > 0:
            overall_rate = total_points / calc_time
            print(f"ğŸš€ æ•´ä½“é€Ÿåº¦: {overall_rate:,.0f} ç‚¹/ç§’")
    
    print(f"ğŸ‰ æ‰¹é‡å› å­è®¡ç®—å®Œæˆ!")


if __name__ == "__main__":
    main()