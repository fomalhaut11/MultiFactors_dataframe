#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®æ¡¥æ¥æ¨¡å—

æä¾›dataæ¨¡å—å’Œfactorsæ¨¡å—ä¹‹é—´çš„æ ‡å‡†æ•°æ®ä¼ é€’æ¥å£
ç¡®ä¿æ•°æ®æ ¼å¼çš„ä¸€è‡´æ€§å’Œå¯é æ€§

Author: MultiFactors Team
Date: 2025-08-21
"""

import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, List, Optional, Union, Any, Tuple
from datetime import datetime
import logging

from .schemas import (
    DataValidator, DataConverter, DataQualityChecker,
    DataSchemas, validate_price_data, validate_financial_data, 
    validate_factor_format, convert_to_factor_format
)
from .fetcher.data_fetcher import StockDataFetcher
from config import get_config

logger = logging.getLogger(__name__)


class DataBridge:
    """æ•°æ®æ¡¥æ¥å™¨ - dataæ¨¡å—å’Œfactorsæ¨¡å—çš„æ ‡å‡†æ¥å£"""
    
    def __init__(self, data_root: Optional[str] = None):
        """
        åˆå§‹åŒ–æ•°æ®æ¡¥æ¥å™¨
        
        Parameters
        ----------
        data_root : str, optional
            æ•°æ®æ ¹ç›®å½•è·¯å¾„
        """
        self.data_root = Path(data_root or get_config('main.paths.data_root'))
        self.auxiliary_path = self.data_root / 'auxiliary'
        self.fetcher = StockDataFetcher()
        
        # æ•°æ®ç¼“å­˜
        self._cache = {}
        self._cache_timestamps = {}
        
        logger.info(f"DataBridgeåˆå§‹åŒ–å®Œæˆï¼Œæ•°æ®è·¯å¾„: {self.data_root}")
    
    def get_financial_data(self, 
                          validate: bool = True,
                          use_cache: bool = True) -> pd.DataFrame:
        """
        è·å–æ ‡å‡†æ ¼å¼çš„è´¢åŠ¡æ•°æ®
        
        Parameters
        ----------
        validate : bool
            æ˜¯å¦éªŒè¯æ•°æ®æ ¼å¼
        use_cache : bool
            æ˜¯å¦ä½¿ç”¨ç¼“å­˜
            
        Returns
        -------
        pd.DataFrame
            éªŒè¯è¿‡çš„è´¢åŠ¡æ•°æ®
        """
        cache_key = 'financial_data'
        
        # å°è¯•ä»ç¼“å­˜è·å–
        if use_cache and cache_key in self._cache:
            logger.info("ä»ç¼“å­˜è·å–è´¢åŠ¡æ•°æ®")
            return self._cache[cache_key]
        
        # ä»æ–‡ä»¶è¯»å–
        file_path = self.auxiliary_path / 'FinancialData_unified.pkl'
        if not file_path.exists():
            raise FileNotFoundError(f"è´¢åŠ¡æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        
        logger.info(f"ä»æ–‡ä»¶è¯»å–è´¢åŠ¡æ•°æ®: {file_path}")
        data = pd.read_pickle(file_path)
        
        # æ•°æ®éªŒè¯
        if validate:
            is_valid, errors = validate_financial_data(data, strict=False)
            if not is_valid:
                logger.warning(f"è´¢åŠ¡æ•°æ®æ ¼å¼éªŒè¯å¤±è´¥: {errors}")
                # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œåªè®°å½•è­¦å‘Šï¼Œå› ä¸ºè´¢åŠ¡æ•°æ®å­—æ®µè¾ƒå¤šä¸”åŠ¨æ€
            else:
                logger.info("è´¢åŠ¡æ•°æ®æ ¼å¼éªŒè¯é€šè¿‡")
        
        # ç¼“å­˜æ•°æ®
        if use_cache:
            self._cache[cache_key] = data
            self._cache_timestamps[cache_key] = datetime.now()
        
        return data
    
    def get_price_data(self,
                      begin_date: Optional[int] = None,
                      end_date: Optional[int] = None,
                      validate: bool = True,
                      use_cache: bool = True) -> pd.DataFrame:
        """
        è·å–æ ‡å‡†æ ¼å¼çš„ä»·æ ¼æ•°æ®
        
        Parameters
        ----------
        begin_date : int, optional
            å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼å¦‚20240101
        end_date : int, optional
            ç»“æŸæ—¥æœŸï¼Œæ ¼å¼å¦‚20241231
        validate : bool
            æ˜¯å¦éªŒè¯æ•°æ®æ ¼å¼
        use_cache : bool
            æ˜¯å¦ä½¿ç”¨ç¼“å­˜
            
        Returns
        -------
        pd.DataFrame
            éªŒè¯è¿‡çš„ä»·æ ¼æ•°æ®
        """
        cache_key = f'price_data_{begin_date}_{end_date}'
        
        # å°è¯•ä»ç¼“å­˜è·å–
        if use_cache and cache_key in self._cache:
            logger.info("ä»ç¼“å­˜è·å–ä»·æ ¼æ•°æ®")
            return self._cache[cache_key]
        
        # ä»æ•°æ®è·å–å™¨è·å–
        logger.info(f"è·å–ä»·æ ¼æ•°æ®: {begin_date} åˆ° {end_date}")
        data = self.fetcher.fetch_data(
            'price', 
            begin_date=begin_date or 20200101,
            end_date=end_date or 0
        )
        
        # æ•°æ®éªŒè¯
        if validate:
            is_valid, errors = validate_price_data(data, strict=False)
            if not is_valid:
                raise ValueError(f"ä»·æ ¼æ•°æ®æ ¼å¼éªŒè¯å¤±è´¥: {errors}")
            logger.info("ä»·æ ¼æ•°æ®æ ¼å¼éªŒè¯é€šè¿‡")
        
        # ç¼“å­˜æ•°æ®
        if use_cache:
            self._cache[cache_key] = data
            self._cache_timestamps[cache_key] = datetime.now()
        
        return data
    
    def get_release_dates(self, use_cache: bool = True) -> pd.DataFrame:
        """
        è·å–è´¢æŠ¥å‘å¸ƒæ—¥æœŸæ•°æ®
        
        Parameters
        ----------
        use_cache : bool
            æ˜¯å¦ä½¿ç”¨ç¼“å­˜
            
        Returns
        -------
        pd.DataFrame
            å‘å¸ƒæ—¥æœŸæ•°æ®
        """
        cache_key = 'release_dates'
        
        # å°è¯•ä»ç¼“å­˜è·å–
        if use_cache and cache_key in self._cache:
            return self._cache[cache_key]
        
        # ä»æ–‡ä»¶è¯»å–
        file_path = self.auxiliary_path / 'ReleaseDates.pkl'
        if not file_path.exists():
            raise FileNotFoundError(f"å‘å¸ƒæ—¥æœŸæ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        
        data = pd.read_pickle(file_path)
        
        # ç¼“å­˜æ•°æ®
        if use_cache:
            self._cache[cache_key] = data
            self._cache_timestamps[cache_key] = datetime.now()
        
        return data
    
    def get_trading_dates(self, use_cache: bool = True) -> pd.Series:
        """
        è·å–äº¤æ˜“æ—¥æœŸåˆ—è¡¨
        
        Parameters
        ----------
        use_cache : bool
            æ˜¯å¦ä½¿ç”¨ç¼“å­˜
            
        Returns
        -------
        pd.Series
            äº¤æ˜“æ—¥æœŸåºåˆ—
        """
        cache_key = 'trading_dates'
        
        # å°è¯•ä»ç¼“å­˜è·å–
        if use_cache and cache_key in self._cache:
            return self._cache[cache_key]
        
        # ä»æ–‡ä»¶è¯»å–
        file_path = self.auxiliary_path / 'TradingDates.pkl'
        if not file_path.exists():
            raise FileNotFoundError(f"äº¤æ˜“æ—¥æœŸæ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        
        data = pd.read_pickle(file_path)
        
        # ç¼“å­˜æ•°æ®
        if use_cache:
            self._cache[cache_key] = data
            self._cache_timestamps[cache_key] = datetime.now()
        
        return data
    
    def get_stock_info(self, use_cache: bool = True) -> pd.DataFrame:
        """
        è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
        
        Parameters
        ----------
        use_cache : bool
            æ˜¯å¦ä½¿ç”¨ç¼“å­˜
            
        Returns
        -------
        pd.DataFrame
            è‚¡ç¥¨ä¿¡æ¯æ•°æ®
        """
        cache_key = 'stock_info'
        
        # å°è¯•ä»ç¼“å­˜è·å–
        if use_cache and cache_key in self._cache:
            return self._cache[cache_key]
        
        # ä»æ–‡ä»¶è¯»å–
        file_path = self.auxiliary_path / 'StockInfo.pkl'
        if not file_path.exists():
            raise FileNotFoundError(f"è‚¡ç¥¨ä¿¡æ¯æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        
        data = pd.read_pickle(file_path)
        
        # ç¼“å­˜æ•°æ®
        if use_cache:
            self._cache[cache_key] = data
            self._cache_timestamps[cache_key] = datetime.now()
        
        return data
    
    def price_to_factor(self,
                       value_column: str = 'c',
                       begin_date: Optional[int] = None,
                       end_date: Optional[int] = None,
                       validate_output: bool = True) -> pd.Series:
        """
        è·å–ä»·æ ¼æ•°æ®å¹¶è½¬æ¢ä¸ºæ ‡å‡†å› å­æ ¼å¼
        
        Parameters
        ----------
        value_column : str
            è¦æå–çš„ä»·æ ¼å­—æ®µ
        begin_date : int, optional
            å¼€å§‹æ—¥æœŸ
        end_date : int, optional
            ç»“æŸæ—¥æœŸ
        validate_output : bool
            æ˜¯å¦éªŒè¯è¾“å‡ºæ ¼å¼
            
        Returns
        -------
        pd.Series
            æ ‡å‡†å› å­æ ¼å¼çš„ä»·æ ¼åºåˆ—
        """
        # è·å–ä»·æ ¼æ•°æ®
        price_df = self.get_price_data(begin_date, end_date)
        
        # è½¬æ¢ä¸ºå› å­æ ¼å¼
        factor_series = convert_to_factor_format(
            price_df, 
            value_col=value_column,
            date_col='tradingday',
            stock_col='code'
        )
        
        # éªŒè¯è¾“å‡ºæ ¼å¼
        if validate_output:
            is_valid, errors = validate_factor_format(factor_series)
            if not is_valid:
                raise ValueError(f"è½¬æ¢åçš„å› å­æ ¼å¼éªŒè¯å¤±è´¥: {errors}")
            logger.info("å› å­æ ¼å¼éªŒè¯é€šè¿‡")
        
        return factor_series
    
    def financial_to_factor(self,
                           value_column: str,
                           validate_output: bool = True) -> pd.Series:
        """
        è·å–è´¢åŠ¡æ•°æ®å¹¶è½¬æ¢ä¸ºæ ‡å‡†å› å­æ ¼å¼
        
        Parameters
        ----------
        value_column : str
            è¦æå–çš„è´¢åŠ¡å­—æ®µ
        validate_output : bool
            æ˜¯å¦éªŒè¯è¾“å‡ºæ ¼å¼
            
        Returns
        -------
        pd.Series
            æ ‡å‡†å› å­æ ¼å¼çš„è´¢åŠ¡åºåˆ—
        """
        # è·å–è´¢åŠ¡æ•°æ®
        financial_df = self.get_financial_data()
        
        # æ£€æŸ¥å­—æ®µæ˜¯å¦å­˜åœ¨
        if value_column not in financial_df.columns:
            available_cols = list(financial_df.columns)
            raise ValueError(f"è´¢åŠ¡æ•°æ®ä¸­ä¸å­˜åœ¨å­—æ®µ '{value_column}'ã€‚å¯ç”¨å­—æ®µ: {available_cols[:10]}...")
        
        # è½¬æ¢ä¸ºå› å­æ ¼å¼
        factor_series = DataConverter.financial_to_factor_format(
            financial_df,
            value_column=value_column,
            date_column='reportday',
            stock_column='code'
        )
        
        # éªŒè¯è¾“å‡ºæ ¼å¼
        if validate_output:
            is_valid, errors = validate_factor_format(factor_series)
            if not is_valid:
                raise ValueError(f"è½¬æ¢åçš„å› å­æ ¼å¼éªŒè¯å¤±è´¥: {errors}")
            logger.info("å› å­æ ¼å¼éªŒè¯é€šè¿‡")
        
        return factor_series
    
    def get_data_quality_report(self, data_type: str = 'all') -> Dict[str, Any]:
        """
        è·å–æ•°æ®è´¨é‡æŠ¥å‘Š
        
        Parameters
        ----------
        data_type : str
            æ•°æ®ç±»å‹ï¼Œå¯é€‰: 'price', 'financial', 'all'
            
        Returns
        -------
        Dict[str, Any]
            æ•°æ®è´¨é‡æŠ¥å‘Š
        """
        reports = {}
        
        if data_type in ['price', 'all']:
            try:
                price_data = self.get_price_data(validate=False)
                reports['price'] = DataQualityChecker.generate_quality_report(
                    price_data, DataSchemas.PRICE_DATA
                )
            except Exception as e:
                logger.error(f"ç”Ÿæˆä»·æ ¼æ•°æ®è´¨é‡æŠ¥å‘Šå¤±è´¥: {e}")
        
        if data_type in ['financial', 'all']:
            try:
                financial_data = self.get_financial_data(validate=False)
                reports['financial'] = DataQualityChecker.generate_quality_report(
                    financial_data, DataSchemas.FINANCIAL_DATA
                )
            except Exception as e:
                logger.error(f"ç”Ÿæˆè´¢åŠ¡æ•°æ®è´¨é‡æŠ¥å‘Šå¤±è´¥: {e}")
        
        return reports
    
    def print_data_status(self):
        """æ‰“å°æ•°æ®çŠ¶æ€æ¦‚è§ˆ"""
        print("\nğŸ“Š æ•°æ®çŠ¶æ€æ¦‚è§ˆ")
        print("=" * 60)
        
        # æ£€æŸ¥å„æ•°æ®æ–‡ä»¶
        files_info = {
            'FinancialData_unified.pkl': 'è´¢åŠ¡æ•°æ®',
            'ReleaseDates.pkl': 'å‘å¸ƒæ—¥æœŸ',
            'StockInfo.pkl': 'è‚¡ç¥¨ä¿¡æ¯',
            'TradingDates.pkl': 'äº¤æ˜“æ—¥æœŸ'
        }
        
        for file_name, description in files_info.items():
            file_path = self.auxiliary_path / file_name
            if file_path.exists():
                mtime = datetime.fromtimestamp(file_path.stat().st_mtime)
                size_mb = file_path.stat().st_size / 1024 / 1024
                
                try:
                    # è¯»å–æ•°æ®è·å–åŸºæœ¬ä¿¡æ¯
                    data = pd.read_pickle(file_path)
                    if isinstance(data, pd.DataFrame):
                        shape_info = f"({data.shape[0]:,}è¡Œ, {data.shape[1]}åˆ—)"
                    elif isinstance(data, pd.Series):
                        shape_info = f"({len(data):,}é¡¹)"
                    else:
                        shape_info = "æœªçŸ¥æ ¼å¼"
                    
                    print(f"âœ… {description}: {shape_info}")
                    print(f"   æ›´æ–°æ—¶é—´: {mtime.strftime('%Y-%m-%d %H:%M:%S')}")
                    print(f"   æ–‡ä»¶å¤§å°: {size_mb:.1f}MB")
                    
                except Exception as e:
                    print(f"âš ï¸ {description}: æ–‡ä»¶æŸå - {e}")
            else:
                print(f"âŒ {description}: æ–‡ä»¶ä¸å­˜åœ¨")
            print()
        
        # ç¼“å­˜çŠ¶æ€
        if self._cache:
            print(f"ğŸ”„ ç¼“å­˜çŠ¶æ€: {len(self._cache)} ä¸ªæ•°æ®é›†å·²ç¼“å­˜")
            for key, timestamp in self._cache_timestamps.items():
                age = (datetime.now() - timestamp).total_seconds() / 60  # åˆ†é’Ÿ
                print(f"   {key}: {age:.1f}åˆ†é’Ÿå‰")
        else:
            print("ğŸ”„ ç¼“å­˜çŠ¶æ€: ç©º")
        
        print("=" * 60)
    
    def clear_cache(self):
        """æ¸…ç©ºç¼“å­˜"""
        self._cache.clear()
        self._cache_timestamps.clear()
        logger.info("æ•°æ®ç¼“å­˜å·²æ¸…ç©º")
    
    def validate_all_data(self) -> Dict[str, Tuple[bool, List[str]]]:
        """
        éªŒè¯æ‰€æœ‰æ•°æ®æ ¼å¼
        
        Returns
        -------
        Dict[str, Tuple[bool, List[str]]]
            å„æ•°æ®ç±»å‹çš„éªŒè¯ç»“æœ
        """
        results = {}
        
        # éªŒè¯ä»·æ ¼æ•°æ®
        try:
            price_data = self.get_price_data(validate=False)
            results['price'] = validate_price_data(price_data)
            logger.info(f"ä»·æ ¼æ•°æ®éªŒè¯: {'é€šè¿‡' if results['price'][0] else 'å¤±è´¥'}")
        except Exception as e:
            results['price'] = (False, [f"è·å–ä»·æ ¼æ•°æ®å¤±è´¥: {e}"])
        
        # éªŒè¯è´¢åŠ¡æ•°æ®
        try:
            financial_data = self.get_financial_data(validate=False)
            results['financial'] = validate_financial_data(financial_data, strict=False)
            logger.info(f"è´¢åŠ¡æ•°æ®éªŒè¯: {'é€šè¿‡' if results['financial'][0] else 'å¤±è´¥'}")
        except Exception as e:
            results['financial'] = (False, [f"è·å–è´¢åŠ¡æ•°æ®å¤±è´¥: {e}"])
        
        return results


# å…¨å±€æ•°æ®æ¡¥æ¥å™¨å®ä¾‹
_global_bridge = None

def get_data_bridge() -> DataBridge:
    """è·å–å…¨å±€æ•°æ®æ¡¥æ¥å™¨å®ä¾‹"""
    global _global_bridge
    if _global_bridge is None:
        _global_bridge = DataBridge()
    return _global_bridge

# ä¾¿æ·å‡½æ•°
def get_factor_data(source: str, column: str, **kwargs) -> pd.Series:
    """
    ä¾¿æ·å‡½æ•°ï¼šè·å–æ ‡å‡†æ ¼å¼çš„å› å­æ•°æ®
    
    Parameters
    ----------
    source : str
        æ•°æ®æºï¼Œ'price' æˆ– 'financial'
    column : str
        å­—æ®µå
    **kwargs
        å…¶ä»–å‚æ•°
        
    Returns
    -------
    pd.Series
        æ ‡å‡†å› å­æ ¼å¼çš„æ•°æ®
    """
    bridge = get_data_bridge()
    
    if source == 'price':
        return bridge.price_to_factor(value_column=column, **kwargs)
    elif source == 'financial':
        return bridge.financial_to_factor(value_column=column, **kwargs)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®æº: {source}")

def validate_data_pipeline() -> bool:
    """
    éªŒè¯æ•´ä¸ªæ•°æ®ç®¡é“
    
    Returns
    -------
    bool
        éªŒè¯æ˜¯å¦é€šè¿‡
    """
    bridge = get_data_bridge()
    
    print("\nğŸ” æ•°æ®ç®¡é“éªŒè¯")
    print("=" * 50)
    
    results = bridge.validate_all_data()
    all_passed = True
    
    for data_type, (is_valid, errors) in results.items():
        status = "âœ… é€šè¿‡" if is_valid else "âŒ å¤±è´¥"
        print(f"{data_type.ljust(10)}: {status}")
        
        if not is_valid:
            all_passed = False
            for error in errors[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªé”™è¯¯
                print(f"  â€¢ {error}")
            if len(errors) > 3:
                print(f"  â€¢ ... è¿˜æœ‰ {len(errors) - 3} ä¸ªé”™è¯¯")
    
    print(f"\næ€»ä½“ç»“æœ: {'âœ… æ•°æ®ç®¡é“éªŒè¯é€šè¿‡' if all_passed else 'âŒ æ•°æ®ç®¡é“éªŒè¯å¤±è´¥'}")
    print("=" * 50)
    
    return all_passed