#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®æ ¼å¼çº¦å®šå’ŒéªŒè¯æ¨¡å—

å®šä¹‰ä»æ•°æ®åº“åˆ°factorsæ¨¡å—çš„æ ‡å‡†æ•°æ®æ ¼å¼å’ŒéªŒè¯æœºåˆ¶
ç¡®ä¿æ•°æ®ä¼ é€’çš„ä¸€è‡´æ€§å’Œå¯é æ€§

Author: MultiFactors Team
Date: 2025-08-21
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Union, Any, Tuple
from dataclasses import dataclass
from datetime import datetime
import logging

logger = logging.getLogger(__name__)


@dataclass
class DataSchema:
    """æ•°æ®æ ¼å¼è§„èŒƒå®šä¹‰"""
    name: str                    # æ•°æ®ç±»å‹åç§°
    required_columns: List[str]  # å¿…éœ€å­—æ®µ
    optional_columns: List[str]  # å¯é€‰å­—æ®µ
    index_columns: List[str]     # ç´¢å¼•å­—æ®µ
    data_types: Dict[str, str]   # å­—æ®µæ•°æ®ç±»å‹
    constraints: Dict[str, Any]  # çº¦æŸæ¡ä»¶
    description: str             # æ•°æ®æè¿°


class DataSchemas:
    """æ ‡å‡†æ•°æ®æ ¼å¼å®šä¹‰"""
    
    # ä»·æ ¼æ•°æ®æ ¼å¼
    PRICE_DATA = DataSchema(
        name="price_data",
        required_columns=['code', 'tradingday', 'c', 'adjfactor'],
        optional_columns=['o', 'h', 'l', 'v', 'amt', 'total_shares', 'free_float_shares', 'exchange_id'],
        index_columns=['code', 'tradingday'],
        data_types={
            'code': 'string',
            'tradingday': 'int64',
            'o': 'float64', 'h': 'float64', 'l': 'float64', 'c': 'float64',
            'v': 'float64', 'amt': 'float64', 'adjfactor': 'float64',
            'total_shares': 'float64', 'free_float_shares': 'float64',
            'exchange_id': 'int64'
        },
        constraints={
            'tradingday': {'min': 20100101, 'max': 29991231},
            'c': {'min': 0, 'max': np.inf},
            'adjfactor': {'min': 0, 'max': np.inf},
            'v': {'min': 0, 'max': np.inf}
        },
        description="è‚¡ç¥¨æ—¥é¢‘ä»·æ ¼æ•°æ®"
    )
    
    # è´¢åŠ¡æ•°æ®æ ¼å¼
    FINANCIAL_DATA = DataSchema(
        name="financial_data",
        required_columns=['code', 'reportday', 'd_year', 'd_quarter'],
        optional_columns=[],  # è´¢åŠ¡å­—æ®µå¤ªå¤šï¼ŒæŒ‰å®é™…è¡¨ç»“æ„åŠ¨æ€éªŒè¯
        index_columns=['code', 'reportday', 'd_year', 'd_quarter'],
        data_types={
            'code': 'string',
            'reportday': 'datetime64[ns]',
            'd_year': 'int64',
            'd_quarter': 'int64'
        },
        constraints={
            'd_year': {'min': 2000, 'max': 2050},
            'd_quarter': {'min': 1, 'max': 4}
        },
        description="è´¢åŠ¡æŠ¥è¡¨æ•°æ®"
    )
    
    # å‘å¸ƒæ—¥æœŸæ•°æ®æ ¼å¼
    RELEASE_DATES = DataSchema(
        name="release_dates",
        required_columns=['StockCodes', 'ReportPeriod', 'ReleasedDates'],
        optional_columns=[],
        index_columns=['StockCodes', 'ReportPeriod'],
        data_types={
            'StockCodes': 'string',
            'ReportPeriod': 'datetime64[ns]',
            'ReleasedDates': 'datetime64[ns]'
        },
        constraints={},
        description="è´¢æŠ¥å‘å¸ƒæ—¥æœŸæ•°æ®"
    )
    
    # äº¤æ˜“æ—¥æœŸæ•°æ®æ ¼å¼
    TRADING_DATES = DataSchema(
        name="trading_dates",
        required_columns=['TradingDates'],
        optional_columns=[],
        index_columns=['TradingDates'],
        data_types={
            'TradingDates': 'datetime64[ns]'
        },
        constraints={},
        description="äº¤æ˜“æ—¥æœŸåˆ—è¡¨"
    )
    
    # å› å­æ ‡å‡†æ ¼å¼ï¼ˆä¼ é€’ç»™factorsæ¨¡å—ï¼‰
    FACTOR_FORMAT = DataSchema(
        name="factor_format",
        required_columns=[],  # Seriesæ•°æ®æ— åˆ—å
        optional_columns=[],
        index_columns=['TradingDates', 'StockCodes'],
        data_types={'values': 'float64'},
        constraints={},
        description="æ ‡å‡†å› å­æ ¼å¼ - MultiIndex Series[TradingDates, StockCodes]"
    )


class DataValidator:
    """æ•°æ®æ ¼å¼éªŒè¯å™¨"""
    
    @staticmethod
    def validate_dataframe(df: pd.DataFrame, schema: DataSchema, 
                          strict: bool = True) -> Tuple[bool, List[str]]:
        """
        éªŒè¯DataFrameæ˜¯å¦ç¬¦åˆæŒ‡å®šæ ¼å¼
        
        Parameters
        ----------
        df : pd.DataFrame
            å¾…éªŒè¯çš„æ•°æ®
        schema : DataSchema
            æ•°æ®æ ¼å¼è§„èŒƒ
        strict : bool
            æ˜¯å¦ä¸¥æ ¼æ¨¡å¼ï¼ˆç¼ºå°‘å¯é€‰å­—æ®µä¹ŸæŠ¥é”™ï¼‰
            
        Returns
        -------
        Tuple[bool, List[str]]
            (æ˜¯å¦é€šè¿‡éªŒè¯, é”™è¯¯ä¿¡æ¯åˆ—è¡¨)
        """
        errors = []
        
        # æ£€æŸ¥æ•°æ®ç±»å‹
        if not isinstance(df, pd.DataFrame):
            errors.append(f"æ•°æ®å¿…é¡»æ˜¯DataFrameç±»å‹ï¼Œå½“å‰: {type(df)}")
            return False, errors
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºç©º
        if df.empty:
            errors.append("æ•°æ®ä¸èƒ½ä¸ºç©º")
            return False, errors
        
        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        missing_required = set(schema.required_columns) - set(df.columns)
        if missing_required:
            errors.append(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {missing_required}")
        
        # æ£€æŸ¥å¯é€‰å­—æ®µï¼ˆä¸¥æ ¼æ¨¡å¼ï¼‰
        if strict:
            missing_optional = set(schema.optional_columns) - set(df.columns)
            if missing_optional:
                errors.append(f"ç¼ºå°‘å¯é€‰å­—æ®µ: {missing_optional}")
        
        # æ£€æŸ¥å­—æ®µæ•°æ®ç±»å‹
        for col, expected_dtype in schema.data_types.items():
            if col in df.columns:
                actual_dtype = str(df[col].dtype)
                if not DataValidator._is_compatible_dtype(actual_dtype, expected_dtype):
                    errors.append(f"å­—æ®µ {col} æ•°æ®ç±»å‹ä¸åŒ¹é…: æœŸæœ› {expected_dtype}, å®é™… {actual_dtype}")
        
        # æ£€æŸ¥çº¦æŸæ¡ä»¶
        for col, constraint in schema.constraints.items():
            if col in df.columns:
                errors.extend(DataValidator._validate_constraints(df[col], col, constraint))
        
        # æ£€æŸ¥é‡å¤å€¼
        if schema.index_columns:
            available_index_cols = [col for col in schema.index_columns if col in df.columns]
            if available_index_cols:
                duplicates = df.duplicated(subset=available_index_cols).sum()
                if duplicates > 0:
                    errors.append(f"å‘ç° {duplicates} è¡Œé‡å¤æ•°æ®")
        
        return len(errors) == 0, errors
    
    @staticmethod
    def validate_series(series: pd.Series, schema: DataSchema) -> Tuple[bool, List[str]]:
        """
        éªŒè¯Seriesæ˜¯å¦ç¬¦åˆå› å­æ ¼å¼
        
        Parameters
        ----------
        series : pd.Series
            å¾…éªŒè¯çš„å› å­æ•°æ®
        schema : DataSchema
            æ•°æ®æ ¼å¼è§„èŒƒ
            
        Returns
        -------
        Tuple[bool, List[str]]
            (æ˜¯å¦é€šè¿‡éªŒè¯, é”™è¯¯ä¿¡æ¯åˆ—è¡¨)
        """
        errors = []
        
        # æ£€æŸ¥æ•°æ®ç±»å‹
        if not isinstance(series, pd.Series):
            errors.append(f"æ•°æ®å¿…é¡»æ˜¯Seriesç±»å‹ï¼Œå½“å‰: {type(series)}")
            return False, errors
        
        # æ£€æŸ¥MultiIndexæ ¼å¼
        if not isinstance(series.index, pd.MultiIndex):
            errors.append("å› å­æ•°æ®å¿…é¡»ä½¿ç”¨MultiIndexæ ¼å¼")
            return False, errors
        
        # æ£€æŸ¥ç´¢å¼•çº§åˆ«
        if series.index.nlevels != 2:
            errors.append(f"MultiIndexå¿…é¡»æœ‰2ä¸ªçº§åˆ«ï¼Œå½“å‰: {series.index.nlevels}")
        
        # æ£€æŸ¥ç´¢å¼•åç§°
        expected_names = schema.index_columns
        if list(series.index.names) != expected_names:
            errors.append(f"ç´¢å¼•åç§°å¿…é¡»ä¸º {expected_names}ï¼Œå½“å‰: {series.index.names}")
        
        # æ£€æŸ¥æ•°æ®ç±»å‹
        if not np.issubdtype(series.dtype, np.number):
            errors.append(f"å› å­å€¼å¿…é¡»æ˜¯æ•°å€¼ç±»å‹ï¼Œå½“å‰: {series.dtype}")
        
        # æ£€æŸ¥ç¼ºå¤±å€¼æ¯”ä¾‹
        null_ratio = series.isnull().sum() / len(series)
        if null_ratio > 0.5:
            errors.append(f"ç¼ºå¤±å€¼æ¯”ä¾‹è¿‡é«˜: {null_ratio:.1%}")
        
        return len(errors) == 0, errors
    
    @staticmethod
    def _is_compatible_dtype(actual: str, expected: str) -> bool:
        """æ£€æŸ¥æ•°æ®ç±»å‹å…¼å®¹æ€§"""
        # æ•°å€¼ç±»å‹å…¼å®¹æ€§
        numeric_types = ['int64', 'int32', 'float64', 'float32']
        if expected in numeric_types and actual in numeric_types:
            return True
        
        # å­—ç¬¦ä¸²ç±»å‹å…¼å®¹æ€§
        string_types = ['object', 'string']
        if expected in string_types and actual in string_types:
            return True
        
        # æ—¥æœŸç±»å‹å…¼å®¹æ€§
        datetime_types = ['datetime64[ns]', 'datetime64']
        if expected in datetime_types and actual in datetime_types:
            return True
        
        return actual == expected
    
    @staticmethod
    def _validate_constraints(series: pd.Series, col_name: str, constraints: Dict) -> List[str]:
        """éªŒè¯çº¦æŸæ¡ä»¶"""
        errors = []
        
        # æ•°å€¼èŒƒå›´çº¦æŸ
        if 'min' in constraints:
            min_val = series.min()
            if min_val < constraints['min']:
                errors.append(f"å­—æ®µ {col_name} å­˜åœ¨å°äºæœ€å°å€¼çš„æ•°æ®: {min_val} < {constraints['min']}")
        
        if 'max' in constraints:
            max_val = series.max()
            if max_val > constraints['max']:
                errors.append(f"å­—æ®µ {col_name} å­˜åœ¨å¤§äºæœ€å¤§å€¼çš„æ•°æ®: {max_val} > {constraints['max']}")
        
        # éç©ºçº¦æŸ
        if constraints.get('not_null', False):
            null_count = series.isnull().sum()
            if null_count > 0:
                errors.append(f"å­—æ®µ {col_name} ä¸èƒ½åŒ…å«ç©ºå€¼ï¼Œå‘ç° {null_count} ä¸ªç©ºå€¼")
        
        return errors


class DataConverter:
    """æ•°æ®æ ¼å¼è½¬æ¢å™¨"""
    
    @staticmethod
    def price_to_factor_format(price_df: pd.DataFrame, 
                              value_column: str = 'c',
                              date_column: str = 'tradingday',
                              stock_column: str = 'code') -> pd.Series:
        """
        å°†ä»·æ ¼DataFrameè½¬æ¢ä¸ºæ ‡å‡†å› å­æ ¼å¼
        
        Parameters
        ----------
        price_df : pd.DataFrame
            ä»·æ ¼æ•°æ®
        value_column : str
            æ•°å€¼åˆ—å
        date_column : str
            æ—¥æœŸåˆ—å
        stock_column : str
            è‚¡ç¥¨ä»£ç åˆ—å
            
        Returns
        -------
        pd.Series
            æ ‡å‡†å› å­æ ¼å¼çš„Series
        """
        # æ•°æ®é¢„å¤„ç†
        df = price_df.copy()
        
        # è½¬æ¢æ—¥æœŸæ ¼å¼
        if df[date_column].dtype != 'datetime64[ns]':
            if df[date_column].dtype in ['int64', 'int32']:
                # å¤„ç†20241201æ ¼å¼çš„æ—¥æœŸ
                df[date_column] = pd.to_datetime(df[date_column].astype(str), format='%Y%m%d')
            else:
                df[date_column] = pd.to_datetime(df[date_column])
        
        # è®¾ç½®MultiIndex
        df = df.set_index([date_column, stock_column])
        df.index.names = ['TradingDates', 'StockCodes']
        
        # æå–ç›®æ ‡åˆ—ä½œä¸ºSeries
        factor_series = df[value_column]
        
        # æ’åºç´¢å¼•
        factor_series = factor_series.sort_index()
        
        return factor_series
    
    @staticmethod
    def financial_to_factor_format(financial_df: pd.DataFrame,
                                  value_column: str,
                                  date_column: str = 'reportday',
                                  stock_column: str = 'code') -> pd.Series:
        """
        å°†è´¢åŠ¡DataFrameè½¬æ¢ä¸ºæ ‡å‡†å› å­æ ¼å¼
        
        Parameters
        ----------
        financial_df : pd.DataFrame
            è´¢åŠ¡æ•°æ®
        value_column : str
            æ•°å€¼åˆ—å
        date_column : str
            æ—¥æœŸåˆ—å  
        stock_column : str
            è‚¡ç¥¨ä»£ç åˆ—å
            
        Returns
        -------
        pd.Series
            æ ‡å‡†å› å­æ ¼å¼çš„Series
        """
        df = financial_df.copy()
        
        # ç¡®ä¿æ—¥æœŸæ ¼å¼
        if df[date_column].dtype != 'datetime64[ns]':
            df[date_column] = pd.to_datetime(df[date_column])
        
        # è®¾ç½®MultiIndex
        df = df.set_index([date_column, stock_column])
        df.index.names = ['TradingDates', 'StockCodes']
        
        # æå–ç›®æ ‡åˆ—
        factor_series = df[value_column]
        
        # æ’åºç´¢å¼•
        factor_series = factor_series.sort_index()
        
        return factor_series


class DataQualityChecker:
    """æ•°æ®è´¨é‡æ£€æŸ¥å™¨"""
    
    @staticmethod
    def generate_quality_report(df: pd.DataFrame, 
                               schema: DataSchema) -> Dict[str, Any]:
        """
        ç”Ÿæˆæ•°æ®è´¨é‡æŠ¥å‘Š
        
        Parameters
        ----------
        df : pd.DataFrame
            å¾…æ£€æŸ¥çš„æ•°æ®
        schema : DataSchema
            æ•°æ®æ ¼å¼è§„èŒƒ
            
        Returns
        -------
        Dict[str, Any]
            æ•°æ®è´¨é‡æŠ¥å‘Š
        """
        report = {
            'data_name': schema.name,
            'check_time': datetime.now(),
            'basic_info': {},
            'quality_metrics': {},
            'issues': []
        }
        
        # åŸºæœ¬ä¿¡æ¯
        report['basic_info'] = {
            'shape': df.shape,
            'memory_usage_mb': df.memory_usage(deep=True).sum() / 1024 / 1024,
            'dtypes': df.dtypes.to_dict()
        }
        
        # è´¨é‡æŒ‡æ ‡
        report['quality_metrics'] = {
            'completeness': {},
            'consistency': {},
            'validity': {}
        }
        
        # å®Œæ•´æ€§æ£€æŸ¥
        for col in df.columns:
            null_count = df[col].isnull().sum()
            total_count = len(df)
            completeness = 1 - (null_count / total_count)
            report['quality_metrics']['completeness'][col] = {
                'completeness_ratio': completeness,
                'null_count': null_count,
                'total_count': total_count
            }
            
            # è®°å½•å®Œæ•´æ€§é—®é¢˜
            if completeness < 0.9:  # 90%å®Œæ•´æ€§é˜ˆå€¼
                report['issues'].append({
                    'type': 'completeness',
                    'column': col,
                    'description': f'å­—æ®µ {col} å®Œæ•´æ€§è¾ƒä½: {completeness:.1%}'
                })
        
        # ä¸€è‡´æ€§æ£€æŸ¥
        if schema.index_columns:
            available_index_cols = [col for col in schema.index_columns if col in df.columns]
            if available_index_cols:
                duplicate_count = df.duplicated(subset=available_index_cols).sum()
                report['quality_metrics']['consistency']['duplicate_count'] = duplicate_count
                
                if duplicate_count > 0:
                    report['issues'].append({
                        'type': 'consistency',
                        'column': available_index_cols,
                        'description': f'å‘ç° {duplicate_count} è¡Œé‡å¤æ•°æ®'
                    })
        
        # æœ‰æ•ˆæ€§æ£€æŸ¥
        for col, constraint in schema.constraints.items():
            if col in df.columns:
                validity_issues = DataValidator._validate_constraints(df[col], col, constraint)
                if validity_issues:
                    for issue in validity_issues:
                        report['issues'].append({
                            'type': 'validity',
                            'column': col,
                            'description': issue
                        })
        
        return report
    
    @staticmethod
    def print_quality_report(report: Dict[str, Any]):
        """æ‰“å°æ•°æ®è´¨é‡æŠ¥å‘Š"""
        print(f"\nğŸ“Š æ•°æ®è´¨é‡æŠ¥å‘Š - {report['data_name']}")
        print("=" * 60)
        
        # åŸºæœ¬ä¿¡æ¯
        basic = report['basic_info']
        print(f"ğŸ“‹ åŸºæœ¬ä¿¡æ¯:")
        print(f"  æ•°æ®å½¢çŠ¶: {basic['shape']}")
        print(f"  å†…å­˜ä½¿ç”¨: {basic['memory_usage_mb']:.1f}MB")
        
        # å®Œæ•´æ€§
        print(f"\nâœ… å®Œæ•´æ€§æ£€æŸ¥:")
        completeness = report['quality_metrics']['completeness']
        for col, metrics in list(completeness.items())[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªå­—æ®µ
            ratio = metrics['completeness_ratio']
            status = "âœ“" if ratio >= 0.9 else "âš ï¸"
            print(f"  {status} {col}: {ratio:.1%}")
        
        if len(completeness) > 5:
            print(f"  ... è¿˜æœ‰ {len(completeness) - 5} ä¸ªå­—æ®µ")
        
        # é—®é¢˜æ±‡æ€»
        issues = report['issues']
        if issues:
            print(f"\nâš ï¸ å‘ç° {len(issues)} ä¸ªé—®é¢˜:")
            for issue in issues[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªé—®é¢˜
                print(f"  â€¢ {issue['description']}")
            if len(issues) > 3:
                print(f"  ... è¿˜æœ‰ {len(issues) - 3} ä¸ªé—®é¢˜")
        else:
            print(f"\nâœ… æœªå‘ç°æ•°æ®è´¨é‡é—®é¢˜")
        
        print("=" * 60)


# é¢„å®šä¹‰éªŒè¯å‡½æ•°
def validate_price_data(df: pd.DataFrame, strict: bool = False) -> Tuple[bool, List[str]]:
    """éªŒè¯ä»·æ ¼æ•°æ®æ ¼å¼"""
    return DataValidator.validate_dataframe(df, DataSchemas.PRICE_DATA, strict)

def validate_financial_data(df: pd.DataFrame, strict: bool = False) -> Tuple[bool, List[str]]:
    """éªŒè¯è´¢åŠ¡æ•°æ®æ ¼å¼"""
    return DataValidator.validate_dataframe(df, DataSchemas.FINANCIAL_DATA, strict)

def validate_factor_format(series: pd.Series) -> Tuple[bool, List[str]]:
    """éªŒè¯å› å­æ ¼å¼"""
    return DataValidator.validate_series(series, DataSchemas.FACTOR_FORMAT)

def convert_to_factor_format(df: pd.DataFrame, value_col: str, 
                           date_col: str = 'tradingday', 
                           stock_col: str = 'code') -> pd.Series:
    """è½¬æ¢ä¸ºæ ‡å‡†å› å­æ ¼å¼"""
    return DataConverter.price_to_factor_format(df, value_col, date_col, stock_col)