# Dataæ¨¡å—ä½¿ç”¨æŒ‡å—

## ğŸ“Š æ¨¡å—æ¦‚è¿°

Dataæ¨¡å—è´Ÿè´£å¤šå› å­é‡åŒ–ç³»ç»Ÿçš„æ•°æ®è·å–ã€å¤„ç†å’Œå­˜å‚¨ï¼Œé‡‡ç”¨ç®€å•å®ç”¨çš„æ‰¹å¤„ç†æ¶æ„ï¼Œé€šè¿‡æ–‡ä»¶ç³»ç»Ÿå®ç°ä¸å…¶ä»–æ¨¡å—çš„è§£è€¦ã€‚

**è®¾è®¡ç†å¿µ**: 
- ğŸ¯ **ç®€å•ç›´æ¥**: è„šæœ¬åŒ–å¤„ç†ï¼Œæ˜“äºç»´æŠ¤å’Œè°ƒè¯•
- ğŸ“ **æ–‡ä»¶é©±åŠ¨**: ä½¿ç”¨pklæ–‡ä»¶ä½œä¸ºæ•°æ®äº¤æ¢åª’ä»‹
- ğŸ”„ **æ‰¹å¤„ç†å‹å¥½**: é€‚åˆT+1é‡åŒ–ç ”ç©¶åœºæ™¯
- ğŸ› ï¸ **å·¥å…·åŒ–**: æ¯ä¸ªè„šæœ¬ä¸“æ³¨ä¸€ä¸ªåŠŸèƒ½

## ğŸ“ ç›®å½•ç»“æ„

```
data/
â”œâ”€â”€ README.md                    # æœ¬æ–‡æ¡£
â”‚
â”œâ”€â”€ ğŸ“‹ ä¸»ç¨‹åºè„šæœ¬
â”œâ”€â”€ prepare_auxiliary_data.py    # è¾…åŠ©æ•°æ®å‡†å¤‡ï¼ˆåˆå§‹åŒ–å¿…å¤‡ï¼‰
â”‚
â”œâ”€â”€ ğŸ“Š æ•°æ®è·å–æ¨¡å— (fetcher/)
â”œâ”€â”€ fetcher/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_fetcher.py          # æ•°æ®è·å–åŸºç±»å’Œè‚¡ç¥¨æ•°æ®è·å–å™¨
â”‚   â”œâ”€â”€ BasicDataLocalization.py # åŸºç¡€æ•°æ®æœ¬åœ°åŒ–
â”‚   â”œâ”€â”€ chunked_price_fetcher.py # åˆ†å—ä»·æ ¼æ•°æ®è·å–
â”‚   â””â”€â”€ incremental_price_updater.py # å¢é‡ä»·æ ¼æ›´æ–°å™¨
â”‚
â”œâ”€â”€ ğŸ”§ æ•°æ®å¤„ç†æ¨¡å— (processor/)
â”œâ”€â”€ processor/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_processor.py        # å¤„ç†å™¨åŸºç±»
â”‚   â”œâ”€â”€ data_processing_pipeline.py # æ•°æ®å¤„ç†ç®¡é“
â”‚   â”œâ”€â”€ enhanced_pipeline.py     # å¢å¼ºå¤„ç†ç®¡é“
â”‚   â”œâ”€â”€ price_processor.py       # ä»·æ ¼æ•°æ®å¤„ç†å™¨
â”‚   â”œâ”€â”€ return_calculator.py     # æ”¶ç›Šç‡è®¡ç®—å™¨
â”‚   â”œâ”€â”€ financial_processor.py   # è´¢åŠ¡æ•°æ®å¤„ç†å™¨
â”‚   â”œâ”€â”€ optimized_return_calculator.py # ä¼˜åŒ–æ”¶ç›Šç‡è®¡ç®—
â”‚   â”œâ”€â”€ parallel_optimizer.py    # å¹¶è¡Œå¤„ç†ä¼˜åŒ–å™¨
â”‚   â””â”€â”€ example_custom_processor.py # è‡ªå®šä¹‰å¤„ç†å™¨ç¤ºä¾‹
â”‚
â”œâ”€â”€ ğŸ’¾ æ•°æ®å­˜å‚¨ç›®å½• (auxiliary/)
â”œâ”€â”€ auxiliary/                   # é¢„å¤„ç†æ•°æ®å­˜å‚¨ï¼ˆç”Ÿæˆçš„pklæ–‡ä»¶ï¼‰
â”‚   â”œâ”€â”€ FinancialData_unified.pkl    # åˆå¹¶çš„è´¢åŠ¡æ•°æ®
â”‚   â”œâ”€â”€ ReleaseDates.pkl             # è´¢æŠ¥å‘å¸ƒæ—¥æœŸ
â”‚   â”œâ”€â”€ StockInfo.pkl                # è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
â”‚   â”œâ”€â”€ TradingDates.pkl             # äº¤æ˜“æ—¥æœŸåˆ—è¡¨
â”‚   â”œâ”€â”€ data_preparation_summary.json    # æ•°æ®å‡†å¤‡æ‘˜è¦
â”‚   â””â”€â”€ data_preparation_summary_v2.json # æ•°æ®å‡†å¤‡æ‘˜è¦v2
â”‚
â”œâ”€â”€ ğŸ—ƒï¸ å­˜å‚¨æ¥å£ (storage/)
â”‚   â””â”€â”€ (ç©ºç›®å½•ï¼Œä¿ç•™æ‰©å±•)
â”‚
â”œâ”€â”€ ğŸ“‹ æ•°æ®æ ¼å¼çº¦å®š
â”œâ”€â”€ schemas.py                   # æ•°æ®æ ¼å¼è§„èŒƒå’ŒéªŒè¯å™¨
â”œâ”€â”€ data_bridge.py               # dataæ¨¡å—ä¸factorsæ¨¡å—çš„æ¡¥æ¥æ¥å£
â”œâ”€â”€ DATA_FORMATS.md              # æ•°æ®æ ¼å¼çº¦å®šè¯¦ç»†æ–‡æ¡£
â”‚
â””â”€â”€ ğŸ“š ä½¿ç”¨ç¤ºä¾‹ (examples/)
    â””â”€â”€ data_format_examples.py     # æ•°æ®æ ¼å¼ä½¿ç”¨ç¤ºä¾‹
```

## ğŸ“‹ æ•°æ®æ–‡ä»¶è¯´æ˜

| æ–‡ä»¶å | ç”¨é€” | æ›´æ–°é¢‘ç‡ | ä¾èµ–è„šæœ¬ |
|--------|------|----------|----------|
| `FinancialData_unified.pkl` | åˆå¹¶çš„è´¢åŠ¡æ•°æ®ï¼ˆåˆ©æ¶¦è¡¨ã€èµ„äº§è´Ÿå€ºè¡¨ã€ç°é‡‘æµé‡è¡¨ï¼‰ | å­£åº¦ | prepare_auxiliary_data.py |
| `ReleaseDates.pkl` | è´¢æŠ¥å‘å¸ƒæ—¥æœŸæ•°æ® | å­£åº¦ | prepare_auxiliary_data.py |
| `StockInfo.pkl` | è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ | æ‰‹åŠ¨ | prepare_auxiliary_data.py |
| `TradingDates.pkl` | äº¤æ˜“æ—¥æœŸåˆ—è¡¨ | æ‰‹åŠ¨ | prepare_auxiliary_data.py |
| `Price.pkl` | è‚¡ç¥¨ä»·æ ¼æ•°æ® | æ—¥ | ../scheduled_data_updater.py |
| `LogReturn_*.pkl` | å„ç±»æ”¶ç›Šç‡æ•°æ® | æŒ‰éœ€ | æ•°æ®å¤„ç†ç®¡é“ |

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. åˆå§‹åŒ–æ•°æ®ç¯å¢ƒ

**é¦–æ¬¡ä½¿ç”¨å¿…é¡»æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š**

```bash
# 1. è¿›å…¥é¡¹ç›®æ ¹ç›®å½•
cd mulitfactors_beta/

# 2. å‡†å¤‡è¾…åŠ©æ•°æ®ï¼ˆå¿…å¤‡æ­¥éª¤ï¼‰
python data/prepare_auxiliary_data.py

# 3. è·å–åˆå§‹ä»·æ ¼æ•°æ®
python scheduled_data_updater.py --data-type price

# 4. éªŒè¯æ•°æ®å‡†å¤‡å®Œæˆ
python -c "
import pandas as pd
from pathlib import Path

files = ['FinancialData_unified.pkl', 'ReleaseDates.pkl', 'StockInfo.pkl', 'TradingDates.pkl']
for f in files:
    path = Path(f'data/auxiliary/{f}')
    if path.exists():
        print(f'âœ“ {f} - å¤§å°: {path.stat().st_size/1024/1024:.1f}MB')
    else:
        print(f'âœ— {f} - ç¼ºå¤±')
"
```

### 2. æ—¥å¸¸æ•°æ®æ›´æ–°

```bash
# æ›´æ–°ä»·æ ¼æ•°æ®ï¼ˆæ—¥å¸¸ï¼‰
python scheduled_data_updater.py --data-type price

# äº¤äº’å¼æ›´æ–°ï¼ˆæ”¯æŒå¤šç§æ•°æ®ç±»å‹ï¼‰
python interactive_data_updater.py

# å¢é‡æ›´æ–°ä»·æ ¼æ•°æ®
python data/fetcher/incremental_price_updater.py
```

## ğŸ’» ä½¿ç”¨èŒƒä¾‹

### 1. è¯»å–åŸºç¡€æ•°æ®

```python
import pandas as pd
from pathlib import Path

# è¯»å–è´¢åŠ¡æ•°æ®
financial_data = pd.read_pickle('data/auxiliary/FinancialData_unified.pkl')
print(f"è´¢åŠ¡æ•°æ®å½¢çŠ¶: {financial_data.shape}")
print(f"åŒ…å«å­—æ®µ: {list(financial_data.columns)}")

# è¯»å–å‘å¸ƒæ—¥æœŸ
release_dates = pd.read_pickle('data/auxiliary/ReleaseDates.pkl')
print(f"å‘å¸ƒæ—¥æœŸæ•°æ®: {release_dates.shape}")

# è¯»å–è‚¡ç¥¨ä¿¡æ¯
stock_info = pd.read_pickle('data/auxiliary/StockInfo.pkl')
print(f"è‚¡ç¥¨ä¿¡æ¯: {stock_info.shape}")

# è¯»å–äº¤æ˜“æ—¥æœŸ
trading_dates = pd.read_pickle('data/auxiliary/TradingDates.pkl')
print(f"äº¤æ˜“æ—¥æœŸ: {len(trading_dates)} ä¸ªäº¤æ˜“æ—¥")
```

### 2. ä½¿ç”¨æ•°æ®è·å–å™¨

```python
from data.fetcher.data_fetcher import StockDataFetcher

# åˆ›å»ºæ•°æ®è·å–å™¨
fetcher = StockDataFetcher()

# è·å–ä»·æ ¼æ•°æ®
price_data = fetcher.fetch_data('price', begin_date=20240101, end_date=20241231)
print(f"ä»·æ ¼æ•°æ®: {price_data.shape}")

# è·å–è´¢åŠ¡æ•°æ®
financial_data = fetcher.fetch_data('financial', sheet_type='fzb')  # èµ„äº§è´Ÿå€ºè¡¨
print(f"èµ„äº§è´Ÿå€ºè¡¨: {financial_data.shape}")
```

### 3. ä½¿ç”¨æ•°æ®å¤„ç†å™¨

```python
from data.processor.data_processing_pipeline import DataProcessingPipeline

# åˆ›å»ºå¤„ç†ç®¡é“
pipeline = DataProcessingPipeline()

# è¿è¡Œå®Œæ•´å¤„ç†æµç¨‹
results = pipeline.run_full_pipeline(save_intermediate=True)

# è·å–å¤„ç†ç»“æœ
price_df = results['price_df']
stock_3d = results['stock_3d']
log_return_daily = results['log_return_daily_o2o']

print(f"ä»·æ ¼æ•°æ®: {price_df.shape}")
print(f"ä¸‰ç»´è‚¡ç¥¨æ•°æ®: {stock_3d.shape}")
print(f"æ—¥æ”¶ç›Šç‡: {log_return_daily.shape}")
```

### 4. è‡ªå®šä¹‰æ•°æ®å¤„ç†

```python
from data.processor.base_processor import BaseDataProcessor
import pandas as pd

class CustomDataProcessor(BaseDataProcessor):
    """è‡ªå®šä¹‰æ•°æ®å¤„ç†å™¨ç¤ºä¾‹"""
    
    def validate_input(self, **kwargs):
        # è‡ªå®šä¹‰éªŒè¯é€»è¾‘
        return True
    
    def process(self, data: pd.DataFrame, **kwargs):
        """è‡ªå®šä¹‰å¤„ç†é€»è¾‘"""
        self.logger.info("å¼€å§‹è‡ªå®šä¹‰å¤„ç†...")
        
        # ç¤ºä¾‹ï¼šæ•°æ®æ¸…æ´—
        cleaned_data = data.dropna()
        
        # ç¤ºä¾‹ï¼šæ•°æ®è½¬æ¢
        processed_data = self.standardize_data(cleaned_data)
        
        # è®°å½•å¤„ç†å†å²
        self._record_processing(
            operation="custom_process",
            params=kwargs,
            result_info={"input_shape": data.shape, "output_shape": processed_data.shape}
        )
        
        return processed_data
    
    def standardize_data(self, data):
        """æ ‡å‡†åŒ–æ•°æ®"""
        numeric_cols = data.select_dtypes(include=[float, int]).columns
        data[numeric_cols] = (data[numeric_cols] - data[numeric_cols].mean()) / data[numeric_cols].std()
        return data

# ä½¿ç”¨è‡ªå®šä¹‰å¤„ç†å™¨
processor = CustomDataProcessor()
result = processor.process(your_data)
```

### 5. å¢é‡æ•°æ®æ›´æ–°

```python
from data.fetcher.incremental_price_updater import IncrementalPriceUpdater

# åˆ›å»ºå¢é‡æ›´æ–°å™¨
updater = IncrementalPriceUpdater()

# æ£€æŸ¥éœ€è¦æ›´æ–°çš„æ•°æ®
update_info = updater.check_update_requirements()
print(f"éœ€è¦æ›´æ–°: {update_info}")

# æ‰§è¡Œå¢é‡æ›´æ–°
if update_info['needs_update']:
    updater.update()
    print("å¢é‡æ›´æ–°å®Œæˆ")
```

## ğŸ” æ•°æ®è´¨é‡æ£€æŸ¥

### æ£€æŸ¥æ•°æ®å®Œæ•´æ€§

```python
import pandas as pd
from datetime import datetime
from pathlib import Path

def check_data_status():
    """æ£€æŸ¥æ‰€æœ‰æ•°æ®æ–‡ä»¶çŠ¶æ€"""
    
    files = {
        'FinancialData_unified.pkl': 'è´¢åŠ¡æ•°æ®',
        'ReleaseDates.pkl': 'å‘å¸ƒæ—¥æœŸ',
        'StockInfo.pkl': 'è‚¡ç¥¨ä¿¡æ¯',
        'TradingDates.pkl': 'äº¤æ˜“æ—¥æœŸ'
    }
    
    print("ğŸ“Š æ•°æ®çŠ¶æ€æ£€æŸ¥")
    print("=" * 50)
    
    for file, name in files.items():
        path = Path(f'data/auxiliary/{file}')
        if path.exists():
            mtime = datetime.fromtimestamp(path.stat().st_mtime)
            size = path.stat().st_size / 1024 / 1024  # MB
            
            # è¯»å–æ•°æ®æ£€æŸ¥å½¢çŠ¶
            try:
                data = pd.read_pickle(path)
                if isinstance(data, pd.DataFrame):
                    shape_info = f"({data.shape[0]}è¡Œ, {data.shape[1]}åˆ—)"
                else:
                    shape_info = f"({len(data)}é¡¹)" if hasattr(data, '__len__') else "æœªçŸ¥æ ¼å¼"
                    
                print(f"âœ“ {name}: {shape_info}")
                print(f"  æ›´æ–°æ—¶é—´: {mtime.strftime('%Y-%m-%d %H:%M:%S')}")
                print(f"  æ–‡ä»¶å¤§å°: {size:.1f}MB")
                
            except Exception as e:
                print(f"âš ï¸ {name}: æ–‡ä»¶æŸå - {e}")
        else:
            print(f"âœ— {name}: æ–‡ä»¶ä¸å­˜åœ¨")
        print()

# è¿è¡Œæ£€æŸ¥
check_data_status()
```

### æ£€æŸ¥æ•°æ®è´¨é‡

```python
def check_data_quality(data_name='FinancialData_unified.pkl'):
    """æ£€æŸ¥æ•°æ®è´¨é‡"""
    
    data = pd.read_pickle(f'data/auxiliary/{data_name}')
    
    print(f"ğŸ“ˆ {data_name} è´¨é‡æŠ¥å‘Š")
    print("=" * 50)
    
    # åŸºæœ¬ä¿¡æ¯
    print(f"æ•°æ®å½¢çŠ¶: {data.shape}")
    print(f"æ•°æ®ç±»å‹: {data.dtypes.value_counts().to_dict()}")
    
    # ç¼ºå¤±å€¼æ£€æŸ¥
    missing_ratio = data.isnull().sum() / len(data)
    high_missing = missing_ratio[missing_ratio > 0.1]
    
    if not high_missing.empty:
        print(f"\nâš ï¸ é«˜ç¼ºå¤±å€¼å­—æ®µ (>10%):")
        for col, ratio in high_missing.head(10).items():
            print(f"  {col}: {ratio:.1%}")
    else:
        print("\nâœ“ ç¼ºå¤±å€¼æ£€æŸ¥é€šè¿‡")
    
    # é‡å¤å€¼æ£€æŸ¥
    if hasattr(data, 'duplicated'):
        dup_count = data.duplicated().sum()
        print(f"\né‡å¤è¡Œæ•°: {dup_count} ({dup_count/len(data):.1%})")
    
    # æ•°å€¼èŒƒå›´æ£€æŸ¥
    numeric_cols = data.select_dtypes(include=[float, int]).columns
    if len(numeric_cols) > 0:
        print(f"\næ•°å€¼å­—æ®µç»Ÿè®¡ (å‰5ä¸ª):")
        print(data[numeric_cols[:5]].describe())

check_data_quality()
```

## ğŸ› ï¸ ç»´æŠ¤æŒ‡å—

### æ—¥å¸¸ç»´æŠ¤ä»»åŠ¡

```bash
# æ¯æ—¥ä»»åŠ¡
python scheduled_data_updater.py --data-type price

# æ¯å­£åº¦ä»»åŠ¡
python data/prepare_auxiliary_data.py  # æ›´æ–°è´¢åŠ¡æ•°æ®

# æ¯æœˆä»»åŠ¡ - æ¸…ç†æ—¥å¿—
find data/ -name "*.log" -mtime +30 -delete

# æ£€æŸ¥ç£ç›˜ç©ºé—´
du -sh data/auxiliary/
```

### æ•…éšœæ’æŸ¥

1. **æ•°æ®æ–‡ä»¶ç¼ºå¤±**
   ```bash
   # é‡æ–°ç”Ÿæˆè¾…åŠ©æ•°æ®
   python data/prepare_auxiliary_data.py
   ```

2. **æ•°æ®æ›´æ–°å¤±è´¥**
   ```bash
   # æ£€æŸ¥æ•°æ®åº“è¿æ¥
   python -c "from core.database import test_connection; test_connection()"
   
   # æ‰‹åŠ¨æ›´æ–°
   python interactive_data_updater.py
   ```

3. **å†…å­˜ä¸è¶³**
   ```python
   # ä½¿ç”¨åˆ†å—å¤„ç†
   from data.fetcher.chunked_price_fetcher import ChunkedPriceFetcher
   
   fetcher = ChunkedPriceFetcher(chunk_size=1000)
   data = fetcher.fetch_all()
   ```

### æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **å¯ç”¨æ•°æ®å‹ç¼©**
   ```python
   # ä¿å­˜æ—¶ä½¿ç”¨å‹ç¼©
   pd.to_pickle(data, 'data.pkl.gz', compression='gzip')
   
   # è¯»å–å‹ç¼©æ–‡ä»¶
   data = pd.read_pickle('data.pkl.gz')
   ```

2. **ä½¿ç”¨ç¼“å­˜æœºåˆ¶**
   ```python
   # æ•°æ®è·å–å™¨ä¼šè‡ªåŠ¨ä½¿ç”¨ç¼“å­˜
   fetcher = StockDataFetcher()
   data = fetcher.fetch_data('price', cache_hours=24)
   ```

3. **å¹¶è¡Œå¤„ç†**
   ```python
   from data.processor.parallel_optimizer import ParallelOptimizer
   
   optimizer = ParallelOptimizer(n_workers=4)
   result = optimizer.process_parallel(data_list)
   ```

## â“ å¸¸è§é—®é¢˜

**Q: åˆæ¬¡è¿è¡Œprepare_auxiliary_data.pyå¾ˆæ…¢æ€ä¹ˆåŠï¼Ÿ**
A: è¿™æ˜¯æ­£å¸¸çš„ï¼Œé¦–æ¬¡éœ€è¦å¤„ç†å¤§é‡è´¢åŠ¡æ•°æ®ã€‚å¯ä»¥å…ˆå¤„ç†éƒ¨åˆ†æ•°æ®æµ‹è¯•ï¼š
```python
# åœ¨prepare_auxiliary_data.pyä¸­è®¾ç½®æµ‹è¯•æ¨¡å¼
TEST_MODE = True  # åªå¤„ç†éƒ¨åˆ†æ•°æ®
```

**Q: å¦‚ä½•æ·»åŠ æ–°çš„æ•°æ®æºï¼Ÿ**
A: ç»§æ‰¿BaseDataFetcherç±»ï¼š
```python
from data.fetcher.data_fetcher import BaseDataFetcher

class YourDataFetcher(BaseDataFetcher):
    def fetch_data(self, **kwargs):
        # å®ç°ä½ çš„æ•°æ®è·å–é€»è¾‘
        pass
```

**Q: æ•°æ®æ–‡ä»¶å¤ªå¤§æ€ä¹ˆåŠï¼Ÿ**
A: å¯ä»¥ä½¿ç”¨å‹ç¼©æˆ–åˆ†ç‰‡å­˜å‚¨ï¼š
```python
# å‹ç¼©å­˜å‚¨
pd.to_pickle(data, 'data.pkl.gz', compression='gzip')

# åˆ†ç‰‡å­˜å‚¨
for i, chunk in enumerate(np.array_split(data, 10)):
    pd.to_pickle(chunk, f'data_chunk_{i}.pkl')
```

**Q: å¦‚ä½•å¤‡ä»½æ•°æ®ï¼Ÿ**
A: å®šæœŸå¤‡ä»½auxiliaryç›®å½•ï¼š
```bash
# åˆ›å»ºå¤‡ä»½
tar -czf data_backup_$(date +%Y%m%d).tar.gz data/auxiliary/

# æ¢å¤å¤‡ä»½
tar -xzf data_backup_20250101.tar.gz
```

## ğŸ”— æ•°æ®æ ¼å¼çº¦å®š

### æ•°æ®ä¼ é€’æ ‡å‡†

Dataæ¨¡å—ä¸factorsæ¨¡å—ä¹‹é—´é‡‡ç”¨æ ‡å‡†åŒ–çš„æ•°æ®æ ¼å¼ï¼Œç¡®ä¿æ•°æ®ä¼ é€’çš„ä¸€è‡´æ€§ï¼š

```python
# è·å–æ ‡å‡†æ ¼å¼å› å­æ•°æ®
from data.data_bridge import get_factor_data

# ä»·æ ¼å› å­
close_factor = get_factor_data('price', 'c')  # æ”¶ç›˜ä»·
volume_factor = get_factor_data('price', 'v') # æˆäº¤é‡

# è´¢åŠ¡å› å­  
profit_factor = get_factor_data('financial', 'NET_PROFIT')  # å‡€åˆ©æ¶¦
revenue_factor = get_factor_data('financial', 'REVENUE')    # è¥ä¸šæ”¶å…¥
```

### æ ‡å‡†å› å­æ ¼å¼

æ‰€æœ‰ä¼ é€’ç»™factorsæ¨¡å—çš„æ•°æ®éƒ½ä½¿ç”¨MultiIndex Seriesæ ¼å¼ï¼š

```python
# æ ‡å‡†æ ¼å¼: MultiIndex[TradingDates, StockCodes]
factor_series.index.names = ['TradingDates', 'StockCodes']

# ç¤ºä¾‹ç»“æ„:
TradingDates  StockCodes
2024-12-01    000001        10.7
              000002        15.35
2024-12-02    000001        10.8
              000002        15.4
```

### æ•°æ®éªŒè¯

ç³»ç»Ÿæä¾›è‡ªåŠ¨æ•°æ®éªŒè¯æœºåˆ¶ï¼š

```python
from data.data_bridge import validate_data_pipeline

# éªŒè¯æ•´ä¸ªæ•°æ®ç®¡é“
if validate_data_pipeline():
    print("âœ… æ•°æ®ç®¡é“éªŒè¯é€šè¿‡")
else:
    print("âŒ æ•°æ®ç®¡é“å­˜åœ¨é—®é¢˜")

# æŸ¥çœ‹æ•°æ®çŠ¶æ€
from data.data_bridge import get_data_bridge
bridge = get_data_bridge()
bridge.print_data_status()
```

### è¯¦ç»†æ–‡æ¡£

- ğŸ“‹ **å®Œæ•´æ ¼å¼è§„èŒƒ**: æŸ¥çœ‹ `DATA_FORMATS.md`
- ğŸ”§ **éªŒè¯æœºåˆ¶**: å‚è€ƒ `schemas.py`
- ğŸŒ‰ **æ¡¥æ¥æ¥å£**: ä½¿ç”¨ `data_bridge.py`
- ğŸ’» **ä½¿ç”¨ç¤ºä¾‹**: è¿è¡Œ `examples/data_format_examples.py`

## ğŸ“ æŠ€æœ¯æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š
1. æ—¥å¿—æ–‡ä»¶ï¼š`core/logs/`
2. é…ç½®æ–‡ä»¶ï¼š`config.yaml`
3. æ•°æ®åº“è¿æ¥ï¼šè¿è¡Œ`python -c "from core.database import test_connection; test_connection()"`
4. æ•°æ®æ ¼å¼ï¼šè¿è¡Œ `python data/examples/data_format_examples.py`

---

**æ›´æ–°æ—¶é—´**: 2025-08-21  
**ç»´æŠ¤è€…**: MultiFactorså¼€å‘å›¢é˜Ÿ