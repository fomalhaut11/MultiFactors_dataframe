#!/usr/bin/env python3
"""
è‡ªå®šä¹‰æ··åˆå› å­
éœ€è¦è´¢åŠ¡æ•°æ®å’Œå¸‚å€¼æ•°æ®çš„å¤åˆå› å­
"""

import pandas as pd
import numpy as np
from typing import Dict, Optional, Any
import logging

from factors.base.factor_base import FactorBase
from factors.base.data_processing_mixin import DataProcessingMixin
from factors.base.validation import DataValidator

logger = logging.getLogger(__name__)


class CashflowEfficiencyRatio(FactorBase, DataProcessingMixin):
    """
    ç°é‡‘æµæ•ˆç‡æ¯”ç‡å› å­
    
    è®¡ç®—å…¬å¼ï¼š
    ((FIN_EXP_CS + DEPR_FA_COGA_DPBA) / CASH_RECP_SG_AND_RS) / BP
    
    å…¶ä¸­ï¼š
    - FIN_EXP_CS: è´¢åŠ¡è´¹ç”¨
    - DEPR_FA_COGA_DPBA: å›ºå®šèµ„äº§æŠ˜æ—§ã€æ²¹æ°”èµ„äº§æŠ˜è€—ã€ç”Ÿäº§æ€§ç”Ÿç‰©èµ„äº§æŠ˜æ—§
    - CASH_RECP_SG_AND_RS: é”€å”®å•†å“ã€æä¾›åŠ³åŠ¡æ”¶åˆ°çš„ç°é‡‘
    - BP: å‡€èµ„äº§å¸‚å€¼æ¯”
    
    è¿™ä¸ªå› å­è¡¡é‡ä¼ä¸šç°é‡‘æµç›¸å¯¹äºè´¦é¢ä»·å€¼çš„æ•ˆç‡
    """
    
    def __init__(self):
        super().__init__(
            name="CashflowEfficiencyRatio",
            category="mixed"
        )
        self.factor_name = "CashflowEfficiencyRatio"
        self.factor_description = "ç°é‡‘æµæ•ˆç‡æ¯”ç‡ï¼š(è´¢åŠ¡è´¹ç”¨+æŠ˜æ—§)/é”€å”®ç°é‡‘æµ/å‡€èµ„äº§å¸‚å€¼æ¯”"
        
        # è®¾ç½®æ•°æ®ä¾èµ–
        self.required_fields = [
            'FIN_EXP_CS',           # è´¢åŠ¡è´¹ç”¨
            'DEPR_FA_COGA_DPBA',    # æŠ˜æ—§è´¹ç”¨
            'CASH_RECP_SG_AND_RS',  # é”€å”®å•†å“æ”¶ç°
            'BP'                    # å‡€èµ„äº§å¸‚å€¼æ¯”
        ]
        
        # è®¾ç½®å­—æ®µæ˜ å°„ï¼ˆå¦‚æœæ•°æ®åº“å­—æ®µåä¸åŒï¼‰
        self.field_mapping = {
            'fin_expense': 'FIN_EXP_CS',
            'depreciation': 'DEPR_FA_COGA_DPBA', 
            'sales_cash': 'CASH_RECP_SG_AND_RS',
            'book_to_price': 'BP'
        }
    
    def validate_data_requirements(self, data: Dict[str, pd.DataFrame]) -> bool:
        """éªŒè¯æ•°æ®å®Œæ•´æ€§"""
        try:
            validator = DataValidator()
            
            # æ£€æŸ¥è´¢åŠ¡æ•°æ®
            if 'financial_data' not in data:
                logger.error("ç¼ºå°‘è´¢åŠ¡æ•°æ®")
                return False
            
            financial_data = data['financial_data']
            
            # æ£€æŸ¥å¿…éœ€çš„è´¢åŠ¡å­—æ®µ
            financial_fields = ['FIN_EXP_CS', 'DEPR_FA_COGA_DPBA', 'CASH_RECP_SG_AND_RS']
            missing_fields = []
            
            for field in financial_fields:
                if field not in financial_data.columns:
                    # å°è¯•æ˜ å°„å­—æ®µå
                    mapped_field = self.get_mapped_column(field)
                    if mapped_field not in financial_data.columns:
                        missing_fields.append(field)
            
            if missing_fields:
                logger.error(f"è´¢åŠ¡æ•°æ®ç¼ºå°‘å­—æ®µ: {missing_fields}")
                return False
            
            # æ£€æŸ¥BPæ•°æ®
            if 'bp_data' not in data and 'BP' not in financial_data.columns:
                logger.error("ç¼ºå°‘BPï¼ˆå‡€èµ„äº§å¸‚å€¼æ¯”ï¼‰æ•°æ®")
                return False
            
            # éªŒè¯æ•°æ®è´¨é‡
            try:
                validator.validate_financial_data(
                    financial_data, 
                    ['FIN_EXP_CS', 'DEPR_FA_COGA_DPBA', 'CASH_RECP_SG_AND_RS']
                )
            except Exception as e:
                logger.error(f"è´¢åŠ¡æ•°æ®æ ¼å¼ä¸æ­£ç¡®: {e}")
                return False
            
            logger.info("æ•°æ®éªŒè¯é€šè¿‡")
            return True
            
        except Exception as e:
            logger.error(f"æ•°æ®éªŒè¯å¤±è´¥: {e}")
            return False
    
    def calculate(self, data: Dict[str, pd.DataFrame]) -> pd.Series:
        """
        è®¡ç®—ç°é‡‘æµæ•ˆç‡æ¯”ç‡å› å­
        
        Parameters
        ----------
        data : Dict[str, pd.DataFrame]
            åŒ…å«è´¢åŠ¡æ•°æ®çš„å­—å…¸
            - 'financial_data': è´¢åŠ¡æŠ¥è¡¨æ•°æ®ï¼ˆå¿…éœ€ï¼‰
            - 'bp_data': BPæ•°æ®ï¼ˆå¯é€‰ï¼Œå¦‚æœfinancial_dataä¸­æ²¡æœ‰BPåˆ—ï¼‰
            
        Returns
        -------
        pd.Series
            è®¡ç®—å¾—åˆ°çš„å› å­å€¼ï¼ŒMultiIndexæ ¼å¼(date, stock_code)
        """
        try:
            logger.info("å¼€å§‹è®¡ç®—ç°é‡‘æµæ•ˆç‡æ¯”ç‡å› å­")
            
            # éªŒè¯æ•°æ®
            if not self.validate_data_requirements(data):
                logger.error("æ•°æ®éªŒè¯å¤±è´¥")
                return pd.Series()
            
            financial_data = data['financial_data']
            
            # æå–æ‰€éœ€å­—æ®µ
            fin_expense = self._get_field_data(financial_data, 'FIN_EXP_CS', 'fin_expense')
            depreciation = self._get_field_data(financial_data, 'DEPR_FA_COGA_DPBA', 'depreciation')
            sales_cash = self._get_field_data(financial_data, 'CASH_RECP_SG_AND_RS', 'sales_cash')
            
            # è·å–BPæ•°æ®
            if 'bp_data' in data:
                bp = data['bp_data']
                if isinstance(bp, pd.DataFrame) and len(bp.columns) == 1:
                    bp = bp.iloc[:, 0]
            else:
                bp = self._get_field_data(financial_data, 'BP', 'book_to_price')
            
            logger.info(f"åŸå§‹æ•°æ®æå–å®Œæˆ - è´¢åŠ¡è´¹ç”¨: {len(fin_expense)}, æŠ˜æ—§: {len(depreciation)}, "
                       f"é”€å”®ç°é‡‘: {len(sales_cash)}, BP: {len(bp)}")
            
            # ğŸš€ ä¼˜åŒ–ï¼šåœ¨å­£åº¦é¢‘ç‡ä¸Šå…ˆè®¡ç®—ï¼Œå‡å°‘æ•°æ®å¡«å……é‡
            logger.info("åœ¨å­£åº¦é¢‘ç‡ä¸Šè¿›è¡Œè´¢åŠ¡æŒ‡æ ‡è®¡ç®—...")
            
            # ç¬¬ä¸€æ­¥ï¼šåœ¨å­£åº¦é¢‘ç‡ä¸Šè®¡ç®—ä¸­é—´ç»“æœ
            logger.info("è®¡ç®—å­£åº¦è´¢åŠ¡æŒ‡æ ‡...")
            
            # æ•°æ®å¯¹é½ï¼ˆå­£åº¦æ•°æ®å†…éƒ¨å¯¹é½ï¼‰
            quarterly_aligned = self._align_data([fin_expense, depreciation, sales_cash])
            if not quarterly_aligned:
                logger.error("å­£åº¦è´¢åŠ¡æ•°æ®å¯¹é½å¤±è´¥")
                return pd.Series()
            
            fin_expense_q, depreciation_q, sales_cash_q = quarterly_aligned
            
            # åœ¨å­£åº¦é¢‘ç‡ä¸Šè®¡ç®—ä¸­é—´æŒ‡æ ‡
            cost_sum_quarterly = fin_expense_q + depreciation_q
            
            # è®¡ç®—ç°é‡‘æµæ•ˆç‡æ¯”ç‡ï¼ˆå­£åº¦é¢‘ç‡ï¼‰
            cash_efficiency_quarterly = self._safe_divide(
                cost_sum_quarterly, sales_cash_q, 'cost_sum', 'sales_cash'
            )
            
            if cash_efficiency_quarterly.empty:
                logger.error("å­£åº¦ç°é‡‘æµæ•ˆç‡è®¡ç®—å¤±è´¥")
                return pd.Series()
            
            logger.info(f"å­£åº¦è®¡ç®—å®Œæˆï¼Œæœ‰æ•ˆæ ·æœ¬æ•°: {cash_efficiency_quarterly.notna().sum()}")
            
            # ç¬¬äºŒæ­¥ï¼šå°†è®¡ç®—ç»“æœæ‰©å±•åˆ°äº¤æ˜“æ—¥é¢‘ç‡ï¼ˆåªæ‰©å±•ä¸€æ¬¡ï¼‰
            logger.info("å°†è®¡ç®—ç»“æœæ‰©å±•åˆ°äº¤æ˜“æ—¥é¢‘ç‡...")
            
            from factors.base.time_series_processor import TimeSeriesProcessor
            
            # å‡†å¤‡ç°é‡‘æµæ•ˆç‡å­£åº¦æ•°æ®
            efficiency_df = pd.DataFrame({'cash_efficiency': cash_efficiency_quarterly})
            
            # è·å–äº¤æ˜“æ—¥æœŸï¼ˆä¼˜å…ˆä½¿ç”¨ç»Ÿä¸€çš„äº¤æ˜“æ—¥æœŸå·¥å…·ï¼‰
            try:
                from utils.trading_dates_utils import get_trading_dates
                # ä»BPæ•°æ®æ¨æ–­æ—¥æœŸèŒƒå›´
                bp_dates = bp.index.get_level_values(0).unique()
                start_date = bp_dates.min().strftime('%Y-%m-%d')
                end_date = bp_dates.max().strftime('%Y-%m-%d')
                trading_dates = get_trading_dates(start_date, end_date)
                logger.info(f"ä½¿ç”¨ç»Ÿä¸€äº¤æ˜“æ—¥å†ï¼Œè·å– {len(trading_dates)} ä¸ªäº¤æ˜“æ—¥")
            except Exception as e:
                logger.warning(f"ä½¿ç”¨ç»Ÿä¸€äº¤æ˜“æ—¥å†å¤±è´¥ï¼Œå›é€€åˆ°BPæ•°æ®æå–: {e}")
                trading_dates = bp.index.get_level_values(0).unique().sort_values()
            
            # å‡†å¤‡å‘å¸ƒæ—¥æœŸæ•°æ®
            if 'release_dates' in data:
                release_dates_df = data['release_dates']
            else:
                release_dates_df = self._create_default_release_dates(efficiency_df)
            
            # ğŸ”¥ ä½¿ç”¨ä¼˜åŒ–çš„æ‰©å±•æ–¹æ³•æå‡æ€§èƒ½
            try:
                from factors.base.optimized_time_series_processor import OptimizedTimeSeriesProcessor
                logger.info("ä½¿ç”¨ä¼˜åŒ–çš„å‘é‡åŒ–æ‰©å±•æ–¹æ³•...")
                cash_efficiency_daily = OptimizedTimeSeriesProcessor.expand_to_daily_vectorized(
                    efficiency_df,
                    release_dates_df,
                    trading_dates
                )
            except Exception as opt_error:
                logger.warning(f"ä¼˜åŒ–æ–¹æ³•å¤±è´¥ï¼Œå›é€€åˆ°åŸå§‹æ–¹æ³•: {opt_error}")
                # å›é€€åˆ°åŸå§‹æ–¹æ³•
                cash_efficiency_daily = TimeSeriesProcessor.expand_to_daily(
                    efficiency_df,
                    release_dates_df,
                    trading_dates
                )
            
            if cash_efficiency_daily.empty:
                logger.error("ç°é‡‘æµæ•ˆç‡æ•°æ®æ‰©å±•åˆ°æ—¥é¢‘å¤±è´¥")
                return pd.Series()
            
            # æå–æ—¥é¢‘ç°é‡‘æµæ•ˆç‡æ•°æ®
            cash_efficiency_series = cash_efficiency_daily['cash_efficiency']
            
            logger.info(f"æ‰©å±•å®Œæˆ - ç°é‡‘æµæ•ˆç‡æ—¥é¢‘æ•°æ®: {len(cash_efficiency_series)}")
            logger.info(f"  - ç°é‡‘æµæ•ˆç‡ç´¢å¼•ç±»å‹: {type(cash_efficiency_series.index)}")
            logger.info(f"  - ç°é‡‘æµæ•ˆç‡ç´¢å¼•åç§°: {cash_efficiency_series.index.names}")
            logger.info(f"  - BPæ•°æ®é•¿åº¦: {len(bp)}")
            logger.info(f"  - BPç´¢å¼•ç±»å‹: {type(bp.index)}")
            logger.info(f"  - BPç´¢å¼•åç§°: {bp.index.names}")
            
            # æ£€æŸ¥ç´¢å¼•å…¼å®¹æ€§
            if hasattr(cash_efficiency_series.index, 'names') and hasattr(bp.index, 'names'):
                if cash_efficiency_series.index.names != bp.index.names:
                    logger.warning(f"ç´¢å¼•åç§°ä¸åŒ¹é…: {cash_efficiency_series.index.names} vs {bp.index.names}")
            
            # é‡‡æ ·æ£€æŸ¥æ•°æ®è´¨é‡
            logger.info(f"ç°é‡‘æµæ•ˆç‡æœ‰æ•ˆå€¼æ¯”ä¾‹: {cash_efficiency_series.notna().mean():.2%}")
            logger.info(f"BPæœ‰æ•ˆå€¼æ¯”ä¾‹: {bp.notna().mean():.2%}")
            
            # ç¬¬ä¸‰æ­¥ï¼šä¸æ—¥é¢‘BPæ•°æ®å¯¹é½å¹¶è®¡ç®—æœ€ç»ˆå› å­
            logger.info("ä¸BPå› å­å¯¹é½å¹¶è®¡ç®—æœ€ç»ˆç»“æœ...")
            
            aligned_data = self._align_data([cash_efficiency_series, bp])
            if not aligned_data:
                logger.error("ä¸BPæ•°æ®å¯¹é½å¤±è´¥")
                return pd.Series()
            
            cash_efficiency_aligned, bp_aligned = aligned_data
            
            # è®¡ç®—æœ€ç»ˆå› å­ï¼šç°é‡‘æµæ•ˆç‡ / BP
            factor_result = self._safe_divide(cash_efficiency_aligned, bp_aligned, 'cash_efficiency', 'BP')
            
            # æ•°æ®æ¸…ç†å’Œå¼‚å¸¸å€¼å¤„ç†
            factor_result = self.handle_outliers(factor_result, method='winsorize', quantiles=(0.01, 0.99))
            factor_result = self.fill_missing_values(factor_result, method='median')
            
            factor_result.name = self.factor_name
            
            logger.info(f"âœ… ç°é‡‘æµæ•ˆç‡æ¯”ç‡å› å­è®¡ç®—å®Œæˆï¼Œæœ‰æ•ˆæ ·æœ¬æ•°: {factor_result.notna().sum()}")
            
            return factor_result
            
        except Exception as e:
            logger.error(f"è®¡ç®—ç°é‡‘æµæ•ˆç‡æ¯”ç‡å› å­å¤±è´¥: {e}")
            return pd.Series()
    
    def _get_field_data(self, data: pd.DataFrame, primary_field: str, mapping_key: str) -> pd.Series:
        """è·å–å­—æ®µæ•°æ®ï¼Œæ”¯æŒå­—æ®µæ˜ å°„"""
        if primary_field in data.columns:
            return data[primary_field]
        
        # å°è¯•ä½¿ç”¨æ˜ å°„
        mapped_field = self.get_mapped_column(mapping_key)
        if mapped_field in data.columns:
            logger.info(f"ä½¿ç”¨å­—æ®µæ˜ å°„: {mapping_key} -> {mapped_field}")
            return data[mapped_field]
        
        raise ValueError(f"æ— æ³•æ‰¾åˆ°å­—æ®µ: {primary_field} æˆ–å…¶æ˜ å°„å­—æ®µ")
    
    def _align_data(self, series_list):
        """å¯¹é½å¤šä¸ªSeriesæ•°æ®"""
        try:
            # è·å–å…¬å…±ç´¢å¼•
            common_index = series_list[0].index
            for series in series_list[1:]:
                common_index = common_index.intersection(series.index)
            
            if len(common_index) < 100:
                logger.warning(f"å¯¹é½åæ•°æ®é‡è¾ƒå°‘: {len(common_index)}")
                return None
            
            # å¯¹é½æ‰€æœ‰æ•°æ®
            aligned_series = []
            for series in series_list:
                aligned = series.loc[common_index]
                aligned_series.append(aligned)
            
            logger.info(f"æ•°æ®å¯¹é½å®Œæˆï¼Œå…¬å…±æ ·æœ¬æ•°: {len(common_index)}")
            return aligned_series
            
        except Exception as e:
            logger.error(f"æ•°æ®å¯¹é½å¤±è´¥: {e}")
            return None
    
    def _safe_divide(self, numerator: pd.Series, denominator: pd.Series, 
                     num_name: str = "numerator", den_name: str = "denominator") -> pd.Series:
        """å®‰å…¨é™¤æ³•ï¼Œå¤„ç†é™¤é›¶å’Œå¼‚å¸¸å€¼"""
        try:
            # å¤„ç†é™¤é›¶æƒ…å†µ
            denominator_safe = denominator.replace(0, np.nan)
            
            # è¿‡æ»¤æå€¼
            denominator_safe = denominator_safe.where(
                (denominator_safe.abs() > 1e-6) & (denominator_safe.abs() < 1e10)
            )
            
            result = numerator / denominator_safe
            
            # è®°å½•ç»Ÿè®¡ä¿¡æ¯
            valid_count = result.notna().sum()
            zero_count = (denominator == 0).sum()
            
            logger.info(f"{num_name} / {den_name}: æœ‰æ•ˆå€¼ {valid_count}, åˆ†æ¯ä¸ºé›¶ {zero_count}")
            
            return result
            
        except Exception as e:
            logger.error(f"å®‰å…¨é™¤æ³•è®¡ç®—å¤±è´¥: {e}")
            return pd.Series()
    
    
    def _create_default_release_dates(self, financial_df: pd.DataFrame) -> pd.DataFrame:
        """
        åˆ›å»ºé»˜è®¤çš„å‘å¸ƒæ—¥æœŸæ•°æ®
        å‡è®¾è´¢åŠ¡æ•°æ®åœ¨æŠ¥å‘ŠæœŸç»“æŸå3ä¸ªæœˆå†…å‘å¸ƒ
        """
        try:
            # æå–æŠ¥å‘Šæ—¥æœŸå’Œè‚¡ç¥¨ä»£ç 
            report_dates = financial_df.index.get_level_values(0)
            stock_codes = financial_df.index.get_level_values(1)
            
            # åˆ›å»ºå‘å¸ƒæ—¥æœŸï¼šæŠ¥å‘ŠæœŸç»“æŸå90å¤©ï¼ˆçº¦3ä¸ªæœˆï¼‰
            release_dates = report_dates + pd.Timedelta(days=90)
            
            # åˆ›å»ºå‘å¸ƒæ—¥æœŸDataFrame
            release_df = pd.DataFrame({
                'ReleasedDates': release_dates
            }, index=financial_df.index)
            
            logger.info(f"åˆ›å»ºé»˜è®¤å‘å¸ƒæ—¥æœŸï¼Œæ ·æœ¬æ•°: {len(release_df)}")
            return release_df
            
        except Exception as e:
            logger.error(f"åˆ›å»ºé»˜è®¤å‘å¸ƒæ—¥æœŸå¤±è´¥: {e}")
            # è¿”å›ç©ºDataFrameï¼Œå°†ä½¿ç”¨æŠ¥å‘ŠæœŸä½œä¸ºå‘å¸ƒæ—¥æœŸ
            return pd.DataFrame()
    
    def _get_trading_calendar(self, start_date, end_date):
        """
        è·å–äº¤æ˜“æ—¥å†ï¼ˆå¦‚æœéœ€è¦çš„è¯ï¼‰
        è¿™é‡Œå¯ä»¥è¿æ¥åˆ°äº¤æ˜“æ‰€æ—¥å†APIæˆ–ä½¿ç”¨æœ¬åœ°æ•°æ®
        """
        try:
            # ç®€åŒ–å®ç°ï¼šç”Ÿæˆå·¥ä½œæ—¥åºåˆ—ï¼Œæ’é™¤å‘¨æœ«
            # å®é™…ä½¿ç”¨ä¸­åº”è¯¥ä½¿ç”¨å‡†ç¡®çš„äº¤æ˜“æ—¥å†
            dates = pd.bdate_range(start=start_date, end=end_date)
            logger.info(f"ç”Ÿæˆäº¤æ˜“æ—¥å†: {len(dates)} ä¸ªäº¤æ˜“æ—¥")
            return dates
        except Exception as e:
            logger.error(f"è·å–äº¤æ˜“æ—¥å†å¤±è´¥: {e}")
            return pd.DatetimeIndex([])


# å› å­å·¥å‚å‡½æ•°ï¼Œæ–¹ä¾¿è°ƒç”¨
def create_cashflow_efficiency_ratio() -> CashflowEfficiencyRatio:
    """åˆ›å»ºç°é‡‘æµæ•ˆç‡æ¯”ç‡å› å­å®ä¾‹"""
    return CashflowEfficiencyRatio()


# æ³¨å†Œå› å­åˆ°å…ƒæ•°æ®ç³»ç»Ÿ
def register_factor_metadata():
    """æ³¨å†Œå› å­åˆ°å…ƒæ•°æ®ç³»ç»Ÿ"""
    try:
        from factors.meta import get_factor_registry, FactorType, NeutralizationCategory
        
        registry = get_factor_registry()
        
        registry.register_factor(
            name="CashflowEfficiencyRatio",
            factor_type=FactorType.DERIVED,
            description="ç°é‡‘æµæ•ˆç‡æ¯”ç‡ï¼š(è´¢åŠ¡è´¹ç”¨+æŠ˜æ—§)/é”€å”®ç°é‡‘æµ/å‡€èµ„äº§å¸‚å€¼æ¯”",
            formula="((FIN_EXP_CS + DEPR_FA_COGA_DPBA) / CASH_RECP_SG_AND_RS) / BP",
            neutralization_category=NeutralizationCategory.OPTIONAL_NEUTRALIZE,
            generator="CashflowEfficiencyRatio",
            tags=["custom", "mixed", "cashflow", "efficiency"],
            category="financial_efficiency",
            priority=5
        )
        
        logger.info("âœ… å› å­å…ƒæ•°æ®æ³¨å†ŒæˆåŠŸ")
        
    except Exception as e:
        logger.warning(f"å› å­å…ƒæ•°æ®æ³¨å†Œå¤±è´¥: {e}")


if __name__ == "__main__":
    # ç¤ºä¾‹ä½¿ç”¨
    logging.basicConfig(level=logging.INFO)
    
    # æ³¨å†Œå› å­å…ƒæ•°æ®
    register_factor_metadata()
    
    print("ç°é‡‘æµæ•ˆç‡æ¯”ç‡å› å­å¼€å‘å®Œæˆï¼")
    print("ä½¿ç”¨æ–¹æ³•:")
    print("1. factor = create_cashflow_efficiency_ratio()")
    print("2. result = factor.calculate(data)")