#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½¿ç”¨experimental_labæ¡†æ¶å®ç°ç®€åŒ–ç‰ˆç›ˆåˆ©èƒ½åŠ›å› å­
ç®€åŒ–ç‰ˆæœ¬: TTMå‡€åˆ©æ¶¦ / æ€»æµåŠ¨è´Ÿå€º / 5æ—¥æ”¶ç›Šç‡z-score

è¿™ä¸ªç‰ˆæœ¬ç®€åŒ–äº†åŸæ¥çš„å¤æ‚å…¬å¼ï¼Œä¸“æ³¨éªŒè¯experimental_labæ¡†æ¶çš„å®Œæ•´å·¥ä½œæµç¨‹
"""

import pandas as pd
import numpy as np
from typing import Dict, Any
import logging

# ä½¿ç”¨æ–°çš„experimental_labæ¡†æ¶
from factors.experimental_lab import ExperimentalFactorManager

# å¿…é¡»ä½¿ç”¨çš„å·¥å…·é›†
from factors.generators import (
    calculate_ttm,
    expand_to_daily_vectorized,
    FinancialReportProcessor
)

# æ•°æ®åŠ è½½å™¨
from factors.utils.data_loader import FactorDataLoader

logger = logging.getLogger(__name__)


def calculate_simplified_profitability_factor(context=None, **kwargs) -> pd.Series:
    """
    è®¡ç®—ç®€åŒ–ç‰ˆç›ˆåˆ©èƒ½åŠ›å› å­
    
    å…¬å¼: TTMå‡€åˆ©æ¶¦ / æ€»æµåŠ¨è´Ÿå€º / 5æ—¥æ”¶ç›Šç‡æˆªé¢z-score
    
    Parameters:
    -----------
    context : CalculationContext
        è®¡ç®—ä¸Šä¸‹æ–‡ï¼Œæä¾›æ•°æ®å’Œå·¥å…·
    **kwargs : dict
        å…¶ä»–è®¡ç®—å‚æ•°
        
    Returns:
    --------
    pd.Series
        å› å­æ•°æ®ï¼ŒMultiIndex[TradingDates, StockCodes]æ ¼å¼
    """
    logger.info("å¼€å§‹è®¡ç®—ç®€åŒ–ç‰ˆç›ˆåˆ©èƒ½åŠ›å› å­")
    
    # 1. è·å–å¿…è¦çš„æ•°æ®ï¼ˆä½¿ç”¨contextæä¾›çš„æ ‡å‡†æ¥å£ï¼‰
    financial_data = context.load_financial_data()
    price_data = context.load_price_data()
    trading_dates = context.load_trading_dates()
    
    # 2. è·å–generatorså·¥å…·é›†ï¼ˆä¸¥ç¦é‡å¤å®ç°ï¼‰
    tools = context.get_generators_tools()
    calculate_ttm_func = tools['calculate_ttm']
    expand_to_daily_func = tools['expand_to_daily_vectorized']
    
    # 3. è®¡ç®—TTMå‡€åˆ©æ¶¦
    logger.info("è®¡ç®—TTMå‡€åˆ©æ¶¦")
    ttm_data = calculate_ttm_func(financial_data)
    ttm_profit = ttm_data.get('NET_PROFIT_IS_ttm', pd.Series())
    
    if ttm_profit.empty:
        raise ValueError("TTMå‡€åˆ©æ¶¦æ•°æ®ç¼ºå¤±ï¼Œè¯·æ£€æŸ¥NET_PROFIT_IS_ttmå­—æ®µ")
    
    # 4. æå–æ€»æµåŠ¨è´Ÿå€º
    logger.info("æå–æ€»æµåŠ¨è´Ÿå€ºæ•°æ®")
    current_liabilities = financial_data.get('TOT_CUR_LIAB', pd.Series())
    
    if current_liabilities.empty:
        raise ValueError("æ€»æµåŠ¨è´Ÿå€ºæ•°æ®ç¼ºå¤±ï¼Œè¯·æ£€æŸ¥TOT_CUR_LIABå­—æ®µ")
    
    # ä½¿ç”¨æœ€æ–°çš„è´Ÿå€ºæ•°æ®
    latest_liabilities = current_liabilities.groupby('StockCodes').last()
    
    # 5. è®¡ç®—åŸºç¡€å› å­ï¼šTTMå‡€åˆ©æ¶¦ / æ€»æµåŠ¨è´Ÿå€º
    logger.info("è®¡ç®—åŸºç¡€å› å­å€¼")
    
    # å°†æµåŠ¨è´Ÿå€ºæ‰©å±•åˆ°ä¸TTMåˆ©æ¶¦ç›¸åŒçš„ç´¢å¼•
    expanded_liabilities = pd.Series(index=ttm_profit.index, dtype=float)
    for stock_code in ttm_profit.index.get_level_values('StockCodes').unique():
        if stock_code in latest_liabilities.index:
            mask = ttm_profit.index.get_level_values('StockCodes') == stock_code
            expanded_liabilities.loc[mask] = latest_liabilities.loc[stock_code]
    
    # è®¡ç®—æ¯”ç‡ï¼Œå¤„ç†é™¤é›¶æƒ…å†µ
    with np.errstate(divide='ignore', invalid='ignore'):
        basic_factor = ttm_profit / expanded_liabilities.fillna(1)
    
    # å¤„ç†å¼‚å¸¸å€¼
    basic_factor = basic_factor.replace([np.inf, -np.inf], np.nan)
    basic_factor = basic_factor.dropna()
    
    if basic_factor.empty:
        raise ValueError("åŸºç¡€å› å­è®¡ç®—ç»“æœä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®è´¨é‡")
    
    # 6. è®¡ç®—5æ—¥æ”¶ç›Šç‡
    logger.info("è®¡ç®—5æ—¥æ”¶ç›Šç‡")
    
    # ç¡®ä¿ä»·æ ¼æ•°æ®æ ¼å¼æ­£ç¡®
    if not isinstance(price_data.index, pd.MultiIndex):
        raise ValueError("ä»·æ ¼æ•°æ®å¿…é¡»æ˜¯MultiIndex[TradingDates, StockCodes]æ ¼å¼")
    
    # è®¡ç®—5æ—¥å¯¹æ•°æ”¶ç›Šç‡ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼šåªå–ä¸€ä¸ªæ ·æœ¬ï¼‰
    price_sample = price_data.iloc[:100000]  # é™åˆ¶æ•°æ®é‡ä»¥æé«˜é€Ÿåº¦
    price_sample_sorted = price_sample.sort_index()
    returns_5d = price_sample_sorted.groupby(level=1).apply(
        lambda x: np.log(x / x.shift(5))
    ).dropna()
    
    # 7. è®¡ç®—5æ—¥æ”¶ç›Šç‡çš„æˆªé¢z-score
    logger.info("è®¡ç®—æ”¶ç›Šç‡æˆªé¢z-score")
    
    def calculate_cross_sectional_zscore(group):
        """è®¡ç®—æˆªé¢z-score"""
        if len(group) < 2:
            return group
        return (group - group.mean()) / (group.std() + 1e-8)
    
    returns_zscore = returns_5d.groupby(level=0).apply(calculate_cross_sectional_zscore)
    returns_zscore = returns_zscore.dropna()
    
    # 8. ä½¿ç”¨å®˜æ–¹æ—¥é¢‘æ‰©å±•å·¥å…·ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
    logger.info("æ‰©å±•è´¢åŠ¡æ•°æ®åˆ°æ—¥é¢‘")
    
    # å°†åŸºç¡€å› å­è½¬æ¢ä¸ºDataFrameæ ¼å¼
    basic_factor_df = basic_factor.to_frame('simplified_profitability_raw')
    
    # ç®€åŒ–çš„å‘å¸ƒæ—¥æœŸå¤„ç†
    base_dates = basic_factor.index.get_level_values('TradingDates')
    release_dates = base_dates + pd.DateOffset(months=1)
    
    # ä½¿ç”¨å®˜æ–¹æ‰©å±•å·¥å…·ï¼ˆä»…å¤„ç†æœ€è¿‘ä¸€å¹´çš„æ•°æ®ä»¥æé«˜é€Ÿåº¦ï¼‰
    recent_trading_dates = trading_dates[-252:]  # æœ€è¿‘ä¸€å¹´äº¤æ˜“æ—¥
    
    daily_basic_factor = expand_to_daily_func(
        factor_data=basic_factor_df,
        release_dates=release_dates,
        trading_dates=recent_trading_dates
    )
    
    # æå–Series
    daily_basic_factor = daily_basic_factor['simplified_profitability_raw']
    
    # 9. æœ€ç»ˆè®¡ç®—ï¼šåŸºç¡€å› å­ / æ”¶ç›Šç‡z-score
    logger.info("è®¡ç®—æœ€ç»ˆå› å­å€¼")
    
    # å¯¹é½ä¸¤ä¸ªæ•°æ®ï¼ˆåªå–å…±åŒçš„ç´¢å¼•ï¼‰
    common_index = daily_basic_factor.index.intersection(returns_zscore.index)
    
    if len(common_index) < 100:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®ç‚¹
        logger.warning(f"å…±åŒæ•°æ®ç‚¹è¾ƒå°‘: {len(common_index)}ï¼Œä½¿ç”¨åŸºç¡€å› å­ä½œä¸ºæœ€ç»ˆç»“æœ")
        final_factor = daily_basic_factor
    else:
        aligned_basic = daily_basic_factor.loc[common_index]
        aligned_returns_zscore = returns_zscore.loc[common_index]
        
        # æœ€ç»ˆè®¡ç®—ï¼Œå¤„ç†é™¤é›¶
        with np.errstate(divide='ignore', invalid='ignore'):
            final_factor = aligned_basic / (aligned_returns_zscore + 1e-8)
        
        # æ¸…ç†å¼‚å¸¸å€¼
        final_factor = final_factor.replace([np.inf, -np.inf], np.nan)
        final_factor = final_factor.dropna()
    
    # 10. æ•°æ®è´¨é‡æ£€æŸ¥
    if final_factor.empty:
        raise ValueError("æœ€ç»ˆå› å­è®¡ç®—ç»“æœä¸ºç©º")
    
    if not isinstance(final_factor.index, pd.MultiIndex):
        raise ValueError("è¿”å›æ•°æ®å¿…é¡»æ˜¯MultiIndexæ ¼å¼")
    
    logger.info(f"ç®€åŒ–ç‰ˆç›ˆåˆ©èƒ½åŠ›å› å­è®¡ç®—å®Œæˆï¼Œæ•°æ®ç‚¹æ•°: {len(final_factor)}")
    logger.info(f"å› å­å€¼èŒƒå›´: {final_factor.min():.4f} ~ {final_factor.max():.4f}")
    logger.info(f"å› å­å‡å€¼: {final_factor.mean():.4f}, æ ‡å‡†å·®: {final_factor.std():.4f}")
    
    return final_factor


def main():
    """ä¸»å‡½æ•°ï¼šæ‰§è¡Œå®Œæ•´çš„å› å­å¼€å‘å·¥ä½œæµç¨‹"""
    
    # åˆ›å»ºå®éªŒå› å­ç®¡ç†å™¨
    logger.info("åˆ›å»ºå®éªŒå› å­ç®¡ç†å™¨")
    manager = ExperimentalFactorManager()
    
    # å› å­åŸºæœ¬ä¿¡æ¯
    factor_name = "simplified_profitability_factor"
    factor_description = """
    ç®€åŒ–ç‰ˆç›ˆåˆ©èƒ½åŠ›å› å­ï¼šTTMå‡€åˆ©æ¶¦ / æ€»æµåŠ¨è´Ÿå€º / 5æ—¥æ”¶ç›Šç‡æˆªé¢z-score
    
    ç»æµå«ä¹‰ï¼š
    - åˆ†å­è¡¡é‡ä¼ä¸šçš„ç›ˆåˆ©èƒ½åŠ›ï¼ˆTTMå‡€åˆ©æ¶¦ï¼‰
    - åˆ†æ¯è¡¡é‡ä¼ä¸šçŸ­æœŸå¿å€ºå‹åŠ›ï¼ˆæ€»æµåŠ¨è´Ÿå€ºï¼‰
    - é™¤ä»¥æ”¶ç›Šç‡z-scoreè¿›è¡Œå¸‚åœºæƒ…ç»ªè°ƒæ•´
    
    é¢„æœŸï¼šè¯¥å› å­åº”è¯¥èƒ½å¤Ÿè¯†åˆ«å…·æœ‰è‰¯å¥½ç›ˆåˆ©èƒ½åŠ›ä¸”çŸ­æœŸå¿å€ºå‹åŠ›è¾ƒå°çš„è‚¡ç¥¨
    
    æ³¨ï¼šè¿™æ˜¯å¤æ‚ç‰ˆæœ¬çš„ç®€åŒ–å®ç°ï¼Œç”¨äºéªŒè¯experimental_labæ¡†æ¶
    """
    
    try:
        # æ‰§è¡Œå®Œæ•´å·¥ä½œæµç¨‹
        logger.info(f"å¼€å§‹æ‰§è¡Œå› å­ {factor_name} å®Œæ•´å·¥ä½œæµç¨‹")
        
        workflow_result = manager.full_workflow(
            name=factor_name,
            calculation_func=calculate_simplified_profitability_factor,
            description=factor_description,
            category="profitability",
            calculation_params={},
            test_params={
                'group_nums': 5,  # å‡å°‘åˆ†ç»„æ•°ä»¥æé«˜é€Ÿåº¦
                'outlier_method': 'IQR',
                'outlier_param': 3,
                'ic_decay_periods': 10  # å‡å°‘å‘¨æœŸæ•°
            },
            auto_decision=True
        )
        
        # åˆ†æå·¥ä½œæµç¨‹ç»“æœ
        print("\n" + "="*60)
        print("ç®€åŒ–ç‰ˆç›ˆåˆ©èƒ½åŠ›å› å­å¼€å‘å·¥ä½œæµç¨‹å®Œæˆ")
        print("="*60)
        
        print(f"å› å­åç§°: {workflow_result['factor_name']}")
        print(f"å·¥ä½œæµç¨‹æˆåŠŸ: {workflow_result['success']}")
        print(f"æœ€ç»ˆçŠ¶æ€: {workflow_result['final_status']}")
        print(f"æ€»è€—æ—¶: {workflow_result.get('total_time', 0):.2f}ç§’")
        
        # å±•ç¤ºå„é˜¶æ®µç»“æœ
        print("\né˜¶æ®µæ‰§è¡Œæƒ…å†µ:")
        for stage_name, stage_result in workflow_result['stages'].items():
            status = "âœ“ æˆåŠŸ" if stage_result['success'] else "âœ— å¤±è´¥"
            print(f"  {stage_name}: {status}")
            if 'time_cost' in stage_result:
                print(f"    è€—æ—¶: {stage_result['time_cost']:.2f}ç§’")
            if 'error_msg' in stage_result and stage_result['error_msg']:
                print(f"    é”™è¯¯: {stage_result['error_msg']}")
        
        # å±•ç¤ºæ€§èƒ½æŒ‡æ ‡
        if 'performance_metrics' in workflow_result:
            print("\næ€§èƒ½æŒ‡æ ‡:")
            metrics = workflow_result['performance_metrics']
            for metric, value in metrics.items():
                print(f"  {metric}: {value:.4f}")
        
        # è·å–å› å­è¯¦ç»†ä¿¡æ¯
        factor_info = manager.get_factor_info(factor_name)
        if factor_info:
            print(f"\nå› å­è¯¦ç»†ä¿¡æ¯:")
            print(f"  åˆ†ç±»: {factor_info['basic_info']['category']}")
            print(f"  çŠ¶æ€: {factor_info['basic_info']['status']}")
            
            if 'lifecycle' in factor_info:
                lifecycle = factor_info['lifecycle']
                print(f"  è®¡ç®—æˆåŠŸ: {lifecycle['calculation_success']}")
                print(f"  æµ‹è¯•æˆåŠŸ: {lifecycle['test_success']}")
                print(f"  æå‡å†³ç­–: {lifecycle['promotion_decision'] or 'å¾…å®š'}")
        
        # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
        summary_report = manager.get_summary_report()
        print(f"\nç®¡ç†å™¨æ±‡æ€»:")
        print(f"  æ€»å› å­æ•°: {summary_report['total_factors']}")
        print(f"  å„çŠ¶æ€åˆ†å¸ƒ: {summary_report['status_distribution']}")
        
        # å¯¼å‡ºç»™ç­›é€‰å™¨ä½¿ç”¨çš„æ•°æ®
        screening_data = manager.export_for_screening(performance_threshold=0)
        print(f"\nç­›é€‰å™¨æ•°æ®å¯¼å‡º:")
        print(f"  ç¬¦åˆæ¡ä»¶çš„å› å­æ•°: {screening_data['metadata']['total_qualified_factors']}")
        
        if workflow_result['success']:
            print(f"\nğŸ‰ ç®€åŒ–ç‰ˆç›ˆåˆ©èƒ½åŠ›å› å­å¼€å‘æˆåŠŸï¼")
            print(f"experimental_labæ¡†æ¶å·¥ä½œæµç¨‹éªŒè¯å®Œæˆã€‚")
        else:
            print(f"\nâŒ å› å­å¼€å‘è¿‡ç¨‹ä¸­å‡ºç°é—®é¢˜ï¼Œè¯·æ£€æŸ¥æ—¥å¿—è·å–è¯¦ç»†ä¿¡æ¯ã€‚")
            
    except Exception as e:
        logger.error(f"æ‰§è¡Œå·¥ä½œæµç¨‹å¤±è´¥: {e}")
        print(f"\nâŒ å·¥ä½œæµç¨‹æ‰§è¡Œå¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    print("å¼€å§‹ä½¿ç”¨experimental_labæ¡†æ¶å¼€å‘ç®€åŒ–ç‰ˆç›ˆåˆ©èƒ½åŠ›å› å­")
    print("="*60)
    
    main()