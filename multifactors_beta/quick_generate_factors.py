#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿå› å­ç”Ÿæˆè„šæœ¬ âš¡
ç”¨äºå¿«é€Ÿç”Ÿæˆå¸¸ç”¨çš„æ ¸å¿ƒå› å­ï¼Œé€‚åˆæ–°æ‰‹ç”¨æˆ·

ç‰¹ç‚¹ï¼š
- ğŸ¯ é¢„è®¾æ ¸å¿ƒå› å­é›†åˆ
- âš¡ ç®€åŒ–çš„æ“ä½œæµç¨‹  
- ğŸ“Š è‡ªåŠ¨æ•°æ®æ£€æŸ¥
- ğŸ’¾ æ ‡å‡†åŒ–è¾“å‡ºæ ¼å¼
- ğŸš€ ä¸€é”®è¿è¡Œ

ä½¿ç”¨æ–¹å¼ï¼š
python quick_generate_factors.py              # ç”Ÿæˆæ ¸å¿ƒå› å­
python quick_generate_factors.py --basic      # ç”ŸæˆåŸºç¡€å› å­
python quick_generate_factors.py --test       # ç”Ÿæˆæµ‹è¯•å› å­
"""

import sys
import os
from pathlib import Path
import pandas as pd
import numpy as np
import logging
import time
from datetime import datetime
from typing import Dict, List, Optional, Tuple
import argparse

# é…ç½®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from config import get_config
from factors.generator.financial.pure_financial_factors import PureFinancialFactorCalculator
from factors.generator.mixed import get_mixed_factor_manager

# è®¾ç½®ç®€å•æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class QuickFactorGenerator:
    """å¿«é€Ÿå› å­ç”Ÿæˆå™¨"""
    
    # é¢„å®šä¹‰å› å­é›†åˆ
    FACTOR_SETS = {
        'core': {
            'description': 'æ ¸å¿ƒå› å­é›†åˆ - æœ€é‡è¦çš„15ä¸ªå› å­',
            'factors': [
                'ROE_ttm', 'ROA_ttm', 'BP', 'EP_ttm', 'Size', 
                'CurrentRatio', 'DebtToAssets', 'AssetTurnover_ttm',
                'GrossProfitMargin_ttm', 'NetProfitMargin_ttm',
                'RevenueGrowth_yoy', 'NetIncomeGrowth_yoy', 
                'OperatingCashFlowRatio_ttm', 'EarningsQuality_ttm',
                'ROIC_ttm'
            ]
        },
        'basic': {
            'description': 'åŸºç¡€å› å­é›†åˆ - æ¶µç›–ä¸»è¦å› å­ç±»åˆ«',
            'factors': [
                'ROE_ttm', 'BP', 'Size', 'CurrentRatio', 
                'AssetTurnover_ttm', 'GrossProfitMargin_ttm',
                'RevenueGrowth_yoy', 'OperatingCashFlowRatio_ttm'
            ]
        },
        'test': {
            'description': 'æµ‹è¯•å› å­é›†åˆ - ç”¨äºå¿«é€Ÿæµ‹è¯•',
            'factors': [
                'ROE_ttm', 'BP', 'Size', 'CurrentRatio'
            ]
        }
    }
    
    def __init__(self):
        """åˆå§‹åŒ–å¿«é€Ÿå› å­ç”Ÿæˆå™¨"""
        self.data_root = Path(get_config('main.paths.data_root'))
        self.auxiliary_path = project_root / 'data' / 'auxiliary'
        self.output_dir = self.data_root / 'factors'
        self.output_dir.mkdir(exist_ok=True, parents=True)
        
        self.data = {}
        self.calculator = None
        
        logger.info("å¿«é€Ÿå› å­ç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"è¾“å‡ºç›®å½•: {self.output_dir}")
    
    def check_data_availability(self) -> bool:
        """æ£€æŸ¥æ•°æ®å¯ç”¨æ€§"""
        logger.info("ğŸ” æ£€æŸ¥æ•°æ®å¯ç”¨æ€§...")
        
        required_files = {
            'financial_data': self.auxiliary_path / 'FinancialData_unified.pkl',
            'market_cap': [
                self.data_root / 'MarketCap.pkl',
                self.data_root / 'LogMarketCap.pkl'
            ]
        }
        
        missing_files = []
        available_files = {}
        
        for key, file_paths in required_files.items():
            if isinstance(file_paths, list):
                found = False
                for file_path in file_paths:
                    if file_path.exists():
                        available_files[key] = file_path
                        found = True
                        break
                if not found:
                    missing_files.append(f"{key} (å°è¯•: {[str(p) for p in file_paths]})")
            else:
                if file_paths.exists():
                    available_files[key] = file_paths
                else:
                    missing_files.append(str(file_paths))
        
        if missing_files:
            logger.error("âŒ ç¼ºå°‘å¿…è¦æ•°æ®æ–‡ä»¶:")
            for file in missing_files:
                logger.error(f"   - {file}")
            logger.error("\nè¯·å…ˆè¿è¡Œä»¥ä¸‹å‘½ä»¤å‡†å¤‡æ•°æ®:")
            logger.error("1. python data/prepare_auxiliary_data.py")
            logger.error("2. python scheduled_data_updater.py --data-type financial")
            return False
        
        logger.info("âœ… æ‰€æœ‰å¿…è¦æ•°æ®æ–‡ä»¶éƒ½å¯ç”¨")
        self.available_files = available_files
        return True
    
    def load_data(self) -> bool:
        """åŠ è½½æ•°æ®"""
        logger.info("ğŸ“Š åŠ è½½æ•°æ®...")
        
        try:
            # åŠ è½½è´¢åŠ¡æ•°æ®
            financial_file = self.available_files['financial_data']
            self.data['financial_data'] = pd.read_pickle(financial_file)
            logger.info(f"âœ… è´¢åŠ¡æ•°æ®: {self.data['financial_data'].shape}")
            
            # åŠ è½½å¸‚å€¼æ•°æ®
            market_cap_file = self.available_files['market_cap']
            market_cap = pd.read_pickle(market_cap_file)
            
            # å¤„ç†å¸‚å€¼æ•°æ®æ ¼å¼
            if isinstance(market_cap, pd.DataFrame):
                market_cap = market_cap.iloc[:, 0]
            
            # å¦‚æœæ˜¯å¯¹æ•°å¸‚å€¼ï¼Œè½¬æ¢ä¸ºåŸå§‹å€¼
            if market_cap.median() < 100:
                logger.info("è½¬æ¢å¯¹æ•°å¸‚å€¼ä¸ºåŸå§‹å¸‚å€¼")
                market_cap = np.exp(market_cap)
            
            self.data['market_cap'] = market_cap
            logger.info(f"âœ… å¸‚å€¼æ•°æ®: {market_cap.shape}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return False
    
    def create_calculator(self) -> bool:
        """åˆ›å»ºå› å­è®¡ç®—å™¨"""
        try:
            self.calculator = PureFinancialFactorCalculator()
            self.mixed_manager = get_mixed_factor_manager()
            logger.info("âœ… å› å­è®¡ç®—å™¨åˆ›å»ºæˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"âŒ å› å­è®¡ç®—å™¨åˆ›å»ºå¤±è´¥: {e}")
            return False
    
    def generate_factor(self, factor_name: str) -> Optional[pd.Series]:
        """ç”Ÿæˆå•ä¸ªå› å­"""
        try:
            start_time = time.time()
            
            # æ ¹æ®å› å­åç§°è°ƒç”¨ç›¸åº”æ–¹æ³•
            if factor_name == 'Size':
                factor_data = self.data['market_cap']
            elif factor_name == 'LogSize':
                factor_data = np.log(self.data['market_cap'])
            elif factor_name in ['BP', 'EP_ttm', 'SP_ttm', 'CFP_ttm']:
                # æ··åˆå› å­ï¼ˆä¼°å€¼å› å­ï¼‰
                factor_data = self.mixed_manager.calculate_factor(
                    factor_name, self.data
                )
            else:
                # çº¯è´¢åŠ¡å› å­
                method_name = f'calculate_{factor_name}'
                if hasattr(self.calculator, method_name):
                    method = getattr(self.calculator, method_name)
                    factor_data = method(self.data['financial_data'])
                else:
                    logger.warning(f"å› å­è®¡ç®—æ–¹æ³•ä¸å­˜åœ¨: {method_name}")
                    return None
            
            duration = time.time() - start_time
            
            if factor_data is not None and not factor_data.empty:
                logger.info(f"  âœ… {factor_name}: {factor_data.shape} ({duration:.1f}s)")
                return factor_data
            else:
                logger.error(f"  âŒ {factor_name}: ç”Ÿæˆå¤±è´¥æˆ–ç»“æœä¸ºç©º")
                return None
                
        except Exception as e:
            logger.error(f"  âŒ {factor_name}: {str(e)}")
            return None
    
    def validate_factor(self, factor_name: str, factor_data: pd.Series) -> Dict[str, float]:
        """éªŒè¯å› å­æ•°æ®è´¨é‡"""
        stats = {
            'null_ratio': factor_data.isnull().mean(),
            'inf_count': np.isinf(factor_data.values).sum(),
            'unique_count': factor_data.nunique(),
            'mean': factor_data.mean() if factor_data.dtype in ['float64', 'int64'] else np.nan,
            'std': factor_data.std() if factor_data.dtype in ['float64', 'int64'] else np.nan,
        }
        
        # è´¨é‡è¯„åˆ†
        quality_score = 100
        if stats['null_ratio'] > 0.5:
            quality_score -= 40
        elif stats['null_ratio'] > 0.2:
            quality_score -= 20
        
        if stats['inf_count'] > 0:
            quality_score -= 20
        
        if stats['unique_count'] < 10:
            quality_score -= 20
        
        stats['quality_score'] = max(0, quality_score)
        return stats
    
    def save_factor(self, factor_name: str, factor_data: pd.Series) -> str:
        """ä¿å­˜å› å­æ•°æ®"""
        try:
            filename = f"{factor_name}.pkl"
            file_path = self.output_dir / filename
            
            factor_data.to_pickle(file_path)
            
            file_size = file_path.stat().st_size / 1024 / 1024  # MB
            logger.info(f"  ğŸ’¾ {factor_name}: {filename} ({file_size:.1f}MB)")
            
            return str(file_path)
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜å¤±è´¥ {factor_name}: {e}")
            return None
    
    def run(self, factor_set: str = 'core') -> Dict[str, str]:
        """è¿è¡Œå¿«é€Ÿå› å­ç”Ÿæˆ"""
        print("=" * 70)
        print("âš¡ å¿«é€Ÿå› å­ç”Ÿæˆå™¨")
        print(f"ğŸ“… å¼€å§‹æ—¶é—´: {datetime.now()}")
        print(f"ğŸ¯ å› å­é›†åˆ: {factor_set}")
        print("=" * 70)
        
        start_time = time.time()
        
        # æ£€æŸ¥å› å­é›†åˆæ˜¯å¦æœ‰æ•ˆ
        if factor_set not in self.FACTOR_SETS:
            logger.error(f"âŒ æœªçŸ¥å› å­é›†åˆ: {factor_set}")
            return {}
        
        factor_config = self.FACTOR_SETS[factor_set]
        factors_to_generate = factor_config['factors']
        
        print(f"ğŸ“‹ {factor_config['description']}")
        print(f"ğŸ”¢ åŒ…å«å› å­: {len(factors_to_generate)} ä¸ª")
        print()
        
        # 1. æ£€æŸ¥æ•°æ®å¯ç”¨æ€§
        if not self.check_data_availability():
            return {}
        
        # 2. åŠ è½½æ•°æ®
        if not self.load_data():
            return {}
        
        # 3. åˆ›å»ºè®¡ç®—å™¨
        if not self.create_calculator():
            return {}
        
        # 4. ç”Ÿæˆå› å­
        logger.info(f"ğŸš€ å¼€å§‹ç”Ÿæˆ {len(factors_to_generate)} ä¸ªå› å­...")
        
        results = {}
        saved_files = {}
        
        for i, factor_name in enumerate(factors_to_generate, 1):
            logger.info(f"[{i}/{len(factors_to_generate)}] ç”Ÿæˆå› å­: {factor_name}")
            
            factor_data = self.generate_factor(factor_name)
            
            if factor_data is not None:
                # éªŒè¯è´¨é‡
                stats = self.validate_factor(factor_name, factor_data)
                logger.info(f"    ğŸ“Š è´¨é‡è¯„åˆ†: {stats['quality_score']:.1f}, "
                          f"ç©ºå€¼ç‡: {stats['null_ratio']:.1%}, "
                          f"å”¯ä¸€å€¼: {stats['unique_count']}")
                
                # ä¿å­˜å› å­
                file_path = self.save_factor(factor_name, factor_data)
                if file_path:
                    results[factor_name] = factor_data
                    saved_files[factor_name] = file_path
        
        # 5. ç”Ÿæˆæ‘˜è¦
        total_time = time.time() - start_time
        success_count = len(results)
        
        summary = {
            'generation_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'factor_set': factor_set,
            'total_factors': len(factors_to_generate),
            'successful_factors': success_count,
            'success_rate': success_count / len(factors_to_generate),
            'total_time': total_time,
            'saved_files': saved_files
        }
        
        # ä¿å­˜æ‘˜è¦æ–‡ä»¶
        import json
        summary_file = self.output_dir / f'quick_generation_summary_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        print("\n" + "=" * 70)
        print("ğŸ‰ å¿«é€Ÿå› å­ç”Ÿæˆå®Œæˆ")
        print(f"â±ï¸  æ€»è€—æ—¶: {total_time:.1f} ç§’")
        print(f"âœ… æˆåŠŸç”Ÿæˆ: {success_count}/{len(factors_to_generate)} ä¸ªå› å­")
        print(f"ğŸ’¾ è¾“å‡ºç›®å½•: {self.output_dir}")
        print(f"ğŸ“‹ ç”Ÿæˆæ‘˜è¦: {summary_file}")
        print("=" * 70)
        
        if success_count > 0:
            print(f"\nâœ¨ æˆåŠŸç”Ÿæˆçš„å› å­:")
            for i, factor_name in enumerate(results.keys(), 1):
                print(f"  {i:2d}. {factor_name}")
        
        if success_count < len(factors_to_generate):
            failed_factors = [f for f in factors_to_generate if f not in results]
            print(f"\nâŒ ç”Ÿæˆå¤±è´¥çš„å› å­:")
            for i, factor_name in enumerate(failed_factors, 1):
                print(f"  {i:2d}. {factor_name}")
        
        return saved_files


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='å¿«é€Ÿå› å­ç”Ÿæˆå·¥å…·')
    parser.add_argument('--set', choices=['core', 'basic', 'test'], 
                       default='core', help='å› å­é›†åˆé€‰æ‹©')
    parser.add_argument('--list', action='store_true', help='åˆ—å‡ºæ‰€æœ‰å¯ç”¨å› å­é›†åˆ')
    
    args = parser.parse_args()
    
    generator = QuickFactorGenerator()
    
    if args.list:
        print("\nğŸ“‹ å¯ç”¨å› å­é›†åˆ:")
        print("=" * 50)
        for set_name, set_config in generator.FACTOR_SETS.items():
            print(f"\nğŸ¯ {set_name.upper()}:")
            print(f"   æè¿°: {set_config['description']}")
            print(f"   å› å­æ•°é‡: {len(set_config['factors'])}")
            print(f"   åŒ…å«å› å­: {', '.join(set_config['factors'][:5])}{'...' if len(set_config['factors']) > 5 else ''}")
        return
    
    # è¿è¡Œå¿«é€Ÿç”Ÿæˆ
    saved_files = generator.run(args.set)
    
    if saved_files:
        print(f"\nğŸš€ å¿«é€Ÿå¼€å§‹ä½¿ç”¨ç”Ÿæˆçš„å› å­:")
        print("```python")
        print("import pandas as pd")
        print("from pathlib import Path")
        print("")
        print("# åŠ è½½ç”Ÿæˆçš„å› å­")
        print(f"factor_dir = Path('{generator.output_dir}')")
        for factor_name in list(saved_files.keys())[:3]:  # æ˜¾ç¤ºå‰3ä¸ª
            print(f"{factor_name.lower()} = pd.read_pickle(factor_dir / '{factor_name}.pkl')")
        print("```")


if __name__ == "__main__":
    main()