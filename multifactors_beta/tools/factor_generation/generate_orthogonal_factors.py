#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ ‡å‡†ä¸­æ€§åŒ–å› å­ç”Ÿæˆè„šæœ¬
å°†åŸå§‹å› å­å¯¹åŸºå‡†å› å­å’Œè¡Œä¸šè¿›è¡Œæ­£äº¤åŒ–å¤„ç†ï¼Œç”Ÿæˆæ ‡å‡†ä¸­æ€§åŒ–å› å­

ç‰¹ç‚¹ï¼š
- ğŸ¯ ä½¿ç”¨æ ‡å‡†æ§åˆ¶å˜é‡è¿›è¡Œæ­£äº¤åŒ–
- ğŸ“Š æ”¯æŒæ‰¹é‡å¤„ç†å¤šä¸ªå› å­  
- ğŸ’¾ ä¿å­˜åˆ°OrthogonalizationFactorsç›®å½•
- ğŸ” ç”Ÿæˆè¯¦ç»†çš„å¤„ç†æŠ¥å‘Š
"""

import sys
import os
from pathlib import Path
import pandas as pd
import numpy as np
import logging
from datetime import datetime
import pickle
import json
from typing import Dict, List, Optional, Tuple
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# å¯¼å…¥å› å­æ³¨å†Œè¡¨
from factors.meta import get_factor_registry, FactorType, NeutralizationCategory

from config import get_config, get_config
from core.utils.data_cleaning import OutlierHandler, Normalizer
from factors.tester.core.data_manager import DataManager

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class OrthogonalFactorGenerator:
    """æ­£äº¤åŒ–å› å­ç”Ÿæˆå™¨"""
    
    # æ ‡å‡†æ§åˆ¶å˜é‡é…ç½®
    STANDARD_CONTROL_CONFIG = {
        'base_factors': [
            'LogMarketCap',     # å¯¹æ•°å¸‚å€¼ï¼ˆæœ€é‡è¦ï¼‰
            'BP',               # å‡€èµ„äº§å¸‚å€¼æ¯”
            'LogTurnover_20',   # æ¢æ‰‹ç‡ï¼ˆå¦‚æœæœ‰ï¼‰
        ],
        'use_industry': True,   # ä½¿ç”¨è¡Œä¸šä¸­æ€§åŒ–
        'classification_name': 'classification_one_hot'
    }
    
    # å› å­ç±»åˆ«é…ç½®ï¼ˆå†³å®šæ˜¯å¦éœ€è¦ä¸­æ€§åŒ–ï¼‰
    FACTOR_CATEGORIES = {
        'must_neutralize': [
            'ROE_ttm', 'ROA_ttm', 'ROIC_ttm',           # ç›ˆåˆ©èƒ½åŠ›
            'CurrentRatio', 'QuickRatio',               # å¿å€ºèƒ½åŠ›  
            'AssetTurnover_ttm', 'EquityTurnover_ttm',  # è¥è¿æ•ˆç‡
            'RevenueGrowth_yoy', 'NetIncomeGrowth_yoy', # æˆé•¿èƒ½åŠ›
            'OperatingCashFlowRatio_ttm',               # ç°é‡‘æµ
            'SUE_ss_4', 'SUE_ttm_4',                    # ç›ˆä½™æƒŠå–œ
        ],
        'optional_neutralize': [
            'EP_ttm', 'SP_ttm', 'CFP_ttm',              # ä¼°å€¼å› å­ï¼ˆå¯é€‰ï¼‰
            'Vol_120', 'Vol_20',                         # æ³¢åŠ¨ç‡å› å­
            'ma_120', 'ma_20', 'ma_5',                   # æŠ€æœ¯å› å­
        ],
        'skip_neutralize': [
            'LogMarketCap', 'MarketCap', 'Size',        # è§„æ¨¡å› å­ï¼ˆä½œä¸ºæ§åˆ¶å˜é‡ï¼‰
            'BP', 'LogFreeMarketCap',                   # åŸºå‡†å› å­è‡ªèº«
        ]
    }
    
    def __init__(self):
        """åˆå§‹åŒ–ç”Ÿæˆå™¨"""
        self.raw_factors_path = Path(get_config('main.paths.raw_factors'))
        self.orth_factors_path = Path(get_config('main.paths.orthogonalization_factors'))
        self.output_path = Path(get_config('main.paths.factors'))
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self.orth_factors_path.mkdir(parents=True, exist_ok=True)
        self.output_path.mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨
        config = get_config('main.factor_test') or {}
        self.data_manager = DataManager(config)
        
        # åˆå§‹åŒ–å› å­æ³¨å†Œè¡¨
        self.factor_registry = get_factor_registry()
        
        logger.info("æ­£äº¤åŒ–å› å­ç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"åŸå§‹å› å­è·¯å¾„: {self.raw_factors_path}")
        logger.info(f"æ­£äº¤åŒ–å› å­è·¯å¾„: {self.orth_factors_path}")
    
    def get_available_factors(self) -> List[str]:
        """è·å–å¯ç”¨çš„åŸå§‹å› å­åˆ—è¡¨"""
        factors = []
        
        if self.raw_factors_path.exists():
            for file in self.raw_factors_path.glob("*.pkl"):
                factor_name = file.stem
                factors.append(factor_name)
        
        logger.info(f"å‘ç° {len(factors)} ä¸ªåŸå§‹å› å­")
        return sorted(factors)
    
    def _update_factor_registry(
        self, 
        factor_name: str, 
        orthogonal_path: str,
        control_factors: List[str],
        stats: Dict
    ):
        """æ›´æ–°å› å­æ³¨å†Œè¡¨ï¼Œè®°å½•æ­£äº¤åŒ–ä¿¡æ¯"""
        try:
            # è·å–æˆ–åˆ›å»ºå› å­å…ƒæ•°æ®
            metadata = self.factor_registry.get_factor(factor_name)
            
            if metadata is None:
                # è‡ªåŠ¨æ¨æ–­å› å­ç±»å‹
                factor_type = self._infer_factor_type(factor_name)
                neutralization_category = self._get_neutralization_category(factor_name)
                
                # æ³¨å†Œæ–°å› å­
                metadata = self.factor_registry.register_factor(
                    name=factor_name,
                    factor_type=factor_type,
                    description=f"è‡ªåŠ¨æ³¨å†Œçš„å› å­: {factor_name}",
                    neutralization_category=neutralization_category,
                    generator="OrthogonalFactorGenerator",
                    tags=["auto_registered"]
                )
            
            # æ›´æ–°æ­£äº¤åŒ–ä¿¡æ¯
            self.factor_registry.mark_orthogonalized(
                name=factor_name,
                orthogonal_path=orthogonal_path,
                control_factors=control_factors,
                method='OLS'
            )
            
            # æ›´æ–°æ€§èƒ½ç»Ÿè®¡
            if stats:
                performance_metrics = {
                    'orthogonalization_stats': stats,
                    'last_orthogonalization': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }
                self.factor_registry.update_factor(
                    factor_name, 
                    performance_metrics=performance_metrics
                )
            
            logger.info(f"å·²æ›´æ–°å› å­æ³¨å†Œè¡¨: {factor_name}")
            
        except Exception as e:
            logger.error(f"æ›´æ–°å› å­æ³¨å†Œè¡¨å¤±è´¥ {factor_name}: {e}")
            raise
    
    def _infer_factor_type(self, factor_name: str) -> FactorType:
        """æ ¹æ®å› å­åç§°æ¨æ–­å› å­ç±»å‹"""
        name_lower = factor_name.lower()
        
        # åŸºæœ¬é¢å› å­
        if any(keyword in name_lower for keyword in ['roe', 'roa', 'roic', 'ep', 'bp', 'sp']):
            return FactorType.FUNDAMENTAL
        # æŠ€æœ¯å› å­
        elif any(keyword in name_lower for keyword in ['ma_', 'vol_', 'rsi', 'macd']):
            return FactorType.TECHNICAL
        # åŠ¨é‡å› å­
        elif any(keyword in name_lower for keyword in ['momentum', 'ret_', 'return']):
            return FactorType.MOMENTUM
        # æ³¢åŠ¨ç‡å› å­
        elif any(keyword in name_lower for keyword in ['vol', 'volatility', 'std']):
            return FactorType.VOLATILITY
        # Alpha191å› å­
        elif name_lower.startswith('alpha'):
            return FactorType.ALPHA191
        # æˆé•¿å› å­
        elif any(keyword in name_lower for keyword in ['growth', 'yoy']):
            return FactorType.GROWTH
        # ä»·å€¼å› å­
        elif any(keyword in name_lower for keyword in ['value', 'book', 'price']):
            return FactorType.VALUE
        # è´¨é‡å› å­
        elif any(keyword in name_lower for keyword in ['quality', 'margin', 'turnover']):
            return FactorType.QUALITY
        else:
            return FactorType.DERIVED
    
    def _get_neutralization_category(self, factor_name: str) -> NeutralizationCategory:
        """æ ¹æ®å› å­åç§°ç¡®å®šä¸­æ€§åŒ–ç±»åˆ«"""
        if factor_name in self.FACTOR_CATEGORIES['must_neutralize']:
            return NeutralizationCategory.MUST_NEUTRALIZE
        elif factor_name in self.FACTOR_CATEGORIES['optional_neutralize']:
            return NeutralizationCategory.OPTIONAL_NEUTRALIZE
        elif factor_name in self.FACTOR_CATEGORIES['skip_neutralize']:
            return NeutralizationCategory.SKIP_NEUTRALIZE
        else:
            # é»˜è®¤ä¸ºå¯é€‰ä¸­æ€§åŒ–
            return NeutralizationCategory.OPTIONAL_NEUTRALIZE
    
    def classify_factor(self, factor_name: str) -> str:
        """
        åˆ†ç±»å› å­ï¼Œå†³å®šå¤„ç†ç­–ç•¥
        
        Returns:
        - 'must': å¿…é¡»ä¸­æ€§åŒ–
        - 'optional': å¯é€‰ä¸­æ€§åŒ–  
        - 'skip': è·³è¿‡ä¸­æ€§åŒ–
        """
        if factor_name in self.FACTOR_CATEGORIES['must_neutralize']:
            return 'must'
        elif factor_name in self.FACTOR_CATEGORIES['optional_neutralize']:
            return 'optional'
        elif factor_name in self.FACTOR_CATEGORIES['skip_neutralize']:
            return 'skip'
        else:
            # é»˜è®¤ç­–ç•¥ï¼šå…¶ä»–å› å­å»ºè®®ä¸­æ€§åŒ–
            return 'must'
    
    def load_control_variables(self) -> Optional[pd.DataFrame]:
        """åŠ è½½æ§åˆ¶å˜é‡ï¼ˆåŸºå‡†å› å­ + è¡Œä¸šï¼‰"""
        try:
            # åŠ è½½åŸºå‡†å› å­
            base_factors_list = []
            available_base_factors = []
            
            for factor_name in self.STANDARD_CONTROL_CONFIG['base_factors']:
                try:
                    factor_data = self.data_manager.load_factor_data(factor_name)
                    if not factor_data.empty:
                        base_factors_list.append(factor_data)
                        available_base_factors.append(factor_name)
                        logger.info(f"åŠ è½½åŸºå‡†å› å­: {factor_name}")
                    else:
                        logger.warning(f"åŸºå‡†å› å­ä¸ºç©º: {factor_name}")
                except Exception as e:
                    logger.warning(f"æ— æ³•åŠ è½½åŸºå‡†å› å­ {factor_name}: {e}")
            
            # åˆå¹¶åŸºå‡†å› å­
            if base_factors_list:
                base_factors_df = pd.concat(base_factors_list, axis=1, join='inner')
                base_factors_df.columns = available_base_factors
            else:
                logger.error("æ²¡æœ‰å¯ç”¨çš„åŸºå‡†å› å­")
                return None
            
            # åŠ è½½è¡Œä¸šæ•°æ®
            if self.STANDARD_CONTROL_CONFIG['use_industry']:
                try:
                    industry_data = self.data_manager.load_industry_data(
                        self.STANDARD_CONTROL_CONFIG['classification_name']
                    )
                    
                    if not industry_data.empty:
                        # åˆå¹¶åŸºå‡†å› å­å’Œè¡Œä¸šæ•°æ®
                        control_vars = self.data_manager._merge_base_and_industry(
                            base_factors_df, industry_data
                        )
                        logger.info(f"åŠ è½½è¡Œä¸šæ•°æ®: {industry_data.shape[1]} ä¸ªè¡Œä¸š")
                    else:
                        logger.warning("è¡Œä¸šæ•°æ®ä¸ºç©ºï¼Œä»…ä½¿ç”¨åŸºå‡†å› å­")
                        control_vars = base_factors_df
                except Exception as e:
                    logger.warning(f"æ— æ³•åŠ è½½è¡Œä¸šæ•°æ®: {e}ï¼Œä»…ä½¿ç”¨åŸºå‡†å› å­")
                    control_vars = base_factors_df
            else:
                control_vars = base_factors_df
            
            logger.info(f"æ§åˆ¶å˜é‡å‡†å¤‡å®Œæˆ: {control_vars.shape}")
            return control_vars
            
        except Exception as e:
            logger.error(f"åŠ è½½æ§åˆ¶å˜é‡å¤±è´¥: {e}")
            return None
    
    def orthogonalize_factor(
        self, 
        factor_data: pd.Series, 
        control_vars: pd.DataFrame
    ) -> Tuple[Optional[pd.Series], Dict]:
        """
        å¯¹å•ä¸ªå› å­è¿›è¡Œæ­£äº¤åŒ–å¤„ç†
        
        Returns:
        - orthogonal_factor: æ­£äº¤åŒ–åçš„å› å­
        - stats: å¤„ç†ç»Ÿè®¡ä¿¡æ¯
        """
        import statsmodels.api as sm
        
        stats = {
            'original_count': len(factor_data),
            'valid_count': 0,
            'orthogonal_count': 0,
            'correlation_before': 0,
            'correlation_after': 0,
            'method_used': 'none'
        }
        
        try:
            # æ•°æ®å¯¹é½
            common_index = factor_data.index.intersection(control_vars.index)
            if len(common_index) < 100:
                logger.warning(f"æ•°æ®å¯¹é½åæ ·æœ¬è¿‡å°‘: {len(common_index)}")
                return None, stats
            
            aligned_factor = factor_data.loc[common_index]
            aligned_controls = control_vars.loc[common_index]
            
            # æŒ‰æ—¥æœŸå¤„ç†
            orthogonal_results = []
            daily_stats = []
            
            for date, daily_factor in aligned_factor.groupby(level=0):
                if len(daily_factor) < 10:
                    continue
                
                daily_controls = aligned_controls.loc[date]
                
                # æ•°æ®é¢„å¤„ç†
                y = daily_factor.fillna(0)
                X = daily_controls.fillna(0)
                
                # å»é™¤å…¨é›¶åˆ—
                valid_cols_mask = (X != 0).any(axis=0)
                X_valid = X.loc[:, valid_cols_mask]
                
                if X_valid.empty or len(X_valid.columns) == 0:
                    # æ²¡æœ‰æœ‰æ•ˆæ§åˆ¶å˜é‡ï¼Œä½¿ç”¨åŸå§‹å› å­
                    orthogonal_results.append(y)
                    daily_stats.append('no_controls')
                    continue
                
                try:
                    # æ£€æŸ¥çŸ©é˜µç§©
                    X_with_const = sm.add_constant(X_valid)
                    rank = np.linalg.matrix_rank(X_with_const)
                    
                    if rank < X_with_const.shape[1]:
                        # ä½¿ç”¨å²­å›å½’å¤„ç†ä¸æ»¡ç§©çŸ©é˜µ
                        try:
                            from sklearn.linear_model import Ridge
                            ridge = Ridge(alpha=1e-4)
                            ridge.fit(X_valid, y)
                            residuals = y - ridge.predict(X_valid)
                            daily_stats.append('ridge')
                        except ImportError:
                            # sklearnä¸å¯ç”¨ï¼Œè·³è¿‡è¯¥æ—¥æœŸ
                            continue
                    else:
                        # ä½¿ç”¨OLSå›å½’
                        model = sm.OLS(y, X_with_const)
                        result = model.fit()
                        residuals = result.resid
                        daily_stats.append('ols')
                    
                    # æ ‡å‡†åŒ–æ®‹å·®
                    orth_factor = Normalizer.normalize(residuals, method='zscore')
                    orthogonal_results.append(orth_factor)
                    
                except Exception as e:
                    logger.warning(f"æ—¥æœŸ {date} æ­£äº¤åŒ–å¤±è´¥: {e}")
                    orthogonal_results.append(y)
                    daily_stats.append('failed')
            
            # åˆå¹¶ç»“æœ
            if orthogonal_results:
                orthogonal_factor = pd.concat(orthogonal_results)
                orthogonal_factor.name = f"{factor_data.name}_orth"
                
                # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
                stats['valid_count'] = len(common_index)
                stats['orthogonal_count'] = len(orthogonal_factor)
                stats['method_used'] = max(set(daily_stats), key=daily_stats.count)
                
                # è®¡ç®—ç›¸å…³æ€§å˜åŒ–ï¼ˆå¦‚æœæœ‰LogMarketCapï¼‰
                if 'LogMarketCap' in aligned_controls.columns:
                    try:
                        size_factor = aligned_controls['LogMarketCap']
                        common_for_corr = factor_data.index.intersection(size_factor.index)
                        if len(common_for_corr) > 100:
                            stats['correlation_before'] = factor_data.loc[common_for_corr].corr(
                                size_factor.loc[common_for_corr]
                            )
                            stats['correlation_after'] = orthogonal_factor.corr(
                                size_factor.loc[orthogonal_factor.index.intersection(size_factor.index)]
                            )
                    except:
                        pass
                
                return orthogonal_factor, stats
            else:
                return None, stats
                
        except Exception as e:
            logger.error(f"æ­£äº¤åŒ–å¤„ç†å¤±è´¥: {e}")
            return None, stats
    
    def generate_single_factor(
        self, 
        factor_name: str, 
        control_vars: pd.DataFrame,
        force: bool = False
    ) -> Dict:
        """
        ç”Ÿæˆå•ä¸ªå› å­çš„æ­£äº¤åŒ–ç‰ˆæœ¬
        
        Returns:
        - result dict with status and details
        """
        result = {
            'factor_name': factor_name,
            'status': 'failed',
            'message': '',
            'output_file': None,
            'stats': {}
        }
        
        try:
            # æ£€æŸ¥å› å­åˆ†ç±»
            category = self.classify_factor(factor_name)
            if category == 'skip' and not force:
                result['status'] = 'skipped'
                result['message'] = f"å› å­ç±»åˆ«ä¸º {category}ï¼Œè·³è¿‡ä¸­æ€§åŒ–"
                return result
            
            # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
            output_file = self.orth_factors_path / f"{factor_name}_orth.pkl"
            if output_file.exists() and not force:
                result['status'] = 'existed'
                result['message'] = "æ­£äº¤åŒ–å› å­å·²å­˜åœ¨"
                result['output_file'] = str(output_file)
                return result
            
            # åŠ è½½åŸå§‹å› å­
            factor_data = self.data_manager.load_factor_data(factor_name)
            if factor_data.empty:
                result['message'] = "åŸå§‹å› å­æ•°æ®ä¸ºç©º"
                return result
            
            # æ‰§è¡Œæ­£äº¤åŒ–
            logger.info(f"æ­£åœ¨å¤„ç†å› å­: {factor_name} (ç±»åˆ«: {category})")
            orthogonal_factor, stats = self.orthogonalize_factor(factor_data, control_vars)
            
            if orthogonal_factor is not None:
                # ä¿å­˜æ­£äº¤åŒ–å› å­
                orthogonal_factor.to_pickle(output_file)
                
                # æ›´æ–°å› å­æ³¨å†Œè¡¨
                try:
                    self._update_factor_registry(
                        factor_name=factor_name,
                        orthogonal_path=str(output_file),
                        control_factors=self.STANDARD_CONTROL_CONFIG['base_factors'],
                        stats=stats
                    )
                except Exception as e:
                    logger.warning(f"æ›´æ–°å› å­æ³¨å†Œè¡¨å¤±è´¥ {factor_name}: {e}")
                
                result['status'] = 'success'
                result['message'] = f"æˆåŠŸç”Ÿæˆæ­£äº¤åŒ–å› å­ï¼Œæ ·æœ¬æ•°: {len(orthogonal_factor)}"
                result['output_file'] = str(output_file)
                result['stats'] = stats
                
                logger.info(f"âœ… {factor_name}: {result['message']}")
            else:
                result['message'] = "æ­£äº¤åŒ–å¤„ç†å¤±è´¥"
                logger.warning(f"âŒ {factor_name}: {result['message']}")
                
        except Exception as e:
            result['message'] = f"å¤„ç†å¼‚å¸¸: {str(e)}"
            logger.error(f"âŒ {factor_name}: {result['message']}")
        
        return result
    
    def generate_batch(
        self, 
        factor_names: Optional[List[str]] = None,
        force: bool = False,
        max_factors: Optional[int] = None
    ) -> Dict:
        """
        æ‰¹é‡ç”Ÿæˆæ­£äº¤åŒ–å› å­
        
        Parameters:
        -----------
        factor_names : List[str], optional
            æŒ‡å®šè¦å¤„ç†çš„å› å­åç§°ï¼Œå¦‚æœä¸ºNoneåˆ™å¤„ç†æ‰€æœ‰å¯ç”¨å› å­
        force : bool
            æ˜¯å¦å¼ºåˆ¶é‡æ–°ç”Ÿæˆï¼ˆè¦†ç›–å·²å­˜åœ¨çš„æ–‡ä»¶ï¼‰
        max_factors : int, optional
            æœ€å¤§å¤„ç†å› å­æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰
            
        Returns:
        --------
        Dict: æ‰¹é‡å¤„ç†ç»“æœ
        """
        start_time = datetime.now()
        logger.info("=" * 70)
        logger.info("ğŸš€ æ‰¹é‡æ­£äº¤åŒ–å› å­ç”Ÿæˆå¼€å§‹")
        logger.info(f"ğŸ“… å¼€å§‹æ—¶é—´: {start_time}")
        logger.info("=" * 70)
        
        # å‡†å¤‡å› å­åˆ—è¡¨
        if factor_names is None:
            available_factors = self.get_available_factors()
        else:
            available_factors = factor_names
        
        if max_factors:
            available_factors = available_factors[:max_factors]
            
        logger.info(f"ğŸ“‹ å¾…å¤„ç†å› å­: {len(available_factors)} ä¸ª")
        
        # åŠ è½½æ§åˆ¶å˜é‡
        logger.info("ğŸ“Š åŠ è½½æ§åˆ¶å˜é‡...")
        control_vars = self.load_control_variables()
        if control_vars is None:
            return {
                'status': 'failed',
                'message': 'æ— æ³•åŠ è½½æ§åˆ¶å˜é‡',
                'results': []
            }
        
        # æ‰¹é‡å¤„ç†
        results = []
        success_count = 0
        skip_count = 0
        exist_count = 0
        
        for i, factor_name in enumerate(available_factors, 1):
            logger.info(f"[{i}/{len(available_factors)}] å¤„ç†å› å­: {factor_name}")
            
            result = self.generate_single_factor(factor_name, control_vars, force)
            results.append(result)
            
            if result['status'] == 'success':
                success_count += 1
            elif result['status'] == 'skipped':
                skip_count += 1
            elif result['status'] == 'existed':
                exist_count += 1
        
        # ç”Ÿæˆå¤„ç†æŠ¥å‘Š
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        summary = {
            'status': 'completed',
            'start_time': start_time.isoformat(),
            'end_time': end_time.isoformat(),
            'duration_seconds': duration,
            'total_factors': len(available_factors),
            'success_count': success_count,
            'skip_count': skip_count,
            'exist_count': exist_count,
            'fail_count': len(available_factors) - success_count - skip_count - exist_count,
            'results': results
        }
        
        # ä¿å­˜å¤„ç†æŠ¥å‘Š
        report_file = self.output_path / f"orthogonal_generation_report_{start_time.strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False, default=str)
        
        # æ‰“å°æ±‡æ€»ä¿¡æ¯
        logger.info("\n" + "=" * 70)
        logger.info("ğŸ‰ æ‰¹é‡æ­£äº¤åŒ–å› å­ç”Ÿæˆå®Œæˆ")
        logger.info(f"â±ï¸  æ€»è€—æ—¶: {duration:.1f} ç§’")
        logger.info(f"ğŸ“Š å¤„ç†ç»“æœ:")
        logger.info(f"   âœ… æˆåŠŸç”Ÿæˆ: {success_count}")
        logger.info(f"   â­ï¸  è·³è¿‡å¤„ç†: {skip_count}")
        logger.info(f"   ğŸ“ å·²ç»å­˜åœ¨: {exist_count}")
        logger.info(f"   âŒ å¤„ç†å¤±è´¥: {summary['fail_count']}")
        logger.info(f"ğŸ“‹ è¯¦ç»†æŠ¥å‘Š: {report_file}")
        logger.info("=" * 70)
        
        return summary

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æ­£äº¤åŒ–å› å­ç”Ÿæˆå·¥å…·')
    parser.add_argument('--factors', nargs='+', help='æŒ‡å®šè¦å¤„ç†çš„å› å­åç§°')
    parser.add_argument('--force', action='store_true', help='å¼ºåˆ¶é‡æ–°ç”Ÿæˆï¼ˆè¦†ç›–å·²å­˜åœ¨æ–‡ä»¶ï¼‰')
    parser.add_argument('--max', type=int, help='æœ€å¤§å¤„ç†å› å­æ•°é‡ï¼ˆæµ‹è¯•ç”¨ï¼‰')
    parser.add_argument('--list', action='store_true', help='åˆ—å‡ºæ‰€æœ‰å¯ç”¨å› å­')
    
    args = parser.parse_args()
    
    generator = OrthogonalFactorGenerator()
    
    if args.list:
        factors = generator.get_available_factors()
        print("\nğŸ“‹ å¯ç”¨åŸå§‹å› å­:")
        print("=" * 50)
        
        # æŒ‰ç±»åˆ«åˆ†ç»„æ˜¾ç¤º
        for category, desc in [
            ('must', 'å¿…é¡»ä¸­æ€§åŒ–'),
            ('optional', 'å¯é€‰ä¸­æ€§åŒ–'), 
            ('skip', 'è·³è¿‡ä¸­æ€§åŒ–')
        ]:
            category_factors = [f for f in factors if generator.classify_factor(f) == category]
            if category_factors:
                print(f"\nğŸ¯ {desc} ({len(category_factors)}ä¸ª):")
                for i, factor in enumerate(category_factors[:10]):  # æ˜¾ç¤ºå‰10ä¸ª
                    print(f"  {i+1:2d}. {factor}")
                if len(category_factors) > 10:
                    print(f"     ... è¿˜æœ‰ {len(category_factors)-10} ä¸ª")
        
        return
    
    # æ‰§è¡Œæ‰¹é‡ç”Ÿæˆ
    summary = generator.generate_batch(
        factor_names=args.factors,
        force=args.force,
        max_factors=args.max
    )
    
    if summary['success_count'] > 0:
        print(f"\nâœ¨ æˆåŠŸç”Ÿæˆçš„æ­£äº¤åŒ–å› å­:")
        for result in summary['results']:
            if result['status'] == 'success':
                print(f"  ğŸ“ˆ {result['factor_name']}_orth.pkl")

if __name__ == "__main__":
    main()