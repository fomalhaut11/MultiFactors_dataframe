"""
æ•°æ®éªŒè¯æ¨¡å—

æä¾›æƒé‡æ•°æ®æ ¼å¼éªŒè¯å’Œé¢„å¤„ç†åŠŸèƒ½
"""

import pandas as pd
import numpy as np
import logging
from typing import Tuple, List, Optional
import warnings

logger = logging.getLogger(__name__)

class ValidationError(Exception):
    """æ•°æ®éªŒè¯å¼‚å¸¸"""
    pass

class WeightsValidator:
    """
    æƒé‡æ•°æ®éªŒè¯å™¨
    
    éªŒè¯å’Œé¢„å¤„ç†å›æµ‹æ‰€éœ€çš„æƒé‡æ•°æ®æ ¼å¼
    """
    
    def __init__(self, tolerance: float = 1e-6):
        """
        åˆå§‹åŒ–éªŒè¯å™¨
        
        Parameters
        ----------
        tolerance : float
            æƒé‡å’Œçš„å®¹å·®èŒƒå›´
        """
        self.tolerance = tolerance
        
    def validate_weights_format(self, weights: pd.DataFrame) -> pd.DataFrame:
        """
        éªŒè¯æƒé‡æ•°æ®æ ¼å¼å¹¶è¿›è¡Œé¢„å¤„ç†
        
        Parameters
        ----------
        weights : pd.DataFrame
            æƒé‡æ•°æ®ï¼ŒæœŸæœ›æ ¼å¼ï¼š
            - index: æ—¥æœŸ (DatetimeIndex)
            - columns: è‚¡ç¥¨ä»£ç 
            - values: æƒé‡å€¼
            
        Returns
        -------
        pd.DataFrame
            éªŒè¯å’Œé¢„å¤„ç†åçš„æƒé‡æ•°æ®
            
        Raises
        ------
        ValidationError
            å½“æ•°æ®æ ¼å¼ä¸ç¬¦åˆè¦æ±‚æ—¶
        """
        logger.info(f"å¼€å§‹éªŒè¯æƒé‡æ•°æ®ï¼Œå½¢çŠ¶: {weights.shape}")
        
        # 1. åŸºç¡€æ ¼å¼æ£€æŸ¥
        self._check_basic_format(weights)
        
        # 2. ç´¢å¼•æ ¼å¼æ£€æŸ¥
        self._check_index_format(weights)
        
        # 3. æ•°å€¼æ£€æŸ¥
        self._check_values(weights)
        
        # 4. æƒé‡å’Œæ£€æŸ¥
        cleaned_weights = self._check_and_fix_weight_sums(weights)
        
        # 5. ç¼ºå¤±å€¼å¤„ç†
        cleaned_weights = self._handle_missing_values(cleaned_weights)
        
        logger.info("æƒé‡æ•°æ®éªŒè¯å®Œæˆ")
        return cleaned_weights
    
    def _check_basic_format(self, weights: pd.DataFrame) -> None:
        """æ£€æŸ¥åŸºç¡€æ•°æ®æ ¼å¼"""
        if not isinstance(weights, pd.DataFrame):
            raise ValidationError(f"æƒé‡æ•°æ®å¿…é¡»æ˜¯pandas.DataFrameï¼Œå½“å‰ç±»å‹: {type(weights)}")
            
        if weights.empty:
            raise ValidationError("æƒé‡æ•°æ®ä¸èƒ½ä¸ºç©º")
            
        if weights.shape[0] == 0:
            raise ValidationError("æƒé‡æ•°æ®å¿…é¡»åŒ…å«è‡³å°‘ä¸€ä¸ªäº¤æ˜“æ—¥")
            
        if weights.shape[1] == 0:
            raise ValidationError("æƒé‡æ•°æ®å¿…é¡»åŒ…å«è‡³å°‘ä¸€åªè‚¡ç¥¨")
            
        logger.debug(f"åŸºç¡€æ ¼å¼æ£€æŸ¥é€šè¿‡: {weights.shape[0]}å¤©, {weights.shape[1]}åªè‚¡ç¥¨")
    
    def _check_index_format(self, weights: pd.DataFrame) -> None:
        """æ£€æŸ¥æ—¥æœŸç´¢å¼•æ ¼å¼"""
        if not isinstance(weights.index, pd.DatetimeIndex):
            try:
                # å°è¯•è½¬æ¢ä¸ºæ—¥æœŸç´¢å¼•
                weights.index = pd.to_datetime(weights.index)
                logger.warning("ç´¢å¼•å·²è‡ªåŠ¨è½¬æ¢ä¸ºDatetimeIndex")
            except Exception as e:
                raise ValidationError(f"æ— æ³•å°†ç´¢å¼•è½¬æ¢ä¸ºæ—¥æœŸæ ¼å¼: {e}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤æ—¥æœŸ
        if weights.index.duplicated().any():
            duplicated_dates = weights.index[weights.index.duplicated()].tolist()
            raise ValidationError(f"å‘ç°é‡å¤çš„äº¤æ˜“æ—¥æœŸ: {duplicated_dates}")
        
        # æ£€æŸ¥æ—¥æœŸæ’åº
        if not weights.index.is_monotonic_increasing:
            logger.warning("æ—¥æœŸç´¢å¼•æœªæŒ‰æ—¶é—´é¡ºåºæ’åˆ—ï¼Œå°†è‡ªåŠ¨æ’åº")
            weights.sort_index(inplace=True)
            
        logger.debug(f"æ—¥æœŸç´¢å¼•æ£€æŸ¥é€šè¿‡: {weights.index[0]} åˆ° {weights.index[-1]}")
    
    def _check_values(self, weights: pd.DataFrame) -> None:
        """æ£€æŸ¥æƒé‡æ•°å€¼"""
        # æ£€æŸ¥æ•°æ®ç±»å‹
        non_numeric_cols = []
        for col in weights.columns:
            if not pd.api.types.is_numeric_dtype(weights[col]):
                non_numeric_cols.append(col)
        
        if non_numeric_cols:
            raise ValidationError(f"ä»¥ä¸‹åˆ—åŒ…å«éæ•°å€¼æ•°æ®: {non_numeric_cols}")
        
        # æ£€æŸ¥è´Ÿæƒé‡ï¼ˆå¦‚æœä¸å…è®¸åšç©ºï¼‰
        negative_weights = (weights < 0).sum().sum()
        if negative_weights > 0:
            logger.warning(f"å‘ç° {negative_weights} ä¸ªè´Ÿæƒé‡å€¼ï¼ˆå¯èƒ½è¡¨ç¤ºåšç©ºï¼‰")
        
        # æ£€æŸ¥å¼‚å¸¸å¤§çš„æƒé‡
        max_weight = weights.max().max()
        if max_weight > 1.0:
            logger.warning(f"å‘ç°å•åªè‚¡ç¥¨æƒé‡è¶…è¿‡100%: {max_weight:.2%}")
        
        # æ£€æŸ¥æ— ç©·å¤§å’ŒNaNçš„åˆæ­¥ç»Ÿè®¡
        inf_count = np.isinf(weights.values).sum()
        if inf_count > 0:
            raise ValidationError(f"æƒé‡æ•°æ®åŒ…å« {inf_count} ä¸ªæ— ç©·å¤§å€¼")
            
        logger.debug("æƒé‡æ•°å€¼æ£€æŸ¥é€šè¿‡")
    
    def _check_and_fix_weight_sums(self, weights: pd.DataFrame) -> pd.DataFrame:
        """æ£€æŸ¥å¹¶ä¿®æ­£æƒé‡å’Œ"""
        daily_sums = weights.sum(axis=1)
        
        # æ‰¾å‡ºæƒé‡å’Œåç¦»1.0çš„æ—¥æœŸ
        deviation_mask = np.abs(daily_sums - 1.0) > self.tolerance
        problematic_dates = daily_sums[deviation_mask]
        
        if len(problematic_dates) > 0:
            logger.warning(f"å‘ç° {len(problematic_dates)} ä¸ªäº¤æ˜“æ—¥çš„æƒé‡å’Œåç¦»1.0:")
            for date, sum_val in problematic_dates.head(5).items():
                logger.warning(f"  {date.date()}: {sum_val:.6f}")
            
            if len(problematic_dates) > 5:
                logger.warning(f"  ... è¿˜æœ‰ {len(problematic_dates) - 5} ä¸ªæ—¥æœŸ")
        
        # å†³å®šæ˜¯å¦è‡ªåŠ¨ä¿®æ­£
        max_deviation = np.abs(daily_sums - 1.0).max()
        
        if max_deviation > 0.01:  # åå·®è¶…è¿‡1%ï¼ŒæŠ¥é”™
            raise ValidationError(
                f"æƒé‡å’Œåå·®è¿‡å¤§ (æœ€å¤§åå·®: {max_deviation:.2%})ï¼Œ"
                f"è¯·æ£€æŸ¥æ•°æ®ã€‚åå·®æœ€å¤§çš„æ—¥æœŸ: {daily_sums.idxmax()}"
            )
        elif max_deviation > self.tolerance:  # å°åå·®ï¼Œè‡ªåŠ¨å½’ä¸€åŒ–
            logger.info(f"è‡ªåŠ¨å½’ä¸€åŒ–æƒé‡ (æœ€å¤§åå·®: {max_deviation:.4%})")
            normalized_weights = weights.div(daily_sums, axis=0)
            
            # éªŒè¯å½’ä¸€åŒ–æ•ˆæœ
            new_sums = normalized_weights.sum(axis=1)
            assert np.allclose(new_sums, 1.0, atol=self.tolerance), "å½’ä¸€åŒ–å¤±è´¥"
            
            return normalized_weights
        
        logger.debug("æƒé‡å’Œæ£€æŸ¥é€šè¿‡")
        return weights.copy()
    
    def _handle_missing_values(self, weights: pd.DataFrame) -> pd.DataFrame:
        """å¤„ç†ç¼ºå¤±å€¼"""
        missing_count = weights.isnull().sum().sum()
        
        if missing_count == 0:
            logger.debug("æ— ç¼ºå¤±å€¼")
            return weights
        
        logger.warning(f"å‘ç° {missing_count} ä¸ªç¼ºå¤±å€¼")
        
        # æŒ‰åˆ—ç»Ÿè®¡ç¼ºå¤±å€¼
        missing_by_stock = weights.isnull().sum()
        stocks_with_missing = missing_by_stock[missing_by_stock > 0]
        
        if len(stocks_with_missing) > 0:
            logger.warning("å„è‚¡ç¥¨ç¼ºå¤±å€¼ç»Ÿè®¡:")
            for stock, count in stocks_with_missing.items():
                logger.warning(f"  {stock}: {count} ä¸ªç¼ºå¤±å€¼")
        
        # å¡«å……ç­–ç•¥ï¼šç”¨0å¡«å……ç¼ºå¤±å€¼ï¼ˆè¡¨ç¤ºä¸æŒæœ‰ï¼‰
        filled_weights = weights.fillna(0.0)
        
        # é‡æ–°å½’ä¸€åŒ–
        daily_sums = filled_weights.sum(axis=1)
        zero_sum_days = (daily_sums == 0).sum()
        
        if zero_sum_days > 0:
            logger.error(f"æœ‰ {zero_sum_days} ä¸ªäº¤æ˜“æ—¥çš„æƒé‡å’Œä¸º0ï¼ˆæ‰€æœ‰è‚¡ç¥¨éƒ½ç¼ºå¤±ï¼‰")
            zero_dates = daily_sums[daily_sums == 0].index.tolist()
            raise ValidationError(f"ä»¥ä¸‹æ—¥æœŸæ‰€æœ‰è‚¡ç¥¨æƒé‡éƒ½ç¼ºå¤±: {zero_dates[:5]}")
        
        # å½’ä¸€åŒ–éé›¶æƒé‡
        normalized_weights = filled_weights.div(daily_sums, axis=0)
        
        logger.info("ç¼ºå¤±å€¼å¤„ç†å®Œæˆ")
        return normalized_weights
    
    def generate_validation_report(self, weights: pd.DataFrame) -> dict:
        """
        ç”Ÿæˆæƒé‡æ•°æ®éªŒè¯æŠ¥å‘Š
        
        Parameters
        ----------
        weights : pd.DataFrame
            æƒé‡æ•°æ®
            
        Returns
        -------
        dict
            éªŒè¯æŠ¥å‘Š
        """
        report = {
            'basic_info': {
                'shape': weights.shape,
                'date_range': (weights.index.min(), weights.index.max()),
                'trading_days': len(weights),
                'stocks_count': len(weights.columns),
                'total_observations': weights.size
            },
            'data_quality': {
                'missing_values': weights.isnull().sum().sum(),
                'missing_ratio': weights.isnull().sum().sum() / weights.size,
                'negative_weights_count': (weights < 0).sum().sum(),
                'zero_weights_count': (weights == 0).sum().sum()
            },
            'weight_statistics': {
                'daily_weight_sums': weights.sum(axis=1).describe(),
                'max_single_weight': weights.max().max(),
                'min_single_weight': weights.min().min(),
                'avg_single_weight': weights.mean().mean()
            },
            'stocks_info': {
                'stock_codes': weights.columns.tolist(),
                'avg_weight_by_stock': weights.mean().sort_values(ascending=False),
                'participation_rate': (weights > 0).mean()  # æ¯åªè‚¡ç¥¨è¢«æŒæœ‰çš„æ¯”ä¾‹
            }
        }
        
        return report
    
    def print_validation_report(self, weights: pd.DataFrame) -> None:
        """æ‰“å°éªŒè¯æŠ¥å‘Š"""
        report = self.generate_validation_report(weights)
        
        print("=" * 60)
        print("æƒé‡æ•°æ®éªŒè¯æŠ¥å‘Š")
        print("=" * 60)
        
        print("\nğŸ“Š åŸºç¡€ä¿¡æ¯:")
        basic = report['basic_info']
        print(f"  æ•°æ®å½¢çŠ¶: {basic['shape']} ({basic['trading_days']}å¤© Ã— {basic['stocks_count']}è‚¡ç¥¨)")
        print(f"  æ—¶é—´èŒƒå›´: {basic['date_range'][0].date()} åˆ° {basic['date_range'][1].date()}")
        print(f"  æ€»è§‚æµ‹æ•°: {basic['total_observations']:,}")
        
        print("\nğŸ” æ•°æ®è´¨é‡:")
        quality = report['data_quality']
        print(f"  ç¼ºå¤±å€¼: {quality['missing_values']} ({quality['missing_ratio']:.2%})")
        print(f"  è´Ÿæƒé‡: {quality['negative_weights_count']} ä¸ª")
        print(f"  é›¶æƒé‡: {quality['zero_weights_count']} ä¸ª")
        
        print("\nğŸ“ˆ æƒé‡ç»Ÿè®¡:")
        stats = report['weight_statistics']
        print(f"  æœ€å¤§å•è‚¡æƒé‡: {stats['max_single_weight']:.2%}")
        print(f"  æœ€å°å•è‚¡æƒé‡: {stats['min_single_weight']:.2%}")
        print(f"  å¹³å‡å•è‚¡æƒé‡: {stats['avg_single_weight']:.2%}")
        
        daily_sums = stats['daily_weight_sums']
        print(f"  æ¯æ—¥æƒé‡å’Œç»Ÿè®¡:")
        print(f"    å‡å€¼: {daily_sums['mean']:.6f}")
        print(f"    æ ‡å‡†å·®: {daily_sums['std']:.6f}")
        print(f"    æœ€å°å€¼: {daily_sums['min']:.6f}")
        print(f"    æœ€å¤§å€¼: {daily_sums['max']:.6f}")
        
        print("\nğŸ¢ è‚¡ç¥¨ä¿¡æ¯:")
        stocks = report['stocks_info']
        print(f"  è‚¡ç¥¨æ•°é‡: {len(stocks['stock_codes'])}")
        
        print("  å¹³å‡æƒé‡å‰5å:")
        top_weights = stocks['avg_weight_by_stock'].head()
        for stock, weight in top_weights.items():
            print(f"    {stock}: {weight:.2%}")
        
        print("  å‚ä¸ç‡å‰5å:")
        top_participation = stocks['participation_rate'].sort_values(ascending=False).head()
        for stock, rate in top_participation.items():
            print(f"    {stock}: {rate:.1%}")

# ä¾¿æ·å‡½æ•°
def validate_weights(weights: pd.DataFrame, tolerance: float = 1e-6) -> pd.DataFrame:
    """
    å¿«é€ŸéªŒè¯æƒé‡æ•°æ®çš„ä¾¿æ·å‡½æ•°
    
    Parameters
    ----------
    weights : pd.DataFrame
        æƒé‡æ•°æ®
    tolerance : float
        æƒé‡å’Œçš„å®¹å·®
        
    Returns
    -------
    pd.DataFrame
        éªŒè¯åçš„æƒé‡æ•°æ®
    """
    validator = WeightsValidator(tolerance=tolerance)
    return validator.validate_weights_format(weights)